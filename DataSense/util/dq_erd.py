# -*- coding: utf-8 -*-
"""
ğŸ“˜ Master ERD ì—ì„œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ë“¤  
2025.12.02 Qliker (New Version)
"""

import pandas as pd
import numpy as np
import os
import re
import sys
import streamlit as st
import datetime
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, Any, Optional
import itertools
from itertools import combinations
import graphviz
from graphviz import Digraph
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import warnings
import plotly.graph_objects as go
import traceback
from PIL import Image
warnings.filterwarnings("ignore", category=UserWarning)


def fill_na_zero_empty_string(df: pd.DataFrame, numeric_cols: list) -> pd.DataFrame:
    """ìˆ«ì ì»¬ëŸ¼ì€ NaNì„ 0ìœ¼ë¡œ ì±„ìš°ê³ , ë‚˜ë¨¸ì§€ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì±„ìš°ê¸°"""
    for col in numeric_cols:
        if col in df.columns:
            df[col] = df[col].fillna(0)
            df[col] = df[col].replace('', 0) # ë¹ˆ ë¬¸ìì—´ì„ 0ìœ¼ë¡œ ë³€í™˜
            df[col] = df[col].astype(int)
    
    # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ì€ ë¹ˆ ë¬¸ìì—´ë¡œ ì±„ìš°ê¸°
    other_cols = [col for col in df.columns if col not in numeric_cols]
    df[other_cols] = df[other_cols].fillna('')
    return df
    
from typing import List, Tuple, Dict

def parse_relations(level_rel: str, self_file: str = None, self_col: str = None) -> List[Tuple[str, str]]:
    """
    'A.a -> B.b -> C.c' ë˜ëŠ” 'A.a->B.b->C.c' ë“± ë‹¤ì–‘í•œ í¬ë§·ì„ ì²˜ë¦¬í•˜ì—¬
    ìê¸° ìì‹ (A.a)ì€ ì œì™¸í•œ [('B','b'), ('C','c')] í˜•íƒœë¡œ ë°˜í™˜.
    - level_rel: ì›ë³¸ ë¬¸ìì—´
    - self_file, self_col: ìê¸° ìì‹ ì„ ëª…í™•íˆ ì œì™¸í•˜ë ¤ë©´ ì œê³µ (ì„ íƒ)
    """
    relations = []
    if level_rel is None:
        return relations

    s = str(level_rel).strip()
    if s == '' or s.lower() in ['nan', 'none']:
        return relations

    # '->' ë˜ëŠ” '->' ì£¼ë³€ ê³µë°± ë¬´ì‹œ, í˜¹ì€ ë‹¨ìˆœ '>' ë“± ë¹„ì •ìƒ ê¸°í˜¸ í—ˆìš©(ì •ê·œì‹ ì•½ê°„ ìœ ì—°)
    # ê¸°ë³¸ì ìœ¼ë¡œ '->' ë¥¼ êµ¬ë¶„ìë¡œ ì‚¬ìš©. ë§Œì•½ '->'ê°€ ì—†ê³  '.'ë§Œ ì—¬ëŸ¬ê°œ ìˆëŠ” ê²½ìš° í•œ ë©ì–´ë¦¬ë¡œ ì·¨ê¸‰.
    parts = [p.strip() for p in re.split(r'\s*->\s*', s) if p.strip()]

    # ê° partëŠ” ë³´í†µ 'File.Column' í˜•ì‹. ë§Œì•½ 'csv.File.Column' ê°™ì´ ì ‘ë‘ì‚¬ê°€ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ë‘ í† í°ìœ¼ë¡œ ì²˜ë¦¬
    for part in parts:
        # normalize: comma or semicolon separated (ë³´í—˜)
        part = part.strip().rstrip(';,')
        if '.' not in part:
            continue

        file_part, col_part = part.rsplit('.', 1)
        file_part = file_part.strip()
        col_part = col_part.strip()

        if file_part.lower().startswith('csv.'):
            file_part = file_part[len('csv.'):]

        # í•„í„°: nan/none/ë¹ˆ ë¬¸ìì—´ ì œì™¸
        if not file_part or not col_part:
            continue
        if file_part.lower() in ['nan', 'none'] or col_part.lower() in ['nan', 'none']:
            continue

        # ìê¸° ìì‹  ì œì™¸(ì˜µì…˜)
        if self_file and self_col:
            if file_part == self_file and col_part == self_col:
                continue

        relations.append((file_part, col_part))

    # ë³´í†µ ì²« ë¶€ë¶„ì´ ìê¸° ìì‹ (A.a)ë¡œ ë“¤ì–´ì˜¨ë‹¤ë©´ parts[0]ì„ ì œê±°í–ˆì„ ë•Œ ì´ë¯¸ ì œì™¸ë˜ë¯€ë¡œ ì¶”ê°€ ì¡°ì¹˜ëŠ” í•„ìš” ì—†ìŒ.
    # í•˜ì§€ë§Œ ë§Œì•½ parts[0]ì´ ìê¸°ìì‹ ìœ¼ë¡œ ë“¤ì–´ì˜¤ì§€ ì•Šê³  ë‹¤ë¥¸ í¬ë§·ì´ë¼ë©´ ìƒìœ„ì—ì„œ ìê¸°ìì‹  ì²´í¬ ê°€ëŠ¥.
    return relations


def expand_rel_rows(df: pd.DataFrame, filter_predicate=None, include_level_cols: bool = True) -> pd.DataFrame:
    """
    ë°˜ë³µë˜ëŠ” í™•ì¥ ë¡œì§ì„ í•˜ë‚˜ë¡œ í•©ì¹œ í•¨ìˆ˜.
    - df: ì›ë³¸ DataFrame (FileName, ColumnName, MasterType, PK, FK, Attribute, Level_Depth, Level_Relationship ë“± í¬í•¨)
    - filter_predicate: ê° rowì— ëŒ€í•´ í™•ì¥ ëŒ€ìƒì¸ì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜(row) -> bool, Noneì´ë©´ ëª¨ë“  row ëŒ€ìƒ
    - include_level_cols: ê²°ê³¼ì— Level_Depth, Level_Relationship ì»¬ëŸ¼ì„ í¬í•¨í• ì§€ ì—¬ë¶€
    """
    rows = []
    columns_needed = ['FileName', 'ColumnName', 'MasterType', 'PK', 'FK', 'Attribute', 'Level_Depth', 'Level_Relationship']

    for _, row in df.iterrows():
        if filter_predicate and not filter_predicate(row):
            continue

        # parse_relationsì— ìê¸° ìì‹  ì •ë³´ ì „ë‹¬í•˜ì—¬ ìê¸° ì°¸ì¡° ì œê±°
        relations = parse_relations(row.get('Level_Relationship', ''), self_file=row.get('FileName'), self_col=row.get('ColumnName'))

        if not relations:
            r = {
                'FileName': row.get('FileName', ''),
                'ColumnName': row.get('ColumnName', ''),
                'MasterType': row.get('MasterType', ''),
                'PK': row.get('PK', ''),
                'FK': row.get('FK', ''),
                'Attribute': row.get('Attribute', ''),
                'Level': 0,
                'To FileName': '',
                'To ColumnName': ''
            }
            if include_level_cols:
                r['Level_Depth'] = row.get('Level_Depth', '')
                r['Level_Relationship'] = row.get('Level_Relationship', '')
            rows.append(r)
            continue

        for idx, (to_file, to_col) in enumerate(relations, start=1):
            r = {
                'FileName': row.get('FileName', ''),
                'ColumnName': row.get('ColumnName', ''),
                'MasterType': row.get('MasterType', ''),
                'PK': row.get('PK', ''),
                'FK': row.get('FK', ''),
                'Attribute': row.get('Attribute', ''),
                'Level': idx,
                'To FileName': to_file,
                'To ColumnName': to_col
            }
            if include_level_cols:
                r['Level_Depth'] = row.get('Level_Depth', '')
                r['Level_Relationship'] = row.get('Level_Relationship', '')
            rows.append(r)

    # ê²°ê³¼ê°€ ë¹„ì–´ ìˆì–´ë„ ì»¬ëŸ¼êµ¬ì¡° ìœ ì§€
    if rows:
        out = pd.DataFrame(rows)
    else:
        base_cols = ['FileName','ColumnName','MasterType','PK','FK','Attribute','Level','To FileName','To ColumnName']
        if include_level_cols:
            base_cols += ['Level_Depth','Level_Relationship']
        out = pd.DataFrame(columns=base_cols)
    return out

    
def display_erd_kpis(df: pd.DataFrame):  # ì²«ë²ˆì§¸ Main KPI ì¶œë ¥ 
    """ì´ˆê¸° Files Information í‘œì‹œ """
    st.markdown("### Files & Columns KPI ")
    
    table_info = [] 
    
    table_info = df.groupby('FileName').agg({
        'MasterType': 'first',
        'ColumnName': lambda x: ', '.join(x)
    }).reset_index().to_dict(orient='records')
            
    table_list = pd.DataFrame(table_info) # DataFrame ìƒì„±
    
    summary = {
        "Files Cnt #": f"{len(table_list):,}",
        "Column Cnt #": f"{table_list['ColumnName'].apply(len).sum():,}",
    }
    
    # ê° ë©”íŠ¸ë¦­ì— ëŒ€í•œ ìƒ‰ìƒ ì •ì˜
    metric_colors = {
        "Files Cnt #": "#1f77b4",
        "Column Cnt #": "#2ca02c",
    }
    
    # ë©”íŠ¸ë¦­ í‘œì‹œ
    cols = st.columns(len(summary))
    for col, (key, value) in zip(cols, summary.items()):
        color = metric_colors.get(key, "#0072B2")
        col.markdown(f"""
            <div style="text-align: center; padding: 1.2rem; background-color: #FFFFFF; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                <div style="color: {color}; font-size: 3em; font-weight: bold;">{value}</div>
                <div style="color: #404040; font-size: 1.5em; margin-top: 0.5rem;">{key}</div>
            </div>
        """, unsafe_allow_html=True)

def display_erd_table_list(df: pd.DataFrame): 
    """2nd Step: Files & Column List Information """

    st.divider()
    st.markdown("##### Files & Columns Information")

    summary_df = summary_erd_info_tables(df)

    summary_df['ì„ íƒ'] = False  # ì²´í¬ë°•ìŠ¤ë¥¼ ìœ„í•œ ì»¬ëŸ¼ ì¶”ê°€
    
    # 'ì„ íƒ' ì»¬ëŸ¼ì„ ì²« ë²ˆì§¸ ìœ„ì¹˜ë¡œ ì´ë™
    cols = summary_df.columns.tolist()
    cols.remove('ì„ íƒ')
    cols.insert(0, 'ì„ íƒ')
    summary_df = summary_df[cols]
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'selected_tables' not in st.session_state:
        st.session_state.selected_tables = []
    
    # ì²´í¬ë°•ìŠ¤ì™€ í•¨ê»˜ DataFrame í‘œì‹œ
    edited_table_list = st.data_editor(
        summary_df,
        column_config={
            'ì„ íƒ': st.column_config.CheckboxColumn('ì„ íƒ', width=50),
            'FileName': st.column_config.TextColumn('FileName', width=200),
            'Type': st.column_config.TextColumn('Type', width=100),
            'Cols': st.column_config.NumberColumn('Cols', width=50),
            'Column List': st.column_config.TextColumn('Column List', width=500, disabled=True),
        },
        hide_index=True,
        height=500,
        width=1000,
        key="table_list_editor"
    )
    
    # ì„ íƒëœ í…Œì´ë¸” ì¶”ì¶œ
    selected_tables = edited_table_list[edited_table_list['ì„ íƒ'] == True]['FileName'].tolist()
    st.session_state.selected_tables = selected_tables

# -------------------------------------------------------------------
# Summary Table & Column Information
# -------------------------------------------------------------------
def summary_erd_info_tables(df:pd.DataFrame) -> pd.DataFrame:
    table_df = df.groupby('FileName').agg({
        'MasterType': 'first',
        'ColumnName': ['count', lambda x: ', '.join(x.astype(str))]
    }).reset_index()
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬ (MultiIndexë¥¼ ë‹¨ì¼ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½)
    table_df.columns = ['FileName', 'Type', 'Cols', 'Column List']
    summary_df = pd.DataFrame(table_df)

    # PK ì •ë³´ ì§‘ê³„
    pk_df = pd.DataFrame()
    if 'PK' in df.columns:
        pk_filtered = df[(df['PK'] == 1) | (df['PK'] == '1')]
        if not pk_filtered.empty:
            pk_df = pk_filtered.groupby('FileName').agg({
                'ColumnName': ['count', lambda x: ', '.join(x.astype(str))]
            }).reset_index()

            pk_df.columns = ['FileName', 'PK Cols', 'PK Column List']
        else: # ë¹ˆ DataFrameì´ì§€ë§Œ ì»¬ëŸ¼ì€ ìƒì„±
            pk_df = pd.DataFrame(columns=['FileName', 'PK Cols', 'PK Column List'])
        summary_df = pd.merge(summary_df, pk_df, on='FileName', how='left')

    # FK ì •ë³´ ì§‘ê³„
    fk_df = pd.DataFrame()
    if 'FK' in df.columns:
        fk_filtered = df[(df['FK'] == 'FK') | (df['FK'] == '1')]
        if not fk_filtered.empty:
            fk_df = fk_filtered.groupby('FileName').agg({
                'ColumnName': ['count', lambda x: ', '.join(x.astype(str))]
            }).reset_index()

            fk_df.columns = ['FileName', 'FK Cols', 'FK Column List']
        else: # ë¹ˆ DataFrameì´ì§€ë§Œ ì»¬ëŸ¼ì€ ìƒì„±
            fk_df = pd.DataFrame(columns=['FileName', 'FK Cols', 'FK Column List'])
        summary_df = pd.merge(summary_df, fk_df, on='FileName', how='left')

    if not summary_df.empty:
        numeric_cols = ['FK Cols', 'PK Cols', 'Cols']
        summary_df = fill_na_zero_empty_string(summary_df, numeric_cols) # ê³µí†µí•¨ìˆ˜

    return summary_df

def get_erd_ref_info(codemapping_df:pd.DataFrame, selected_df:pd.DataFrame, concat_df:pd.DataFrame):
    """ì°¸ì¡° í…Œì´ë¸” ì •ë³´ í‘œì‹œ"""

    cols = ['FileName','ColumnName','MasterType','PK','FK','Attribute','Level_Depth','Level_Relationship']
    ref_candidates_df = selected_df[cols].copy()
    predicate_ref = lambda r: (r.get('Level_Depth') is not None) and (r.get('Level_Depth') != '') and (float(r.get('Level_Depth') or 0) > 0)
    ref_df = expand_rel_rows(ref_candidates_df, filter_predicate=predicate_ref, include_level_cols=True)

    master_type_by_table = codemapping_df.groupby('FileName')['MasterType'].first().to_dict()
    ref_df['To Type'] = ref_df['To FileName'].map(master_type_by_table)

    ref_df = ref_df.drop(columns=['Level_Depth', 'Level_Relationship'])
    ref_df = ref_df.fillna('')

    concat_cols = ['FileName','ColumnName','MasterType', 'CodeFile', 'CodeColumn', 'CodeType', 'Matched', 'Matched(%)']
    concat_df = concat_df[concat_cols]

    concat_df = concat_df.rename(columns={
        'CodeFile': 'To FileName', 'CodeColumn': 'To ColumnName', 'CodeType': 'To Type'})
    ref_df = ref_df.merge(concat_df, on=['FileName','ColumnName','MasterType', 'To FileName', 'To ColumnName', 'To Type'], how='left')
    return ref_df

def selected_tables_info(codemapping_df:pd.DataFrame, selected_tables: list, concat_df:pd.DataFrame):
    """ì„ íƒí•œ í…Œì´ë¸”ë“¤ì˜ ì •ë³´ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ ì¶œë ¥"""
    
    selected_df = codemapping_df[codemapping_df['FileName'].isin(selected_tables)].copy()
    selected_df = selected_df.fillna('')

    ref_df = get_erd_ref_info(codemapping_df, selected_df, concat_df)

    # íƒ­ ìƒì„±
    SUB_TITLE1 = "í…Œì´ë¸”ë³„ ì»¬ëŸ¼ë¦¬ìŠ¤íŠ¸, PK, FK ì •ë³´"
    SUB_TITLE2 = "ì»¬ëŸ¼ê°„ì˜ ê´€ê³„ ì •ë³´"
    SUB_TITLE3 = "Foreign Keyë³„ ê´€ê³„ ì •ë³´ ìƒì„¸"
    SUB_TITLE4 = "Reference ì»¬ëŸ¼ë³„ ê´€ê³„ ì •ë³´ ìƒì„¸"
    SUB_TITLE5 = "ì „ì²´ ì»¬ëŸ¼ ê´€ê³„ ì •ë³´ ìƒì„¸"
    tab1, tab2, tab3, tab4, tab5 = st.tabs([SUB_TITLE1, SUB_TITLE2, SUB_TITLE3, SUB_TITLE4, SUB_TITLE5])       
    # 1. í…Œì´ë¸” ë° Primary Key ì •ë³´ (í†µí•©)
    with tab1:
        st.markdown(f"### {SUB_TITLE1}")

        selected_table_info_df = summary_erd_info_tables(selected_df)

        st.dataframe(selected_table_info_df, hide_index=True, width=1400, height=300)
    
    # 2. Level_relationship ì •ë³´
    with tab2:
        st.markdown(f"### {SUB_TITLE2}")
        df = selected_df[['FileName', 'ColumnName', 'MasterType', 'PK', 'FK', 'Attribute', 'Level_Depth', 'Level_Relationship']]
        df = df.fillna('')
        st.dataframe(df, hide_index=True, width=1400, height=500)
    # 3. FK ì •ë³´
    with tab3:
        st.markdown(f"### {SUB_TITLE3}")

        fk_df = ref_df[(ref_df['PK'] == 1) | (ref_df['FK'] == 'FK')]
        st.dataframe(fk_df, hide_index=True, width=1000, height=500)

    # 4. ì°¸ì¡° í…Œì´ë¸” ì •ë³´
    with tab4:
        st.markdown(f"### {SUB_TITLE4}")
        st.dataframe(ref_df, hide_index=True, width=1000, height=500)

    # 5. ì°¸ì¡° í…Œì´ë¸” ì •ë³´
    with tab5:
        st.markdown(f"### {SUB_TITLE5}")
        all_df = selected_df[['FileName', 'ColumnName', 'MasterType', 'PK', 'FK', 'Attribute']]
        all_df = all_df.merge(ref_df, on=['FileName', 'ColumnName', 'MasterType', 'PK', 'FK', 'Attribute',], how='left')
        all_df = all_df.fillna('')
        st.dataframe(all_df, hide_index=True, width=1000, height=500)

def get_max_depth(codemapping_df:pd.DataFrame, key:str): # ë…¼ë¦¬ê´€ê³„ ìš”ì•½/ìƒì„¸ ERD ìƒì„±ì‹œ Depth ì…ë ¥
    """Level ê´€ê³„ì˜ ìµœëŒ€ ê¹Šì´ ì¶”ì¶œ"""
    level_cols = [col for col in codemapping_df.columns if col.startswith('Level') and '_File' in col]
    if level_cols:
        max_available_depth = max([int(col.replace('Level', '').replace('_File', '')) for col in level_cols]) + 1
        
        st.markdown("DepthëŠ” Level ê´€ê³„ì˜ ê¹Šì´ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ˆ: Depth=1ì´ë©´ Level0->Level1 ê´€ê³„ë§Œ í‘œì‹œ, Depth=2ì´ë©´ Level0->Level1, Level1->Level2ê¹Œì§€ í‘œì‹œ")
        col1, col2 = st.columns([1, 2])
        with col1:
            max_depth_input = st.number_input(
                "Depth (ëª¨ë“  Levelì„ í‘œì‹œí•˜ë ¤ë©´ 0 ë˜ëŠ” ë¹„ì›Œë‘ì„¸ìš”)",
                min_value=0,
                max_value=max_available_depth,
                value=0,
                step=1,
                key=key
            )
        max_depth = None if max_depth_input == 0 else max_depth_input

        with col2:
            st.markdown(f"**Depth ì„¤ì •** (ìµœëŒ€ ì‚¬ìš© ê°€ëŠ¥: {max_available_depth})")
    else:
        max_depth = None

    return max_depth