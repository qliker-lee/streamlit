import pandas as pd
import os
import streamlit as st
from docx import Document
from docx.shared import Inches, Pt, RGBColor, Mm
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.shared import Inches
from docx.enum.section import WD_ORIENT, WD_ORIENTATION
from datetime import datetime

# Create Main KPIs
def master_File_summary(df):
    file_cnt = len(df['FileName'].unique())
    Column_cnt = df['ColumnCnt'].sum()
    record_Cnt = df['RecordCnt'].sum()/100000
    file_size = df['FileSize'].sum()/1000000
    work_date = df['WorkDate'].unique().max()
    return {
        "Total Files #": f"{file_cnt:,}", 
        "Total Columns #": f"{Column_cnt:,}", # Column_cnt,
        "Record #(ë°±ë§Œ)": f"{record_Cnt:,.0f}",   # record_Cnt, 
        "File Size(MB)": f"{file_size:,.0f}",  #file_size,
        "Analyzed Date" : work_date
    }

def Display_KPIs(df):
    st.markdown("####  ë¶„ì„ ëŒ€ìƒ íŒŒì¼(íŒŒì¼)ë“¤ì˜ ì£¼ìš” ì§€í‘œ ì…ë‹ˆë‹¤.")   
    # CSS ìŠ¤íƒ€ì¼ ì •ì˜
    st.markdown("""
        <style>
        div[data-testid="metric-container"] {
            background-color: #FFFFFF;
            border: 1px solid #E0E0E0;
            padding: 1rem;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        div[data-testid="metric-container"] > label[data-testid="stMetricLabel"] {
            display: flex;
            justify-content: center;
            color: #404040;
            font-weight: 600;
        }
        div[data-testid="metric-container"] > div[data-testid="stMetricValue"] {
            display: flex;
            justify-content: center;
            font-weight: bold;
        }
        </style>
    """, unsafe_allow_html=True)

    # KPI í‘œì‹œ
    summary = master_File_summary(df)
    
    # ê° ë©”íŠ¸ë¦­ì— ëŒ€í•œ ìƒ‰ìƒ ì •ì˜
    metric_colors = {
        "Total Files #": "#1f77b4",      # íŒŒë€ìƒ‰
        "Total Columns #": "#2ca02c",      # ì´ˆë¡ìƒ‰
        "Record #(ë°±ë§Œ)": "#ff7f0e",      # ì£¼í™©ìƒ‰
        "File Size(MB)": "#d62728",       # ë¹¨ê°„ìƒ‰
        "Working Date": "#9467bd"         # ë³´ë¼ìƒ‰
    }

    # ë©”íŠ¸ë¦­ í‘œì‹œ
    cols = st.columns(len(summary))
    for col, (key, value) in zip(cols, summary.items()):
        color = metric_colors.get(key, "#0072B2")  # ê¸°ë³¸ ìƒ‰ìƒ
        col.markdown(f"""
            <div style="text-align: center; padding: 1.2rem; background-color: #FFFFFF; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                <div style="color: {color}; font-size: 2em; font-weight: bold;">{value}</div>
                <div style="color: #404040; font-size: 1em; margin-top: 0.5rem;">{key}</div>
            </div>
        """, unsafe_allow_html=True)

# # -------------------------------------------------------------------------------
# # ë³´ê³ ì„œ ìƒì„± í•¨ìˆ˜
# # -------------------------------------------------------------------------------
# def generate_text_report(df, CURRENT_DIR_PATH, QDQM_ver):
#     if df.empty:
#         st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return

#     # ë³´ê³ ì„œ ë‚´ìš© ìƒì„±
#     report_content = "\n"  
#     report_content += """
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                                             
#                Data Quality Management Report                 
                                                              
#                    QDQM Analyzer Report                      
                                                             
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# """
#     report_content += "\n"*3   
#     report_content += f"""
#     \tì‘ì„±ì\t\t: QDQM Analyzer
#     \tì‘ì„±ì¼ì‹œ\t\t: {pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")}
#     \të²„ì „\t\t: {QDQM_ver}
#     """
#     report_content += "\n"*3

#     report_content += """
#     \të³¸ ë³´ê³ ì„œëŠ” QDQM Analyzerì— ì˜í•´ ìë™ ìƒì„±ëœ ë³´ê³ ì„œì…ë‹ˆë‹¤.
#     \të°ì´í„° í’ˆì§ˆ ê´€ë¦¬ë¥¼ ìœ„í•œ ìë£Œë¡œ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
#     """
#     report_content += "\n" + "=" * 60 + "\n\n"
    
#     # ê¸°ë³¸ ì •ë³´ ì¶”ê°€
#     summary = master_File_summary(df)
#     report_content += "[ Files Information ]\n\n"
#     for key, value in summary.items():
#         report_content += f"\t{key}\t: {value}\n"

#     unicode_files = df[df['UnicodeCnt'] > 0]['FileName'].tolist()
#     unicode_file_count = len(unicode_files)
#     report_content += f"\n\tUnicode ë¬¸ì í¬í•¨ íŒŒì¼ ìˆ˜: {unicode_file_count} ê°œ\n"
    
#     broken_kor_files = df[df['BrokenKoreanCnt'] > 0]['FileName'].tolist()
#     broken_kor_file_count = len(broken_kor_files)
#     report_content += f"\tí•œê¸€ ë¯¸ì™„ì„± ë¬¸ì í¬í•¨ íŒŒì¼ ìˆ˜: {broken_kor_file_count} ê°œ\n"
    
#     lt_lcl_files = df[df['BelowLCL'] > 0]['FileName'].tolist()
#     lt_lcl_file_count = len(lt_lcl_files)
#     report_content += f"\tLCL ë³´ë‹¤ ì‘ì€ ê°’ì„ ê°–ê³ ìˆëŠ” íŒŒì¼ ìˆ˜: {lt_lcl_file_count} ê°œ\n"  
    
#     gt_ucl_files = df[df['UpperUCL'] > 0]['FileName'].tolist()
#     gt_ucl_file_count = len(gt_ucl_files)
#     report_content += f"\tUCL ë³´ë‹¤ í° ê°’ì„ ê°–ê³ ìˆëŠ” íŒŒì¼ ìˆ˜: {gt_ucl_file_count} ê°œ\n"   
    
      
#     LCLUCL_Site = "https://qliksense.tistory.com/45"
#     report_content += f"\n\tLCL, UCLì— ê´€í•œ ìì„¸í•œ ë‚´ìš©ì€ ì—¬ê¸°ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”: {LCLUCL_Site}\n"
    
#     report_content += "\n" + "=" * 60 + "\n\n"

#     # íŒŒì¼ë³„ ìƒì„¸ ì •ë³´
#     report_content += "[ Files Detail Information ]\n"
#     report_content += "\n" + "=" * 60 + "\n\n"
#     for _, row in df.iterrows():
#         report_content += f"[ {row['FileName']} ] File Detail Information \n\n"
#         report_content += f"\tColumns #\t\t: {row['ColumnCnt']}\n"
#         report_content += f"\tFile Size\t\t: {row['FileSize']/1000:,.0f} KB\n"
#         if len(str(int(row['RecordCnt']))) > 6:
#             report_content += f"\tRow #\t\t: {row['RecordCnt']:,.0f}\n"
#         else:
#             report_content += f"\tRow #\t\t: {row['RecordCnt']:,.0f}\n"
#         report_content += f"\tSampling #\t: {row['SamplingRows']:,.0f}\n"
#         report_content += f"\tUnique Columns\t: {row['UniqueCnt']}\n"
#         report_content += "\n\t--- Column # by Data Type ---\n"
#         report_content += f"\tText Columns\t: {row['IsText']}\t\t"
#         report_content += f"\tNull Columns\t: {row['IsNull']}\n"
#         report_content += f"\tNumeric Columns\t: {row['IsNum']}\t\t"
#         report_content += f"\tVarchar(Num)\t: {row['NumChar']}\n"    
#         report_content += f"\tDate Columns\t: {row['Date']}\t\t"
#         report_content += f"\tVarchar(Date)\t: {row['DateChar']}\n"
#         report_content += f"\tVarchar(Time)\t: {row['TimeChar']}\t\t"
#         report_content += f"\tTimeStamp Columns\t: {row['TimeStamp']}\n" 
#         report_content += "\n\t--- Column # by Data Value ---\n"
#         report_content += f"\tHas Alpha     \t: {row['HasAlpha']}\n"
#         report_content += f"\tHas Only Alpha\t: {row['HasOnlyAlpha']}\t\t"
#         report_content += f"\tOnly Alpha&Num\t: {row['HasOnlyAlphaNum']}\n"
#         report_content += f"\tHas Kor    \t: {row['HasKor']}\n"
#         report_content += f"\tHas Only Kor\t: {row['HasOnlyKor']}\t\t"
#         report_content += f"\tBroken Kor\t: {row['BrokenKoreanCnt']}\n"
#         report_content += f"\tHas Special\t: {row['SpecialCnt']}\t\t"
#         report_content += f"\tHas Unicode\t: {row['UnicodeCnt']}\n"
#         report_content += f"\tHas Chinese\t: {row['ChineseCnt']}\t\t"   
#         report_content += f"\tHas Null   \t: {row['NullCnt']}\n"
#         report_content += f"\tHas Blank  \t: {row['HasBlank']}\t\t"
#         report_content += f"\tHas Dash  \t: {row['HasDash']}\n"
#         report_content += f"\tHas Dot    \t: {row['HasDot']}\t\t"
#         report_content += f"\tHas Bracket\t: {row['HasBracket']}\n"
#         # report_content += f"Has At\t: {row['HasAt_Cnt']}\n"
#         report_content += "\n\t--- Column # by Numeric Value & Statistics ---\n"
#         report_content += f"\tHas Only Num\t: {row['HasOnlyNum']}\n"
#         report_content += f"\tHas Minus   \t: {row['HasMinus']}\t\t"
#         # report_content += f"\tHas Float  \t: {row['HasReal']}\n"
#         report_content += f"\tLess Than LCL\t: {row['BelowLCL']}\t\t"
#         report_content += f"\tGreater Than UCL\t: {row['UpperUCL']}\n"

#         report_content += "\n\t--- Column # by Master Matching ---\n"
#         report_content += f"\tì í•©        \t: {row['ì í•©']}\t\t"
#         report_content += f"\tì–‘í˜¸        \t: {row['ì–‘í˜¸']}\n"
#         report_content += f"\tê³ ë ¤        \t: {row['ê³ ë ¤']}\t\t"
#         report_content += f"\të¶€ì í•©      \t: {row['ë¶€ì í•©']}\n"
#         report_content += f"\tNot Matched  \t: {row['X']}\t\t"
#         report_content += f"\tMatching Ratio\t: {(row['ì í•©']+row['ì–‘í˜¸'])/(row['ColumnCnt']):,.0%}\n"
#         report_content += "\tMatching Ratio = (ì í•© + ì–‘í˜¸) / ì»¬ëŸ¼ìˆ˜\n"
#         report_content += "-" * 100 + "\n\n"

#     # # Unicode ë¬¸ìê°€ í¬í•¨ëœ íŒŒì¼ ë¶„ì„
#     # unicode_files = df[df['HasUnicode_Cnt'] > 0]['FileName'].tolist()
#     # unicode_file_count = len(unicode_files)
    
#     # report_content += "\n[ Unicode ë¬¸ì í¬í•¨ íŒŒì¼ ë¶„ì„ ]\n\n"
#     # report_content += f"    Unicode ë¬¸ì í¬í•¨ íŒŒì¼ ìˆ˜: {unicode_file_count} ê°œ\n"
    
#     # if unicode_file_count > 0:
#     #     report_content += "\n    ëŒ€ìƒ íŒŒì¼ ëª©ë¡:\n"
#     #     for idx, file in enumerate(unicode_files, 1):
#     #         report_content += f"    {idx:2d}. {file}\n"
#     #         unicode_count = df[df['FileName'] == file]['HasUnicode_Cnt'].iloc[0]
#     #         report_content += f"       Unicode ì»¬ëŸ¼ ìˆ˜: {unicode_count} ê°œ\n"
    
#     # report_content += "\n" + "=" * 60 + "\n\n"

#     # ë³´ê³ ì„œ ì €ì¥
#     try:
#         # REPORT_FILE_Name = f'QDQM_File_Info_Report_{pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")}.txt'
#         REPORT_FILE_Name = f'QDQM_File_Info_Report.txt'
#         output_dir = os.path.join(CURRENT_DIR_PATH, 'report')
#         os.makedirs(output_dir, exist_ok=True)
        
#         report_file = os.path.join(output_dir, REPORT_FILE_Name)
        
#         with open(report_file, 'w', encoding='utf-8') as f:
#             f.write(report_content)
            
#         st.success(f"ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file}")
        
#         # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
#         with open(report_file, 'r', encoding='utf-8') as f:
#             st.download_button(
#                 label="ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
#                 data=f.read(),
#                 file_name=os.path.basename(report_file),
#                 mime="text/plain"
#             )
            
#     except Exception as e:
#         st.error(f"ë³´ê³ ì„œ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


# def generate_markdown_report(df, CURRENT_DIR_PATH, QDQM_ver):
#     if df.empty:
#         st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return

#     # ë³´ê³ ì„œ ë‚´ìš© ìƒì„±
#     report_content = f"""# Data Quality Management Report

# ## QDQM Analyzer Report v{QDQM_ver}

# - ì‘ì„±ì: QDQM Analyzer
# - ì‘ì„±ì¼ì‹œ: {pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")}

# > ë³¸ ë³´ê³ ì„œëŠ” QDQM Analyzerì— ì˜í•´ ìë™ ìƒì„±ëœ ë³´ê³ ì„œì…ë‹ˆë‹¤.  
# > ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ë¥¼ ìœ„í•œ ìë£Œë¡œ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
# > ë°ì´í„° í’ˆì§ˆê´€ë¦¬ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](https://qliksense.tistory.com/176)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

# ---

# ## Files Information

# """

#     # ê¸°ë³¸ ì •ë³´ ì¶”ê°€
#     summary = master_File_summary(df)
#     for key, value in summary.items():
#         report_content += f"- **{key}**: {value}\n"

#     # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ íŒŒì¼ ìˆ˜ ì •ë³´
#     unicode_file_count = len(df[df['UnicodeCnt'] > 0])
#     broken_kor_file_count = len(df[df['BrokenKoreanCnt'] > 0])
#     lt_lcl_file_count = len(df[df['BelowLCL'] > 0])
#     gt_ucl_file_count = len(df[df['UpperUCL'] > 0])

#     report_content += "\n### íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ë¶„ì„\n"
#     report_content += f"- Unicode ë¬¸ì í¬í•¨ íŒŒì¼ ìˆ˜: **{unicode_file_count}** ê°œ\n"
#     report_content += f"- í•œê¸€ ë¯¸ì™„ì„± ë¬¸ì í¬í•¨ íŒŒì¼ ìˆ˜: **{broken_kor_file_count}** ê°œ\n"
#     report_content += f"- Less Than LCL í¬í•¨ íŒŒì¼ ìˆ˜: **{lt_lcl_file_count}** ê°œ\n"
#     report_content += f"- Greater Than UCL í¬í•¨ íŒŒì¼ ìˆ˜: **{gt_ucl_file_count}** ê°œ\n"
    
#     report_content += f"\n> LCL, UCLì— ê´€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](https://qliksense.tistory.com/45)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.\n"

#     # íŒŒì¼ë³„ ìƒì„¸ ì •ë³´
#     report_content += "\n## Files Detail Information\n"
    
#     for _, row in df.iterrows():
#         report_content += f"\n### {row['FileName']}\n\n"
        
#         report_content += "#### ê¸°ë³¸ ì •ë³´\n"
#         report_content += f"- Columns #: {row['ColumnCnt']:,}\n"
#         report_content += f"- File Size: {row['FileSize']/1000:,.0f} KB\n"
#         report_content += f"- Row #: {row['RecordCnt']:,.0f}\n"
#         report_content += f"- Sampling #: {row['SamplingRows']:,.0f}\n"
#         report_content += f"- Unique Columns: {row['UniqueCnt']}\n"

#         report_content += "\n#### Column # by Data Type\n"
#         report_content += "| êµ¬ë¶„ | ê°œìˆ˜ | êµ¬ë¶„ | ê°œìˆ˜ |\n"
#         report_content += "|------|------|------|------|\n"
#         report_content += f"| Text Columns | {row['IsText']} | Null Columns | {row['NullCnt']} |\n"
#         report_content += f"| Numeric Columns | {row['IsNum']} | Varchar(Num) | {row['NumChar']} |\n"
#         report_content += f"| Date Columns | {row['Date']} | Varchar(Date) | {row['DateChar']} |\n"
#         report_content += f"| Varchar(Time) | {row['TimeChar']} | TimeStamp Columns | {row['TimeStamp']} |\n"

#         report_content += "\n#### Column # by Data Value\n"
#         report_content += "| êµ¬ë¶„ | ê°œìˆ˜ | êµ¬ë¶„ | ê°œìˆ˜ |\n"
#         report_content += "|------|------|------|------|\n"
#         report_content += f"| Has Alpha | {row['HasAlpha']} | Has Only Alpha | {row['HasOnlyAlpha']} |\n"
#         report_content += f"| Only Alpha&Num | {row['HasOnlyAlphaNum']} | Has Kor | {row['HasKor']} |\n"
#         report_content += f"| Has Only Kor | {row['HasOnlyKor']} | Broken Kor | {row['BrokenKoreanCnt']} |\n"
#         report_content += f"| Has Special | {row['SpecialCnt']} | Has Unicode | {row['UnicodeCnt']} |\n"
#         report_content += f"| Has Chinese | {row['ChineseCnt']} | Has Null | {row['NullCnt']} |\n"
#         report_content += f"| Has Blank | {row['HasBlank']} | Has Dash | {row['HasDash']} |\n"
#         report_content += f"| Has Dot | {row['HasDot']} | Has Bracket | {row['HasBracket']} |\n"

#         report_content += "\n#### Column # by Numeric Value & Statistics\n"
#         report_content += "| êµ¬ë¶„ | ê°œìˆ˜ | êµ¬ë¶„ | ê°œìˆ˜ |\n"
#         report_content += "|------|------|------|------|\n"
#         report_content += f"| Has Only Num | {row['HasOnlyNum']} | Has Minus | {row['HasMinus']} |\n"
#         report_content += f"| Has Float | {row['HasNum']} | Less Than LCL | {row['BelowLCL']} |\n"
#         report_content += f"| Greater Than UCL | {row['UpperUCL']} |\n"

#         report_content += "\n#### Column # by Master Matching\n"
#         report_content += "| êµ¬ë¶„ | ê°œìˆ˜ | êµ¬ë¶„ | ê°œìˆ˜ |\n"
#         report_content += "|------|------|------|------|\n"
#         report_content += f"| ì í•© | {row['ì í•©']} | ì–‘í˜¸ | {row['ì–‘í˜¸']} |\n"
#         report_content += f"| ê³ ë ¤ | {row['ê³ ë ¤']} | ë¶€ì í•© | {row['ë¶€ì í•©']} |\n"
#         report_content += f"| Not Matched | {row['X']} | Matching Ratio | {(row['ì í•©']+row['ì–‘í˜¸'])/(row['ColumnCnt']):,.0%} |\n"
        
#         report_content += "\n> Matching Ratio = (ì í•© + ì–‘í˜¸) / ì»¬ëŸ¼ìˆ˜\n"
#         report_content += "\tMatching Ratio = (ì í•© + ì–‘í˜¸) / ì»¬ëŸ¼ìˆ˜\n"
#         report_content += "\n---\n"

#     # ë³´ê³ ì„œ ì €ì¥
#     try:
#         # REPORT_FILE_Name = f'QDQM_File_Info_Report_{pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")}.md'
#         REPORT_FILE_Name = f'QDQM_File_Info_Report.md'
#         output_dir = os.path.join(CURRENT_DIR_PATH, 'report')
#         os.makedirs(output_dir, exist_ok=True)
        
#         report_file = os.path.join(output_dir, REPORT_FILE_Name)
        
#         with open(report_file, 'w', encoding='utf-8') as f:
#             f.write(report_content)
            
#         st.success(f"ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file}")
        
#         # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
#         with open(report_file, 'r', encoding='utf-8') as f:
#             st.download_button(
#                 label="ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
#                 data=f.read(),
#                 file_name=os.path.basename(report_file),
#                 mime="text/markdown"
#             )
            
#     except Exception as e:
#         st.error(f"ë³´ê³ ì„œ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")      


# def Display_Footer():
#     st.markdown("""
#     \n
# ##### íŒŒì¼ì˜ ìƒì„¸ ë¶„ì„ê²°ê³¼ëŠ” ì¢Œì¸¡ì˜ 
# <div style="
#     color: #1f77b4; 
#     font-size: 24px; 
#     font-weight: bold; 
#     display: inline-block;
#     background-color: #f0f8ff;
#     padding: 4px 8px;
#     border-radius: 4px;
#     margin: 4px 0;
# ">Files Information Detail</div>
# <span style="font-size: 24px;"> ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”.</span>
# """, unsafe_allow_html=True)          



# def generate_word_report(df, CURRENT_DIR_PATH, QDQM_ver):
#     if df.empty:
#         st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         return
        
#     try:
#         # Word ë¬¸ì„œ ìƒì„±
#         doc = Document()
        
#         # ì œëª© ì¶”ê°€
#         title = doc.add_heading('QDQM íŒŒì¼ ì •ë³´ ë¶„ì„ ë³´ê³ ì„œ', 0)
#         title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
#         # ìƒì„±ì¼ì ì¶”ê°€
#         date_paragraph = doc.add_paragraph()
#         date_run = date_paragraph.add_run(f'ìƒì„±ì¼ì: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
#         date_run.font.size = Pt(10)
#         date_run.font.color.rgb = RGBColor(128, 128, 128)
        
#         # 1. ê¸°ë³¸ í†µê³„ ì •ë³´ë¥¼ í‘œë¡œ ì‘ì„±
#         doc.add_heading('1. ê¸°ë³¸ í†µê³„ ì •ë³´', level=1)
#         summary = master_File_summary(df)
#         File = doc.add_table(rows=1, cols=2)
#         File.style = 'Table Grid'
#         header_cells = File.rows[0].cells
#         header_cells[0].text = 'í•­ëª©'
#         header_cells[1].text = 'ê°’'
        
#         for key, value in summary.items():
#             row_cells = File.add_row().cells
#             row_cells[0].text = key
#             row_cells[1].text = str(value)
        
#         doc.add_paragraph()  # ê°„ê²© ì¶”ê°€
        
#         # 2. ë°ì´í„° ìƒì„¸ ë¶„ì„
#         doc.add_heading('2. ë°ì´í„° ìƒì„¸ ë¶„ì„', level=1)
        
#         # íŒŒì¼ë³„ ìƒì„¸ ì •ë³´ë¥¼ í‘œë¡œ ì‘ì„±
#         for _, row in df.iterrows():
#             doc.add_heading(f'íŒŒì¼: {row["FileName"]}', level=2)
            
#             # ê¸°ë³¸ ì •ë³´ íŒŒì¼
#             File = doc.add_table(rows=1, cols=2)
#             File.style = 'Table Grid'
#             File.rows[0].cells[0].text = 'í•­ëª©'
#             File.rows[0].cells[1].text = 'ê°’'
            
#             # ê¸°ë³¸ ì •ë³´ ì¶”ê°€
#             basic_info = [
#                 ('Columns #', f"{row['ColumnCnt']:,}"),
#                 ('File Size', f"{row['FileSize']/1000:,.0f} KB"),
#                 ('Row #', f"{row['RecordCnt']:,.0f}"),
#                 ('Sampling #', f"{row['SamplingRows']:,.0f}"),
#                 ('Text Columns', f"{row['IsText']:,}"),
#                 ('Numeric Columns', f"{row['IsNum']:,}"),
#                 ('Date Columns', f"{row['Date']:,}"),
#                 ('Unicode Columns', f"{row['UnicodeCnt']:,}"),
#                 ('Broken Korean', f"{row['BrokenKoreanCnt']:,}"),
#                 ('Chinese Characters', f"{row['ChineseCnt']:,}"),
#                 ('Sample Rate', f"{row['SamplingRows']/row['RecordCnt']:.1%}")
#             ]
            
#             for item, value in basic_info:
#                 cells = File.add_row().cells
#                 cells[0].text = item
#                 cells[1].text = str(value)
            
#             doc.add_paragraph()  # ê°„ê²© ì¶”ê°€
            
#             # êµ¬ë¶„ì„  ì¶”ê°€
#             doc.add_paragraph('â”€' * 50)
        
#         # 3. íŠ¹ì´ì‚¬í•­ ìš”ì•½
#         doc.add_heading('3. íŠ¹ì´ì‚¬í•­ ìš”ì•½', level=1)
#         summary_File = doc.add_table(rows=1, cols=2)
#         summary_File.style = 'Table Grid'
#         summary_File.rows[0].cells[0].text = 'í•­ëª©'
#         summary_File.rows[0].cells[1].text = 'íŒŒì¼ ìˆ˜'
        
#         summary_items = [
#             ('Unicode ë¬¸ì í¬í•¨', len(df[df['UnicodeCnt'] > 0])),
#             ('í•œê¸€ ê¹¨ì§ ë¬¸ì í¬í•¨', len(df[df['BrokenKoreanCnt'] > 0])),
#             ('í•œì í¬í•¨', len(df[df['ChineseCnt'] > 0])),
#             ('NULL ê°’ í¬í•¨', len(df[df['NullCnt'] > 0])),
#             ('íŠ¹ìˆ˜ë¬¸ì í¬í•¨', len(df[df['SpecialCnt'] > 0]))
#         ]
        
#         for item, count in summary_items:
#             cells = summary_File.add_row().cells
#             cells[0].text = item
#             cells[1].text = f"{count:,} ê°œ"
        
#         # ì €ì¥
#         report_file = os.path.join(CURRENT_DIR_PATH, 'report', 'QDQM_Files_Report.docx')
#         os.makedirs(os.path.dirname(report_file), exist_ok=True)
#         doc.save(report_file)
        
#         st.success(f"Word ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file}")
        
#         # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
#         with open(report_file, 'rb') as f:
#             st.download_button(
#                 label="Word ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
#                 data=f.read(),
#                 file_name="QDQM_Files_Report.docx",
#                 mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
#             )
            
#     except Exception as e:
#         st.error(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

#---------------------------------------------------------------------------------------------------

def set_File_width(File):
    """íŒŒì¼ì˜ ëª¨ë“  ì—´ ë„ˆë¹„ë¥¼ ë™ì¼í•˜ê²Œ ì„¤ì •í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    for row in File.rows:
        for cell in row.cells:
            cell.width = Inches(10 / len(row.cells))  # A4 ê°€ë¡œ ê¸°ì¤€ ì•½ 9ì¸ì¹˜ë¥¼ ì—´ ê°œìˆ˜ë¡œ ë‚˜ëˆ”
            # ì…€ ë‚´ìš© ê°€ìš´ë° ì •ë ¬
            for paragraph in cell.paragraphs:
                paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER

    return 

def generate_data_quality_report(df, df_Column, CURRENT_DIR_PATH, QDQM_ver):
    if df.empty:
        st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    try:
        doc = Document()
        
        # í˜ì´ì§€ ì—¬ë°± ì„¤ì • (1.5 inches = 1.5 * 914400 twips)
        sections = doc.sections
        for section in sections:
            # Change from inches to centimeters (1 cm = 914400 / 2.54 twips)
            section.left_margin = int(1.5 * 914400 / 2.54)   # 1.5 cm
            section.right_margin = int(1.5 * 914400 / 2.54)  # 1.5 cm
            section.top_margin = int(2 * 914400 / 2.54)   # 2 cm
            section.bottom_margin = int(2 * 914400 / 2.54)  # 2 cm

            section.orientation = WD_ORIENT.LANDSCAPE
            section.page_width = int(297 * 914400 / 25.4)    # A4 ë„ˆë¹„ (297mm)
            section.page_height = int(210 * 914400 / 25.4)   # A4 ë†’ì´ (210mm)
        
            section = doc.sections[0]
            footer = section.footer
            paragraph = footer.paragraphs[0] if footer.paragraphs else footer.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT
            run = paragraph.add_run("QDQM Report")
            run.font.size = Pt(8)
            run.font.name = 'Arial'

        # ë°ì´í„° íƒ€ì… ë³€í™˜
        df['UnicodeCnt'] = df['UnicodeCnt'].fillna(0).astype(int)
        df['BrokenKoreanCnt'] = df['BrokenKoreanCnt'].fillna(0).astype(int)
        df['BelowLCL'] = df['BelowLCL'].fillna(0).astype(int)
        df['UpperUCL'] = df['UpperUCL'].fillna(0).astype(int)
        df['Match_Check'] = df['Match_Check'].fillna(0).astype(int)
        df['Date_Check'] = df['Date_Check'].fillna(0).astype(int)
        df['Len_Check'] = df['Len_Check'].fillna(0).astype(int)
        df['ChineseCnt'] = df['ChineseCnt'].fillna(0).astype(int)

        # ì œëª© ì¶”ê°€
        title = doc.add_heading('ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ë³´ê³ ì„œ', 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # ìƒì„±ì¼ì ì¶”ê°€
        date_paragraph = doc.add_paragraph()
        date_run = date_paragraph.add_run(f'ìƒì„±ì¼ì: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        date_run.font.size = Pt(10)
        date_run.font.color.rgb = RGBColor(128, 128, 128)
        
        # 1. ì „ì²´ í†µê³„ ì •ë³´
        doc.add_heading('1. ì „ì²´ í†µê³„ ì •ë³´', level=1)
        total_Files = len(df['FileName'].unique())
        total_Columns = df['ColumnCnt'].sum()
        total_records = df['RecordCnt'].sum()
        total_filesize = df['FileSize'].sum()
        
        # ê¸°ë³¸ í†µê³„ íŒŒì¼ ìƒì„±
        File = doc.add_table(rows=1, cols=2)
        File.style = 'Table Grid'
        header_cells = File.rows[0].cells
        header_cells[0].text = 'êµ¬   ë¶„'
        header_cells[1].text = 'ê°’'
        
        stats = [
            ('ì´ íŒŒì¼ ìˆ˜', f"{total_Files:,}ê°œ"),
            ('ì´ ì»¬ëŸ¼ ìˆ˜', f"{total_Columns:,}ê°œ"),
            ('ì´ ë ˆì½”ë“œ ìˆ˜', f"{total_records/1000:,.0f}ì²œê±´"),
            ('ì´ íŒŒì¼ í¬ê¸°', f"{total_filesize/1000000:,.0f} MB"),
        ]
        
        for key, value in stats:
            row_cells = File.add_row().cells
            row_cells[0].text = key
            row_cells[1].text = str(value)
        
        set_File_width(File)
        
        # 2. ë°ì´í„° í’ˆì§ˆ ì§€í‘œ
        doc.add_heading('2. ë°ì´í„° í’ˆì§ˆ ì§€í‘œ', level=1)
        # íŒŒì¼ í—¤ë” ìƒì„±
        File = doc.add_table(rows=1, cols=4)
        File.style = 'Table Grid'
        header_cells = File.rows[0].cells
        header_cells[0].text = 'ì ê²€ í•­ëª©'
        header_cells[1].text = 'íŒŒì¼ ìˆ˜'
        header_cells[2].text = 'íŒŒì¼ ë¹„ìœ¨(%)'
        header_cells[3].text = 'ì»¬ëŸ¼ ìˆ˜'
        
        # ì ê²€ í•­ëª©ë³„ í†µê³„
        quality_checks = {
            'ìœ ë‹ˆì½”ë“œ': ('UnicodeCnt', df['UnicodeCnt'] > 0),
            'ë¯¸ì™„ì„±í•œê¸€': ('BrokenKoreanCnt', df['BrokenKoreanCnt'] > 0),
            'í•˜í•œì„ ë¯¸ë§Œ': ('BelowLCL', df['BelowLCL'] > 0),
            'ìƒí•œì„ ì´ˆê³¼': ('UpperUCL', df['UpperUCL'] > 0),
            'ì°¸ì¡°ë¬´ê²°ì„±': ('Match_Check', df['Match_Check'] > 0),
            'ì¼ìì ê²€': ('Date_Check', df['Date_Check'] > 0),
            'ê¸¸ì´ì ê²€': ('Len_Check', df['Len_Check'] > 0),
            'í•œìë¬¸ì': ('ChineseCnt', df['ChineseCnt'] > 0)
        }
        
        for check_name, (count_col, condition) in quality_checks.items():
            affected_Files = len(df[condition])
            affected_Columns = df[count_col].sum()
            File_percentage = (affected_Files / total_Files * 100) if total_Files > 0 else 0
            row_cells = File.add_row().cells
            row_cells[0].text = check_name
            row_cells[1].text = f"{affected_Files:,}ê°œ"
            row_cells[2].text = f"{File_percentage:.1f}%"
            row_cells[3].text = f"{affected_Columns:,}ê°œ"
        
        set_File_width(File)
        
        # 3. ì£¼ì˜ ëŒ€ìƒ íŒŒì¼ ëª©ë¡
        doc.add_heading('3. íŒŒì¼ ëª©ë¡', level=1)
        warning_condition = ((df['UnicodeCnt'] > 0) | 
                           (df['BrokenKoreanCnt'] > 0) |
                           (df['BelowLCL'] > 0) |
                           (df['UpperUCL'] > 0) |
                           (df['Match_Check'] > 0) |
                           (df['Date_Check'] > 0) |
                           (df['Len_Check'] > 0))
        
        warning_Files = df[warning_condition]
        
        if not warning_Files.empty:
            File = doc.add_table(rows=1, cols=10)
            File.style = 'Table Grid'
            
            # í—¤ë” ì„¤ì •
            headers = ['íŒŒì¼ëª…', 'ì»¬ëŸ¼ìˆ˜', 'ìœ ë‹ˆì½”ë“œ', 'ë¯¸ì™„ì„±í•œê¸€', 'í•˜í•œì„ ë¯¸ë§Œ', 'ìƒí•œì„ ì´ìƒ', 
                'ì°¸ì¡°ë¬´ê²°ì„±', 'ì¼ìì ê²€', 'ê¸¸ì´ì ê²€', 'ì ê²€']
            for i, header in enumerate(headers):
                File.rows[0].cells[i].text = header
            
            # ë°ì´í„° ì¶”ê°€
            for _, row in warning_Files.iterrows():
                row_cells = File.add_row().cells
                row_cells[0].text = str(row['FileName'])
                row_cells[1].text = f"{int(row['ColumnCnt']):,}"
                row_cells[2].text = f"âš ï¸({int(row['UnicodeCnt'])})" if row['UnicodeCnt'] > 0 else ''
                row_cells[3].text = f"âš ï¸({int(row['BrokenKoreanCnt'])})" if row['BrokenKoreanCnt'] > 0 else ''
                row_cells[4].text = f"âš ï¸({int(row['BelowLCL'])})" if row['BelowLCL'] > 0 else ''
                row_cells[5].text = f"âš ï¸({int(row['UpperUCL'])})" if row['UpperUCL'] > 0 else ''
                row_cells[6].text = f"âš ï¸({int(row['Match_Check'])})" if row['Match_Check'] > 0 else ''
                row_cells[7].text = f"âš ï¸({int(row['Date_Check'])})" if row['Date_Check'] > 0 else ''
                row_cells[8].text = f"âš ï¸({int(row['Len_Check'])})" if row['Len_Check'] > 0 else ''
                row_cells[9].text = 'ğŸš¨' if (row['Match_Check'] > 0 or 
                                            row['Date_Check'] > 0 or 
                                            # row['Len_Check'] > 0 or 
                                            row['BrokenKoreanCnt'] > 0 or 
                                            row['UnicodeCnt'] > 0 or 
                                            row['BelowLCL'] > 0 or 
                                            row['UpperUCL'] > 0) else ''
            
            set_File_width(File)
        else:
            doc.add_paragraph('ì ê²€ ëŒ€ìƒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')

        doc.add_page_break()

        # 6. ì»¬ëŸ¼ë³„ ìƒì„¸ ì ê²€ ë¦¬ìŠ¤íŠ¸
        doc.add_heading('4. ì»¬ëŸ¼ë³„ ìƒì„¸ ë¦¬ìŠ¤íŠ¸', level=1)
        date_run.font.size = Pt(10)

        #----------------------------------------------------------------------------
        # FileNameìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ìˆœí™˜
        page_cnt = 0
        for file in df_Column['FileName'].unique():
            page_cnt += 1
            # ê° íŒŒì¼ì— ëŒ€í•œ ë°ì´í„° í•„í„°ë§
            file_data = df_Column[df_Column['FileName'] == file]  
            doc.add_heading(f'4.{page_cnt} [ {file} ] ì ê²€ í•­ëª©ë³„ ì»¬ëŸ¼ìˆ˜', level=2)

            # Filter data for the specific file
            file_data = df_Column[df_Column['FileName'] == file].copy()

            file_data['ì ê²€'] = ''
            file_data.loc[(file_data['UnicodeCnt'] > 0) 
                | (file_data['BrokenKoreanCnt'] > 0)
                | (file_data['BelowLCL'] > 0)
                | (file_data['UpperUCL'] > 0)
                | (file_data['Match_Check'] > 0)
                | (file_data['Date_Check'] > 0)
                # | (file_data['Len_Check'] > 0)
                , 'ì ê²€'] = 'ğŸš¨'  # ì „ì²´ ì ê²€

            file_data['Null(%)'] = file_data['Null(%)'].fillna(0).astype(float)
            file_data['Match_Total'] = file_data['Match_Total'].fillna(0).astype(int)
            file_data['Match_Good'] = file_data['Match_Good'].fillna(0).astype(int)
            file_data['Match_Check'] = file_data['Match_Check'].fillna(0).astype(int)
            file_data['Date_Check'] = file_data['Date_Check'].fillna(0).astype(int)
            file_data['Len_Check'] = file_data['Len_Check'].fillna(0).astype(int)
            file_data['UniqueCnt'] = file_data['UniqueCnt'].fillna(0).astype(int)
            file_data['NullCnt'] = file_data['NullCnt'].fillna(0).astype(int)
            file_data['LenMax'] = file_data['LenMax'].fillna(0).astype(int)
            file_data['ChineseCnt'] = file_data['ChineseCnt'].fillna(0).astype(int)
            file_data['SpecialCnt'] = file_data['SpecialCnt'].fillna(0).astype(int)
            file_data['ValueCnt'] = file_data['ValueCnt'].fillna(0).astype(int)
            file_data['Matched'] = file_data['Matched'].fillna(0).astype(int)


            # Create a summary of integrity issues
            integrity_summary = {
                'ì»¬ëŸ¼ / í–‰ ìˆ˜': [int(file_data['No'].max()), 
                            f"{int(file_data['RecordCnt'].max()):,}",
                         'ì´ ì»¬ëŸ¼ ë° í–‰ ìˆ˜'],
                'Unique ì»¬ëŸ¼': [
                    len(file_data[file_data['Unique(%)'] == 100]) if not file_data.empty else '',
                    ' ',
                    'ë°ì´í„°ê°€ ìœ ë‹ˆí¬í•œ ê°’ì„ ê°–ëŠ” ì»¬ëŸ¼ ìˆ˜' 
                ],        
                'NULLì»¬ëŸ¼': [
                    len(file_data[file_data['Null(%)'] == 100]) if not file_data.empty else '',
                    f"{len(file_data[file_data['Null(%)'] == 100])/int(file_data['No'].max()):.1%}" if not file_data.empty else '',
                    'ì „ì²´ ê°’ì´ NULLì¸ ì»¬ëŸ¼ ìˆ˜'
                ],
                'NULL > 50%': [
                    len(file_data[(file_data['Null(%)'] > 50) & (file_data['Null(%)'] < 100)]) if not file_data.empty else '',
                    f"{len(file_data[(file_data['Null(%)'] > 50) & (file_data['Null(%)'] < 100)])/int(file_data['No'].max()):.1%}" if not file_data.empty else '',
                    'NULL ê°’ì´ 50% ì´ˆê³¼ì¸ ì»¬ëŸ¼ ìˆ˜ (Null ì»¬ëŸ¼ëŠ” ì œì™¸)'
                ],
                'ì ê²€ì»¬ëŸ¼': [
                    len(file_data[file_data['ì ê²€'] == 'ğŸš¨']),
                    f"{len(file_data[file_data['ì ê²€'] == 'ğŸš¨'])/int(file_data['No'].max()):.1%}" if not file_data.empty else '',
                    'ìœ ë‹ˆì½”ë“œ, ë¯¸ì™„ì„±í•œê¸€, í•˜í•œì„ ë¯¸ë§Œ, ìƒí•œì„ ì´ˆê³¼, ì°¸ì¡°ë¬´ê²°ì„±, ì¼ìì ê²€, ê¸¸ì´ì ê²€ ì¤‘ ì ê²€ëŒ€ìƒ'
                ],
                'ìœ ë‹ˆì½”ë“œ': [
                    len(file_data[file_data['UnicodeCnt'] > 0]) if not file_data.empty else '',
                    f"{int(file_data['UnicodeCnt'].sum())}",
                    'ìœ ë‹ˆì½”ë“œë¥¼ í¬í•¨í•œ ì»¬ëŸ¼ ìˆ˜ ë° í–‰ ìˆ˜'
                ],
                'ë¯¸ì™„ì„±í•œê¸€': [
                    len(file_data[file_data['BrokenKoreanCnt'] > 0]) if not file_data.empty else '',
                    f"{int(file_data['BrokenKoreanCnt'].sum())}",
                    'ë¯¸ì™„ì„±í•œê¸€ì„ í¬í•¨í•œ ì»¬ëŸ¼ ìˆ˜ ë° í–‰ ìˆ˜'
                ],
                'í•˜í•œì„ ë¯¸ë§Œ': [
                    len(file_data[file_data['BelowLCL'] > 0]) if not file_data.empty else '',
                    f"{int(file_data['BelowLCL'].sum())}",
                    'í•˜í•œì„ ë¯¸ë§Œ ê°’ì„ í¬í•¨í•œ ì»¬ëŸ¼ ìˆ˜'
                ],
                'ìƒí•œì„ ì´ìƒ': [
                    len(file_data[file_data['UpperUCL'] > 0]) if not file_data.empty else '',
                    f"{int(file_data['UpperUCL'].sum())}",
                    'ìƒí•œì„ ì´ˆê³¼ ê°’ì„ í¬í•¨í•œ ì»¬ëŸ¼ ìˆ˜'
                ],
                'ë§ˆìŠ¤í„°ì°¸ì¡°': [
                    len(file_data[file_data['Match_Total'] > 0]) if not file_data.empty else '',
                    f"{int(file_data['Match_Total'].sum()) / int(file_data['No'].max()):.1%}",
                    'ë§ˆìŠ¤í„° ì½”ë“œë¥¼ ì°¸ì¡°í•˜ëŠ” ì»¬ëŸ¼ ìˆ˜ ë° ì°¸ì¡°ìœ¨(ë§ˆìŠ¤í„°ì°¸ì¡°/ì»¬ëŸ¼ìˆ˜)' 
                ],
                'ì°¸ì¡°ì í•©ë„': [
                    len(file_data[file_data['Match_Good'] > 0]) if not file_data.empty else '',
                    f"{int(file_data['Match_Good'].sum()) / int(file_data['Match_Total'].sum()):.1%}",
                    'ë§ˆìŠ¤í„° ì½”ë“œ ì°¸ì¡°ê°€ ì í•©í•œ ì»¬ëŸ¼ ìˆ˜ ë° ì í•©ìœ¨(ë§ˆìŠ¤í„°ì°¸ì¡°ì í•©ì»¬ëŸ¼/ë§ˆìŠ¤í„°ì°¸ì¡°)'
                ],
                'ì°¸ì¡°ë¬´ê²°ì„±': [
                    len(file_data[file_data['Match_Check'] > 0]) if not file_data.empty else '',
                    f"{int(file_data[file_data['Match_Check'] > 0]['ValueCnt'].sum() - file_data[file_data['Match_Check'] > 0]['Matched'].sum()):,}",
                    'ì°¸ì¡°ë¬´ê²°ì„± ì ê²€ ëŒ€ìƒ ì»¬ëŸ¼ ë° í–‰ ìˆ˜(ê²€ì‚¬í•  ì»¬ëŸ¼ì˜ ê°’ì´ ë§ˆìŠ¤í„°ì— ì—†ëŠ” ì»¬ëŸ¼ ìˆ˜)'
                ],
                'ì¼ìì ê²€': [
                    len(file_data[file_data['Date_Check'] > 0]) if not file_data.empty else '',
                    f"{int(file_data[file_data['Date_Check'] > 0]['ValueCnt'].sum() - file_data[file_data['Date_Check'] > 0]['Matched'].sum()):,}",
                    'ì¼ì(ë¬¸ì)í˜•ìœ¼ë¡œ ì§€ì •ëœ ì»¬ëŸ¼ì—ì„œ ê°’ì´ ì ê²€ ëŒ€ìƒì¸ ì»¬ëŸ¼ ìˆ˜ ë° í–‰ ìˆ˜ (ex:20240231)'
                ],
                'ê¸¸ì´ì ê²€': [
                    int(file_data['Len_Check'].sum() if not file_data.empty else 0),
                    '',
                    'ê¸¸ì´ì ê²€ ëŒ€ìƒ ì»¬ëŸ¼ ìˆ˜ (ìµœëŒ€ ê¸¸ì´ > ê¸¸ì´ ìµœë¹ˆê°’ * 2) '
                ],
                'í•œìë¬¸ì': [
                    len(file_data[file_data['ChineseCnt'] > 0]) if not file_data.empty else '',
                    f"{int(file_data['ChineseCnt'].sum()):,}",
                    'í•œì ë¬¸ìë¥¼ í¬í•¨í•œ ì»¬ëŸ¼ ìˆ˜ ë° í–‰ ìˆ˜'
                ],
                'íŠ¹ìˆ˜ë¬¸ì': [
                    len(file_data[file_data['SpecialCnt'] > 0]) if not file_data.empty else '',
                    f"{int(file_data['SpecialCnt'].sum()):,}",
                    'íŠ¹ìˆ˜ë¬¸ìë¥¼ í¬í•¨í•œ ì»¬ëŸ¼ ìˆ˜ ë° í–‰ ìˆ˜'
                ],
                'ìˆ«ì & Null í¬í•¨': [
                    len(file_data[(file_data['NullCnt'] > 0) & (file_data['DataType'] != 'object')]) if not file_data.empty else '',
                    '', 
                    'ë°ì´í„° íƒ€ì…ì´ ìˆ«ìì´ë©´ì„œ NULLì´ ìˆëŠ” ì»¬ëŸ¼ ìˆ˜'
                ],
                'ë‹¨ì¼ê°’ì»¬ëŸ¼': [
                    len(file_data[file_data['UniqueCnt'] == 1]) if not file_data.empty else '',
                    '', 
                    'ë‹¨ì¼ê°’ë§Œ ê°–ê³ ìˆëŠ” ì»¬ëŸ¼ ìˆ˜'
                ],
                'ìµœëŒ€ê¸¸ì´ > 200': [
                    len(file_data[file_data['LenMax'] > 200]) if not file_data.empty else '',
                    '', 
                    'ë°ì´í„°ì˜ ê¸¸ì´ê°€ 200 Byte ì´ìƒì¸ ì»¬ëŸ¼ ìˆ˜'
                ],
            }

            # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì»¬ëŸ¼ëª… ì„¤ì •
            summary_df = pd.DataFrame(integrity_summary).transpose()
            summary_df.columns = ['ì»¬ëŸ¼ ìˆ˜', 'í–‰ ìˆ˜ or (%)', 'ì„¤ëª…']  # ì»¬ëŸ¼ëª… ì§ì ‘ ì§€ì •

            # Word ë¬¸ì„œì— íŒŒì¼ ì¶”ê°€ (í•˜ë‚˜ì˜ íŒŒì¼ë§Œ ìƒì„±)
            File = doc.add_table(rows=len(integrity_summary)+1, cols=4)
            File.style = 'Table Grid'

            # í—¤ë” ì¶”ê°€
            headers = ['ì ê²€ í•­ëª©', 'ì»¬ëŸ¼ ìˆ˜', 'í–‰ ìˆ˜ or (%)', 'ì„¤ëª…']
            for i, header in enumerate(headers):
                cell = File.rows[0].cells[i]
                cell.text = header
                cell.paragraphs[0].runs[0].font.bold = True
                cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER

            # ë°ì´í„° ì¶”ê°€
            for idx, (key, values) in enumerate(integrity_summary.items(), start=1):
                cells = File.rows[idx].cells
                cells[0].text = key
                cells[1].text = str(values[0])
                cells[2].text = str(values[1])
                cells[3].text = str(values[2])
                
                # ì…€ ì •ë ¬
                cells[0].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.LEFT
                cells[1].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
                cells[2].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
                cells[3].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.LEFT

            # íŒŒì¼ ìƒì„± í›„ ì—´ ë„ˆë¹„ ì¡°ì •
            for i, column in enumerate(File.columns):
                for cell in column.cells:
                    # ì—´ ë„ˆë¹„ ì„¤ì •
                    if i == 0:  # ì²« ë²ˆì§¸ ì—´
                        cell.width = Inches(1.5)
                    elif i == 3:  # ë„¤ ë²ˆì§¸ ì—´
                        cell.width = Inches(6.5)
                    else:  # ë‚˜ë¨¸ì§€ ì—´
                        cell.width = Inches(1)
                        
                    # ì…€ì˜ ë‹¨ë½ ì •ë ¬ ì„¤ì •
                    for paragraph in cell.paragraphs:
                        if i == 0 or i == 3:  # ì²« ë²ˆì§¸ì™€ ë„¤ ë²ˆì§¸ ì—´
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                        else:  # ë‚˜ë¨¸ì§€ ì—´
                            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER


            # íŒŒì¼ ìŠ¤íƒ€ì¼ë§
            for row in File.rows:
                for cell in row.cells:
                    cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
                    for paragraph in cell.paragraphs:
                        for run in paragraph.runs:
                            run.font.size = Pt(10)

            doc.add_page_break()
            doc.add_heading(f'4.{page_cnt} [ {file} ] íŒŒì¼ ì»¬ëŸ¼ë³„ ìƒì„¸ë¦¬ìŠ¤íŠ¸', level=2)
            # ìƒì„¸ ì ê²€ íŒŒì¼ ìƒì„±
            File = doc.add_table(rows=1, cols=10)  # í—¤ë” ì„¤ì •í•œ ì—´ ìˆ˜ ë§Œí¼ ì§€ì • 
            File.style = 'Table Grid'
            
            # í—¤ë” ì„¤ì •
            headers = ['ì»¬ëŸ¼ëª…', 'ë°ì´í„°ê±´ìˆ˜', 'ìœ ë‹ˆì½”ë“œ', 'ë¯¸ì™„ì„±í•œê¸€', 'í•˜í•œì„ ë¯¸ë§Œ', 'ìƒí•œì„ ì´ˆê³¼'
                       , 'ì°¸ì¡°ë¬´ê²°ì„±', 'ì¼ìì ê²€', 'ê¸¸ì´ì ê²€', 'ë§ˆìŠ¤í„°']
            try:
                for i, header in enumerate(headers):
                    cell = File.rows[0].cells[i]
                    try:
                        cell.text = header
                        cell.paragraphs[0].runs[0].font.bold = True
                        cell.paragraphs[0].runs[0].font.size = Pt(9)  
                        cell.paragraphs[0].alignment = (WD_ALIGN_PARAGRAPH.LEFT if i == 0 
                                                      else WD_ALIGN_PARAGRAPH.CENTER)
                    except IndexError:
                        st.error(f"íŒŒì¼ í—¤ë” '{header}' ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

            # ... existing code ...

            # íŒŒì¼ ìƒì„± í›„ ì—´ ë„ˆë¹„ ì¡°ì •
            for i, column in enumerate(File.columns):
                for cell in column.cells:
                    # ì²« ë²ˆì§¸ ì—´ì€ 2ë°° ë„ˆë¹„, ë‚˜ë¨¸ì§€ ì—´ì€ ë™ì¼ ë„ˆë¹„
                    if i == 0:
                        cell.width = Inches(1.5)  # ì²« ë²ˆì§¸ ì—´ 2ë°° ë„ˆë¹„
                    else:
                        cell.width = Inches(0.5)  # ë‚˜ë¨¸ì§€ ì—´ ê¸°ë³¸ ë„ˆë¹„
            
            # ë°ì´í„° í–‰ ì¶”ê°€
            for _, row in file_data.iterrows():
                row_cells = File.add_row().cells
                
                # ê° ì—´ì— ë°ì´í„° ì¶”ê°€
                row_cells[0].text = str(row['ColumnName'])
                row_cells[1].text = f"{int(row['ValueCnt']):,}"
                row_cells[2].text = f"âš ï¸({int(row['UnicodeCnt'])})" if row['UnicodeCnt'] > 0 else ''
                row_cells[3].text = f"âš ï¸({int(row['BrokenKoreanCnt'])})" if row['BrokenKoreanCnt'] > 0 else ''
                row_cells[4].text = f"âš ï¸({int(row['BelowLCL'])})" if row['BelowLCL'] > 0 else ''
                row_cells[5].text = f"âš ï¸({int(row['UpperUCL'])})" if row['UpperUCL'] > 0 else ''
                row_cells[6].text = f"âš ï¸({int(row['ValueCnt']-row['Matched'])})" if row['Match_Check'] > 0 else ''
                row_cells[7].text = f"âš ï¸({int(row['ValueCnt']-row['Matched'])})" if row['Date_Check'] > 0 else ''
                row_cells[8].text = f"âš ï¸" if row['Len_Check'] > 0 else ''
                row_cells[9].text = str(row['Master']) if pd.notna(row['Master']) else 'None'

                # ì…€ ê°€ìš´ë° ì •ë ¬
                for idx, cell in enumerate(row_cells):
                    paragraph = cell.paragraphs[0]
                    # ê¸°ì¡´ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥
                    text = paragraph.text
                    # ê¸°ì¡´ runs ì‚­ì œ
                    for run in paragraph.runs:
                        run._element.getparent().remove(run._element)
                    # ìƒˆë¡œìš´ run ìƒì„± ë° ìŠ¤íƒ€ì¼ ì ìš©
                    run = paragraph.add_run(text)
                    run.font.size = Pt(9)
                    
                    # ì •ë ¬ ì„¤ì •
                    if idx == 0:  # ì²« ë²ˆì§¸ ì—´
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                    else:  # ë‚˜ë¨¸ì§€ ì—´
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
                    idx += 1

           
            # íŒŒì¼ ê°„ êµ¬ë¶„ì„ ìœ„í•œ í˜ì´ì§€ ë‚˜ëˆ„ê¸° ì¶”ê°€
            if file != df_Column['FileName'].unique()[-1]:  # ë§ˆì§€ë§‰ íŒŒì¼ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ í˜ì´ì§€ ë‚˜ëˆ„ê¸°
                doc.add_page_break()

        # ì €ì¥
        report_file = os.path.join(CURRENT_DIR_PATH, 'report', 'QDQM_DataQuality_Report.docx')
        os.makedirs(os.path.dirname(report_file), exist_ok=True)
        doc.save(report_file)
            
        st.success(f"Word ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file}")
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
        with open(report_file, 'rb') as f:
            st.download_button(
                label="ë°ì´í„° í’ˆì§ˆ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                data=f.read(),
                file_name="QDQM_DataQuality_Report.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
            
    except Exception as e:
        st.error(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def generate_Column_integrity_report(df_Column, CURRENT_DIR_PATH, QDQM_ver):
    doc = Document()
    
    # ë¬¸ì„œë¥¼ ê°€ë¡œ ë°©í–¥ìœ¼ë¡œ ì„¤ì •
    section = doc.sections[0]
    section.orientation = WD_ORIENTATION.LANDSCAPE
    section.page_width = Mm(297)  # A4 ê°€ë¡œ ê¸¸ì´
    section.page_height = Mm(210)  # A4 ì„¸ë¡œ ê¸¸ì´
    
    # ì œëª© ì¶”ê°€
    doc.add_heading('ì»¬ëŸ¼ë³„ ìƒì„¸ ì ê²€ ë¦¬ìŠ¤íŠ¸', level=1)
    
    # íŒŒì¼ ìƒì„±
    File = doc.add_table(rows=1, cols=9)
    File.style = 'Table Grid'
    
    # í—¤ë” ì„¤ì •
    headers = ['íŒŒì¼ëª…', 'ì»¬ëŸ¼ëª…', 'ìœ ë‹ˆì½”ë“œ', 'ë¯¸ì™„ì„±í•œê¸€', 'í•˜í•œì„ ë¯¸ë§Œ', 'ìƒí•œì„ ì´ˆê³¼', 'ë§ˆìŠ¤í„°ì ê²€', 'ì¼ìì ê²€', 'ê¸¸ì´ì ê²€']
    for i, header in enumerate(headers):
        cell = File.rows[0].cells[i]
        cell.text = header
        # í—¤ë” ìŠ¤íƒ€ì¼ ì„¤ì •
        cell.paragraphs[0].runs[0].font.bold = True
        cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # ë°ì´í„° í–‰ ì¶”ê°€
    for _, row in df_Column.iterrows():
        row_cells = File.add_row().cells
        
        # ê° ì—´ì— ë°ì´í„° ì¶”ê°€
        row_cells[0].text = str(row['FileName'])
        row_cells[1].text = str(row['ColumnName'])
        row_cells[2].text = f"âš ï¸({int(row['UnicodeCnt'])})" if row['UnicodeCnt'] > 0 else ''
        row_cells[3].text = f"âš ï¸({int(row['BrokenKoreanCnt'])})" if row['BrokenKoreanCnt'] > 0 else ''
        row_cells[4].text = f"âš ï¸({int(row['BelowLCL'])})" if row['BelowLCL'] > 0 else ''
        row_cells[5].text = f"âš ï¸({int(row['UpperUCL'])})" if row['UpperUCL'] > 0 else ''
        row_cells[6].text = f"âš ï¸({int(row['Match_Check'])})" if row['Match_Check'] > 0 else ''
        row_cells[7].text = f"âš ï¸({int(row['Date_Check'])})" if row['Date_Check'] > 0 else ''
        row_cells[8].text = f"âš ï¸({int(row['Len_Check'])})" if row['Len_Check'] > 0 else ''
        
        # ì…€ ê°€ìš´ë° ì •ë ¬
        for cell in row_cells:
            cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # íŒŒì¼ ë„ˆë¹„ ì¡°ì •
    File.allow_autofit = True
    for column in File.columns:
        for cell in column.cells:
            cell.width = Inches(1.0)
    
    # ë¬¸ì„œ ì €ì¥
        # ì €ì¥
    report_file = os.path.join(CURRENT_DIR_PATH, 'report', 'QDQM_DataQuality_Report_Detail.docx')
    os.makedirs(os.path.dirname(report_file), exist_ok=True)
    doc.save(report_file)
    
    st.success(f"Word ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file}")
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
    with open(report_file, 'rb') as f:
        st.download_button(
            label="ë°ì´í„° í’ˆì§ˆ ìƒì„¸ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
            data=f.read(),
            file_name="QDQM_DataQuality_Report_Detail.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )    


