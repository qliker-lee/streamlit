# -*- coding: utf-8 -*-
"""
ğŸ“˜ ğŸ”— ë°ì´í„° ê´€ê³„ (ERD) ì‹œê°í™” (CodeMapping_relationship.csv ê¸°ë°˜)
2025.12.17 Qliker
ì´ˆê¸° import ì‹œ ê²½ë¡œì„¤ì •, streamlit warnings ì–µì œ ì„¤ì • ìˆœì„œ ì¤‘ìš”
"""
# -------------------------------------------------------------------
# 1. ê²½ë¡œ ì„¤ì • (Streamlit warnings import ì „ì— í•„ìš”)
# -------------------------------------------------------------------
import sys
from pathlib import Path

CURRENT_DIR = Path(__file__).resolve()
PROJECT_ROOT = CURRENT_DIR.parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

# -------------------------------------------------------------------
# 2. Streamlit ê²½ê³  ì–µì œ ì„¤ì • (Streamlit import ì „ì— í˜¸ì¶œ)
# -------------------------------------------------------------------
from DataSense.util.streamlit_warnings import setup_streamlit_warnings
setup_streamlit_warnings()

# -------------------------------------------------------------------
# 3. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
# -------------------------------------------------------------------
# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
from collections import defaultdict
from datetime import datetime

# ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st
import pandas as pd
import graphviz
import streamlit.components.v1 as components
from PIL import Image

#----------------------------------------------------------------------------
# 4. ë¡œì»¬ ëª¨ë“ˆ import
#----------------------------------------------------------------------------
from DataSense.util.Files_FunctionV20 import load_yaml_datasense, set_page_config

from DataSense.util.Display import (
    create_metric_card,
    display_kpi_metrics     # df, colors, title
)

APP_NAME = "Developing 2"
APP_KOR_NAME = "ê°œë°œ 2"
APP_TITLE = "ğŸ”— ë°ì´í„° ê´€ê³„ (ERD) ë¶„ì„"
APP_DESCRIPTION = "ë°ì´í„° ê°’ì— ì˜í•œ ë…¼ë¦¬ì  ERDë¥¼ ìƒì„±í•©ë‹ˆë‹¤. CodeMapping ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤."
# -------------------------------------------------------------------
# ìƒìˆ˜ ì„¤ì •
# -------------------------------------------------------------------
MAPPING_FILE = "CodeMapping_relationship.csv"
MAPPING_ORG_FILE = "CodeMapping.csv"
OUTPUT_DIR = PROJECT_ROOT / 'DataSense' / 'DS_Output'

set_page_config(APP_NAME)

MAX_RELATED_TABLE_COUNT = 100
#----------------------------------------------------------------------------
# 5. í•¨ìˆ˜ ì •ì˜
#----------------------------------------------------------------------------
def parse_relationship(relationship_str):
    """Level_Relationship ë¬¸ìì—´ì—ì„œ ëª¨ë“  ê´€ê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not isinstance(relationship_str, str) or '->' not in relationship_str:
        return []
    
    segments = relationship_str.split(' -> ')
    relationships = []
    
    for i in range(len(segments) - 1):
        parent_segment = segments[i].strip()
        child_segment = segments[i+1].strip()
        
        try:
            # íŒŒì¼ëª…ê³¼ ì»¬ëŸ¼ëª… ë¶„ë¦¬ (ë§ˆì§€ë§‰ '.' ê¸°ì¤€)
            parent_file, parent_col = parent_segment.rsplit('.', 1)
            child_file, child_col = child_segment.rsplit('.', 1)
            
            # Level_Relationship ìˆœì„œë¥¼ ë°˜ëŒ€ë¡œ í•´ì„í•˜ì—¬ FK ê´€ê³„ ìƒì„±
            relationships.append({
                'Child_Table': child_file,
                'Child_Column': child_col,
                'Parent_Table': parent_file,
                'Parent_Column': parent_col
            })
            
        except ValueError:
            continue
            
    return relationships

def _extract_and_load_erd_data_impl(input_file_path: Path):
    """ì›ë³¸ íŒŒì¼ì„ ë¡œë“œí•˜ê³  ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        df_raw = pd.read_csv(input_file_path, encoding='utf-8-sig') # CodeMapping_relationship.csv ë¡œë“œ
    except Exception as e:
        st.error(f"ì›ë³¸ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None, None

    required_columns = ['FileName', 'ColumnName', 'PK']
    missing_columns = [col for col in required_columns if col not in df_raw.columns]
    if missing_columns:
        st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}")
        return None, None, None

    if 'Level_Relationship' not in df_raw.columns:
        st.warning("âš ï¸ 'Level_Relationship' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. FK ê´€ê³„ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        df_raw['Level_Relationship'] = ''

    # --- 2. ERD ì •ë³´ ì¶”ì¶œ ë©”ì¸ ë¡œì§ ---
    tables_data = {}
    df_raw = df_raw.fillna('')

    # 2.1. ëª¨ë“  í…Œì´ë¸” ë° ì»¬ëŸ¼ ì •ë³´ ì¶”ì¶œ (ë²¡í„°í™”ëœ ì—°ì‚° ì‚¬ìš©)
    df_raw['FileName'] = df_raw['FileName'].astype(str).str.strip()
    df_raw['ColumnName'] = df_raw['ColumnName'].astype(str).str.strip()
    df_valid = df_raw[(df_raw['FileName'] != '') & (df_raw['ColumnName'] != '')].copy()
    
    for file_name, group in df_valid.groupby('FileName'):
        if file_name not in tables_data:
            tables_data[file_name] = defaultdict(lambda: {'PK': '', 'FK': '', 'Parent_Table': ''})
        
        for _, row in group.iterrows():
            col_name = row['ColumnName']
            pk_status = 'PK' if str(row.get('PK', '')).strip() == '1' else ''
            tables_data[file_name][col_name]['PK'] = pk_status

    # 2.2. ê´€ê³„ ì •ë³´ ì¶”ì¶œ ë° FK ì—…ë°ì´íŠ¸ (í•„í„°ë§ëœ ë°ì´í„°ë§Œ ì²˜ë¦¬)
    all_relationships = []
    df_with_rel = df_valid[df_valid.get('Level_Relationship', '').astype(str).str.strip() != ''].copy()
    
    for _, row in df_with_rel.iterrows():
        rel_str = str(row.get('Level_Relationship', '')).strip()
        parsed_rels = parse_relationship(rel_str)
        
        for rel in parsed_rels:
            all_relationships.append(rel)
            
            child_table = str(rel['Child_Table']).strip()
            child_col = str(rel['Child_Column']).strip()
            parent_table = str(rel['Parent_Table']).strip()
            
            if not child_table or not child_col or not parent_table:
                continue
            
            if child_table in tables_data and child_col in tables_data[child_table]:
                tables_data[child_table][child_col]['FK'] = 'FK'
                
                current_parents = str(tables_data[child_table][child_col]['Parent_Table']).strip()
                if current_parents:
                    parent_list = [p.strip() for p in current_parents.split(',') if p.strip()]
                    if parent_table not in parent_list:
                        parent_list.append(parent_table)
                        tables_data[child_table][child_col]['Parent_Table'] = ', '.join(parent_list)
                else:
                    tables_data[child_table][child_col]['Parent_Table'] = parent_table


    # 2.3. ìµœì¢… í†µí•© DataFrame ìƒì„± (ë²¡í„°í™”ëœ ì—°ì‚° ì‚¬ìš©)
    df_raw['FileName'] = df_raw['FileName'].astype(str).str.strip()
    df_raw['ColumnName'] = df_raw['ColumnName'].astype(str).str.strip()
    df_raw = df_raw[(df_raw['FileName'] != '') & (df_raw['ColumnName'] != '')]
    
    # Level_Depth ì²˜ë¦¬
    if 'Level_Depth' in df_raw.columns:
        df_raw['Level_Depth'] = pd.to_numeric(df_raw['Level_Depth'], errors='coerce').fillna(0).astype(int)
    else:
        df_raw['Level_Depth'] = 0
    
    # FilePath ì²˜ë¦¬
    if 'FilePath' in df_raw.columns:
        df_raw['FilePath'] = df_raw['FilePath'].astype(str).str.strip()
    else:
        df_raw['FilePath'] = ''
    
    # Level_Relationship ì²˜ë¦¬
    if 'Level_Relationship' in df_raw.columns:
        df_raw['Level_Relationship'] = df_raw['Level_Relationship'].astype(str).str.strip()
    else:
        df_raw['Level_Relationship'] = ''
    
    # tables_dataì™€ ë³‘í•©í•˜ì—¬ PK/FK ì •ë³´ ì¶”ê°€
    erd_data_list = []
    for _, row in df_raw.iterrows():
        file_name = row['FileName']
        col_name = row['ColumnName']
        
        if file_name in tables_data and col_name in tables_data[file_name]:
            info = tables_data[file_name][col_name]
            erd_data_list.append({
                'FileName': file_name,
                'ColumnName': col_name,
                'PK': 1 if info['PK'] == 'PK' else 0,
                'FK': 1 if info['FK'] == 'FK' else 0,
                'Parent_Table': str(info['Parent_Table']).strip(),
                'Level_Relationship': row['Level_Relationship'],
                'Level_Depth': int(row['Level_Depth']),
                'FilePath': row['FilePath']
            })
    
    if not erd_data_list:
        st.error("ERD ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ íŒŒì¼ì˜ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None, None, None
    
    df_erd_attributes = pd.DataFrame(erd_data_list)

    unique_relationships = {}
    for rel in all_relationships:
        key = (rel['Child_Table'], rel['Parent_Table'])
        
        if key not in unique_relationships:
            unique_relationships[key] = {
                'Child Table': rel['Child_Table'],
                'Parent Table': rel['Parent_Table'],
                'FK Columns': set(),
                'PK Columns': set()
            }
        
        unique_relationships[key]['FK Columns'].add(rel['Child_Column'])
        unique_relationships[key]['PK Columns'].add(rel['Parent_Column'])

    df_erd_relationships = pd.DataFrame([
        {
            'Child Table': rel['Child Table'],
            'Parent Table': rel['Parent Table'],
            'FK Columns': ', '.join(sorted(rel['FK Columns'])),
            'PK Columns': ', '.join(sorted(rel['PK Columns']))
        }
        for rel in unique_relationships.values()
    ])
    
    pk_map = df_erd_attributes[df_erd_attributes['PK'] == 1].groupby('FileName')['ColumnName'].apply(
        lambda x: list(x.astype(str))
    ).to_dict()
    
    return pk_map, df_erd_relationships, df_erd_attributes

try:
    from streamlit.runtime.scriptrunner.script_run_context import get_script_run_ctx
    if get_script_run_ctx(suppress_warning=True) is not None:
        extract_and_load_erd_data = st.cache_data(_extract_and_load_erd_data_impl)
    else:
        extract_and_load_erd_data = _extract_and_load_erd_data_impl
except:
    extract_and_load_erd_data = _extract_and_load_erd_data_impl

def _extract_relationships_from_erd_logic(selected_tables: list, all_tables: set, it_df: pd.DataFrame):
    """
    generate_erd_graphì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ê´€ê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ë°˜í™˜: relationships_list = [(from_file, from_col, to_file, to_col), ...]
    """
    relationships_list = []
    
    if 'Level_Relationship' not in it_df.columns:
        return relationships_list
    
    # selected_tablesê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì „ì²´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬
    if selected_tables is None:
        selected_tables = []
    use_all_data = (len(selected_tables) == 0)
    
    # ì„ íƒëœ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
    selected_table_columns = {}
    if not use_all_data:
        selected_df = it_df[it_df['FileName'].isin(selected_tables)]
        for table_name, group in selected_df.groupby('FileName'):
            selected_table_columns[table_name] = set(group['ColumnName'].dropna().astype(str).str.strip())
    
    # Level_Relationshipì´ ìˆëŠ” í–‰ë§Œ í•„í„°ë§
    df_with_rel = it_df[
        (it_df['Level_Relationship'].notna()) & 
        (it_df['Level_Relationship'].astype(str).str.strip() != '')
    ].copy()
    
    # all_tablesê°€ Noneì´ê±°ë‚˜ ë¹ˆ setì¸ ê²½ìš° ëª¨ë“  í…Œì´ë¸” í—ˆìš©
    if all_tables is None:
        all_tables = set()
    use_all_tables = (len(all_tables) == 0)
    
    for _, row in df_with_rel.iterrows():
        file_name = str(row['FileName']).strip()
        col_name = str(row['ColumnName']).strip()
        rel_str = str(row['Level_Relationship']).strip()
        
        is_selected_column = False
        if not use_all_data:
            is_selected_column = (file_name in selected_tables and 
                                 col_name in selected_table_columns.get(file_name, set()))
        
        segments = rel_str.split(' -> ')
        parsed_segments = []
        for segment in segments:
            segment = segment.strip()
            if not segment:
                continue
            try:
                file_part, col_part = segment.rsplit('.', 1)
                parsed_segments.append((file_part.strip(), col_part.strip()))
            except ValueError:
                continue
        
        # ì „ì²´ ë°ì´í„° ëª¨ë“œì´ê±°ë‚˜ ì„ íƒëœ ì»¬ëŸ¼/í…Œì´ë¸”ì´ í¬í•¨ëœ ê²½ìš°
        should_process = use_all_data or is_selected_column or any(seg_file in selected_tables for seg_file, _ in parsed_segments)
        
        if should_process:
            for i in range(len(parsed_segments) - 1):
                from_file, from_col = parsed_segments[i]
                to_file, to_col = parsed_segments[i+1]
                
                # all_tables í•„í„°ë§ (ì „ì²´ ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ)
                if not use_all_tables:
                    if from_file not in all_tables or to_file not in all_tables:
                        continue
                
                relationships_list.append((from_file, from_col, to_file, to_col))
                
                if is_selected_column and i == 0 and file_name != from_file:
                    if use_all_tables or (file_name in all_tables and from_file in all_tables):
                        relationships_list.append((file_name, col_name, from_file, from_col))
    
    return relationships_list

def _extract_edge_groups_from_relationships(it_df: pd.DataFrame, selected_tables: list = None, all_tables: set = None):
    """Level_Relationshipì—ì„œ ì—£ì§€ ê·¸ë£¹ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ERDì™€ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©."""
    if selected_tables is None:
        selected_tables = []
    if all_tables is None:
        all_tables = set()
    
    # ERDì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ê´€ê³„ ì¶”ì¶œ
    relationships_list = _extract_relationships_from_erd_logic(selected_tables, all_tables, it_df)
    
    # ì—£ì§€ ê·¸ë£¹ìœ¼ë¡œ ì§‘ê³„ (ERDì™€ ë™ì¼í•˜ê²Œ all_tables í•„í„°ë§)
    edge_groups = {}  # {(from_file, to_file): set()}
    edge_groups_by_file = {}  # {file_name: set of (from_file, to_file)}
    
    for from_file, from_col, to_file, to_col in relationships_list:
        # ERDì™€ ë™ì¼í•˜ê²Œ all_tables í•„í„°ë§
        if all_tables and (from_file not in all_tables or to_file not in all_tables):
            continue
            
        key = (from_file, to_file)
        if key not in edge_groups:
            edge_groups[key] = set()
        edge_groups[key].add((from_col, to_col))
        
        # ê° íŒŒì¼ë³„ë¡œ ì—£ì§€ ê·¸ë£¹ ìˆ˜ì§‘
        if from_file not in edge_groups_by_file:
            edge_groups_by_file[from_file] = set()
        edge_groups_by_file[from_file].add(key)
        
        if to_file not in edge_groups_by_file:
            edge_groups_by_file[to_file] = set()
        edge_groups_by_file[to_file].add(key)
    
    return edge_groups_by_file

def export_summary_result(integrated_df: pd.DataFrame, selected_tables: list = None, all_tables: set = None):
    """FileName ê¸°ì¤€ìœ¼ë¡œ ì§‘ê³„í•˜ì—¬ ìš”ì•½ ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # ERDì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ì—£ì§€ ê·¸ë£¹ ì¶”ì¶œ
    edge_groups_by_file = _extract_edge_groups_from_relationships(integrated_df, selected_tables, all_tables)
    
    grouped = integrated_df.groupby('FileName', sort=False)
    
    summary_df = grouped.agg({
        'FilePath': 'first',
        'ColumnName': 'nunique',
        'Level_Depth': lambda x: int(x.max()) if x.notna().any() else 0
    }).reset_index()
    
    summary_df.columns = ['FileName', 'FilePath', 'Column #', 'Max_Level']
    
    # Rel Table #: ERDì— ê·¸ë ¤ì§€ëŠ” ì—£ì§€ ê·¸ë£¹ ê°œìˆ˜ (ë™ì¼í•œ ê¸°ì¤€)
    summary_df['Rel Table #'] = summary_df['FileName'].apply(
        lambda x: len(edge_groups_by_file.get(str(x).strip(), set()))
    )
    
    summary_df = summary_df.sort_values(by='FileName')
    return summary_df

#----------------------------------------------------------------------------
def export_summary_result_new(integrated_df: pd.DataFrame):
    """
    FileName ê¸°ì¤€ìœ¼ë¡œ ì§‘ê³„í•˜ì—¬ ìš”ì•½ ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. (Level Rel Table # ê³„ì‚° ì¶”ê°€)
    """
    
    # Level_Relationship ë¬¸ìì—´ì—ì„œ ëª¨ë“  ê³ ìœ  íŒŒì¼ ì´ë¦„ì„ ì¶”ì¶œí•˜ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
    def extract_unique_files_from_chain(relationship_str):
        if not isinstance(relationship_str, str) or not relationship_str.strip():
            return set()
        files = set()
        segments = relationship_str.split(' -> ')
        for segment in segments:
            segment = segment.strip()
            if not segment: continue
            try:
                # FileName.Columnì—ì„œ FileNameë§Œ ì¶”ì¶œ
                file_part, _ = segment.rsplit('.', 1)
                files.add(file_part.strip())
            except ValueError:
                continue
        return files

    # 1. íŒŒì¼ë³„ ê¸°ë³¸ í†µê³„ ê³„ì‚° (Column #, FilePath, Max_Level_Depth)
    def get_max_level_depth(series):
        if 'Level_Depth' not in integrated_df.columns: return 0
        non_na = series.dropna()
        if non_na.empty: return 0
        try:
            return int(pd.to_numeric(non_na, errors='coerce').max())
        except (ValueError, TypeError):
            return 0

    table_stats = integrated_df.groupby('FileName').agg(
        {'ColumnName': 'nunique',
         'FilePath': lambda x: x.iloc[0] if not x.empty and 'FilePath' in integrated_df.columns else '',
         'Level_Depth': get_max_level_depth}
    ).reset_index()
    table_stats.rename(columns={'ColumnName': 'Column #', 'Level_Depth': 'Max_Level'}, inplace=True)
    
    
    # 2. Level_Relationship ê¸°ë°˜ ì´ ê´€ë ¨ íŒŒì¼ ê°œìˆ˜ ê³„ì‚° (â˜…â˜…â˜… ì‚¬ìš©ì ìš”ì²­ ì§€í‘œ ìµœì í™” â˜…â˜…â˜…)
    temp_df = integrated_df[integrated_df['Level_Relationship'].astype(bool)].copy()
    # Level_Relationship ë¬¸ìì—´ì— í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ê° í–‰ì˜ ê³ ìœ  ê´€ë ¨ íŒŒì¼ ëª©ë¡ì„ ì¶”ì¶œ
    temp_df['Related_Files'] = temp_df['Level_Relationship'].apply(extract_unique_files_from_chain)
    
    # FileNameë³„ë¡œ Related_Files setì„ unioní•˜ì—¬ ì´ ê³ ìœ  íŒŒì¼ ê°œìˆ˜ ê³„ì‚°
    total_rel_files_map = temp_df.groupby('FileName')['Related_Files'].apply(
        lambda x: len(set.union(*x)) if x.any() else 0
    ).to_dict()

    # 4. ê²°ê³¼ DataFrameì— ë³‘í•©
    summary_df = table_stats.copy()

    # **ì‚¬ìš©ì ìš”ì²­ í•„ë“œ ì¶”ê°€**
    summary_df['Rel Table #'] = summary_df['FileName'].apply(
        lambda x: total_rel_files_map.get(x, 0)
    )
    
    summary_df = summary_df.sort_values(by='FileName').fillna(0)
    
    return summary_df

def get_related_tables(selected_tables: list, it_df: pd.DataFrame):
    """ì„ íƒëœ í…Œì´ë¸”ê³¼ ê´€ë ¨ëœ ëª¨ë“  í…Œì´ë¸”ì„ ì°¾ìŠµë‹ˆë‹¤."""
    if it_df is None or 'Level_Relationship' not in it_df.columns:
        return set(selected_tables)
    
    # ì„ íƒëœ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘ (ë²¡í„°í™”ëœ ì—°ì‚°)
    selected_table_columns = {}
    selected_df = it_df[it_df['FileName'].isin(selected_tables)]
    for table_name, group in selected_df.groupby('FileName'):
        selected_table_columns[table_name] = set(group['ColumnName'].dropna().astype(str).str.strip())
    
    # Level_Relationshipì´ ìˆëŠ” í–‰ë§Œ í•„í„°ë§
    df_with_rel = it_df[
        (it_df['Level_Relationship'].notna()) & 
        (it_df['Level_Relationship'].astype(str).str.strip() != '')
    ].copy()
    
    all_relations = []
    for _, row in df_with_rel.iterrows():
        file_name = str(row['FileName']).strip()
        col_name = str(row['ColumnName']).strip()
        rel_str = str(row['Level_Relationship']).strip()
        
        is_selected_column = (file_name in selected_tables and 
                             col_name in selected_table_columns.get(file_name, set()))
        
        segments = rel_str.split(' -> ')
        parsed_segments = []
        for segment in segments:
            segment = segment.strip()
            if not segment:
                continue
            try:
                file_part, _ = segment.rsplit('.', 1)
                parsed_segments.append((file_part.strip(), ''))
            except ValueError:
                continue
        
        if is_selected_column or any(seg_file in selected_tables for seg_file, _ in parsed_segments):
            for i in range(len(parsed_segments) - 1):
                from_file, _ = parsed_segments[i]
                to_file, _ = parsed_segments[i+1]
                all_relations.append((from_file, to_file))
                
                if is_selected_column and i == 0 and file_name != from_file:
                    all_relations.append((file_name, from_file))
    
    related_tables = set(selected_tables)
    tables_to_check = set(selected_tables)
    
    for _ in range(5):
        newly_added = set()
        for from_table, to_table in all_relations:
            if from_table in tables_to_check:
                newly_added.add(to_table)
            if to_table in tables_to_check:
                newly_added.add(from_table)
        
        if not newly_added:
            break
        
        newly_added -= related_tables
        related_tables.update(newly_added)
        tables_to_check = newly_added
    
    return related_tables

def generate_erd_graph(selected_tables: list, all_tables: set, pk_map: dict, it_df: pd.DataFrame):
    """Graphviz ê°ì²´ë¥¼ ìƒì„±í•˜ê³  ERD ê´€ê³„ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""

    table_count = len(all_tables)
    graph_size = max(20, min(20 + table_count * 3, 150))
    
    dot = graphviz.Digraph(comment='Dynamic ERD', engine='dot', graph_attr={
        'rankdir': 'LR', 
        'splines': 'curved', 
        'concentrate': 'true',
        'nodesep': '0.25',
        'ranksep': '1',
        'size': f'{graph_size},{graph_size}'
    })
    dot.attr('node', shape='none', fontname='Malgun Gothic', fontsize='10')
    dot.attr('edge', fontname='Malgun Gothic', fontsize='10', penwidth='1.0')
    
    # ERDì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ê´€ê³„ ì¶”ì¶œ
    relationships_list = _extract_relationships_from_erd_logic(selected_tables, all_tables, it_df)
    # ì—°ê²°ëœ ì»¬ëŸ¼ ìˆ˜ì§‘
    connected_columns = {}
    for from_file, from_col, to_file, to_col in relationships_list:
        if from_file not in connected_columns:
            connected_columns[from_file] = set()
        connected_columns[from_file].add(from_col)
        
        if to_file not in connected_columns:
            connected_columns[to_file] = set()
        connected_columns[to_file].add(to_col)
    
    # 2. ê° í…Œì´ë¸”ë³„ë¡œ í‘œì‹œí•  ì»¬ëŸ¼ ê²°ì •
    display_columns = {}
    for table_name in all_tables:
        pk_cols_ordered = pk_map.get(table_name, [])
        pk_cols_set = set(pk_cols_ordered)
        connected_cols = connected_columns.get(table_name, set())
        pk_to_display = [col for col in pk_cols_ordered if col in connected_cols]
        other_to_display = sorted(list(connected_cols - pk_cols_set))
        display_columns[table_name] = pk_to_display + other_to_display

    # 3. í…Œì´ë¸” ë…¸ë“œ ìƒì„±
    def escape_html(text):
        return text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
    
    for table_name in sorted(all_tables):
        pk_cols_ordered = pk_map.get(table_name, [])
        pk_cols_set = set(pk_cols_ordered)
        table_cols = display_columns.get(table_name, [])
        
        is_selected = table_name in selected_tables
        title_bgcolor = '#FFA500' if is_selected else '#FFF8DC'
        
        table_label = f'<<TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0">'
        table_label += f'<TR><TD COLSPAN="2" PORT="title" BGCOLOR="{title_bgcolor}"><B>{escape_html(table_name)}</B></TD></TR>'
        
        pk_to_display = [col for col in table_cols if col in pk_cols_set]
        other_to_display = [col for col in table_cols if col not in pk_cols_set]
        
        for col in pk_to_display:
            safe_col = escape_html(col)
            table_label += f'<TR><TD ALIGN="LEFT" BGCOLOR="#E6E6FA" PORT="{safe_col}"><B>ğŸ”‘ {safe_col}</B></TD></TR>'
        
        for col in other_to_display:
            safe_col = escape_html(col)
            table_label += f'<TR><TD ALIGN="LEFT" PORT="{safe_col}"><B>ğŸ”— {safe_col}</B></TD></TR>'
        
        table_label += '</TABLE>>'
        dot.node(table_name, table_label, shape='none')

    # 4. FK ê´€ê³„ (Edge) ì¶”ê°€
    edge_groups = {}
    for from_file, from_col, to_file, to_col in relationships_list:
        key = (from_file, to_file)
        if key not in edge_groups:
            edge_groups[key] = []
        edge_groups[key].append((from_col, to_col))
    
    edge_count = 0
    for (from_file, to_file), cols_list in edge_groups.items():
        if from_file not in all_tables or to_file not in all_tables:
            continue
        
        from_col, to_col = cols_list[0]
        safe_from_col = escape_html(from_col)
        safe_to_col = escape_html(to_col)
        
        dot.edge(f'{from_file}:{safe_from_col}', 
                f'{to_file}:{safe_to_col}',
                dir='both',
                arrowtail='crow',
                arrowhead='none',
                constraint='true')
        edge_count += 1
    
    return dot, edge_count

def create_erd_result_dataframe(selected_tables: list, all_tables: set, pk_map: dict, it_df: pd.DataFrame):
    """ERD ìƒì„± ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤. ERDì™€ ë™ì¼í•œ í•„í„°ë§ ë¡œì§ ì‚¬ìš©."""
    # ERDì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ê´€ê³„ ì¶”ì¶œ
    relationships_list = _extract_relationships_from_erd_logic(selected_tables, all_tables, it_df)
    
    # ì—£ì§€ ê·¸ë£¹ìœ¼ë¡œ ì§‘ê³„ (ERDì™€ ë™ì¼)
    edge_groups = {}  # {(from_file, to_file): list of (from_col, to_col)}
    from_edge_groups = {}  # {table_name: set of (from_file, to_file)}
    to_edge_groups = {}  # {table_name: set of (from_file, to_file)}
    
    for from_file, from_col, to_file, to_col in relationships_list:
        # ERDì™€ ë™ì¼í•˜ê²Œ all_tables í•„í„°ë§
        if from_file not in all_tables or to_file not in all_tables:
            continue
            
        key = (from_file, to_file)
        if key not in edge_groups:
            edge_groups[key] = []
        edge_groups[key].append((from_col, to_col))
        
        # From ê´€ê³„ (ì´ í…Œì´ë¸”ì´ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”)
        if from_file not in from_edge_groups:
            from_edge_groups[from_file] = set()
        from_edge_groups[from_file].add(key)
        
        # To ê´€ê³„ (ì´ í…Œì´ë¸”ì„ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”)
        if to_file not in to_edge_groups:
            to_edge_groups[to_file] = set()
        to_edge_groups[to_file].add(key)
    
    # ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
    from_relations = {}  # {table_name: [(col, to_table, to_col), ...]}
    to_relations = {}  # {table_name: [(from_table, from_col, col), ...]}
    
    for from_file, from_col, to_file, to_col in relationships_list:
        if from_file not in from_relations:
            from_relations[from_file] = []
        from_relations[from_file].append((from_col, to_file, to_col))
        
        if to_file not in to_relations:
            to_relations[to_file] = []
        to_relations[to_file].append((from_file, from_col, to_col))
    
    result_data = []
    for table_name in sorted(all_tables):
        is_selected = table_name in selected_tables
        pk_cols_ordered = pk_map.get(table_name, [])
        pk_cols_str = ', '.join(pk_cols_ordered) if pk_cols_ordered else ''
        
        all_fk_cols = set()
        parent_tables_set = set()
        child_tables_set = set()
        
        if table_name in from_relations:
            for from_col, to_table, _ in from_relations[table_name]:
                all_fk_cols.add(from_col)
                if to_table:
                    parent_tables_set.add(to_table)
        
        if table_name in to_relations:
            for from_table, _, to_col in to_relations[table_name]:
                all_fk_cols.add(to_col)
                if from_table:
                    child_tables_set.add(from_table)
        
        # ê´€ê³„ ìˆ˜: ERDì™€ ë™ì¼í•˜ê²Œ ì—£ì§€ ê·¸ë£¹ ê°œìˆ˜ë¡œ ê³„ì‚°
        from_edge_count = len(from_edge_groups.get(table_name, set()))
        to_edge_count = len(to_edge_groups.get(table_name, set()))
        
        result_data.append({
            'í…Œì´ë¸”ëª…': table_name,
            'ì„ íƒì—¬ë¶€': 'âœ“' if is_selected else '',
            'PK ì»¬ëŸ¼': pk_cols_str,
            'FK ì»¬ëŸ¼': ', '.join(sorted(all_fk_cols)) if all_fk_cols else '',
            'Parent í…Œì´ë¸”': ', '.join(sorted(parent_tables_set)) if parent_tables_set else '',
            'Child í…Œì´ë¸”': ', '.join(sorted(child_tables_set)) if child_tables_set else '',
            'ê´€ê³„ ìˆ˜': from_edge_count + to_edge_count
        })
    
    return pd.DataFrame(result_data)

#-----------------------------------------------------------------------------------------
# Master KPI 
def Display_File_Statistics(filestats_df):
    """ Master Statistics KPIs """
    # def calculate_master_type_counts(df):
    #     """Code Typeë³„ íŒŒì¼ ìˆ˜ ê³„ì‚°"""
    #     if 'MasterType' not in df.columns or 'FileName' not in df.columns:
    #         return {}
    #     try:
    #         master_type_counts = df.groupby('MasterType')['FileName'].nunique()
    #         expected_types = ['Master', 'Operation', 'Attribute', 'Common', 'Reference', 'Validation']
            
    #         result = {}
    #         for master_type in expected_types:
    #             count = master_type_counts.get(master_type, 0)
    #             result[master_type] = f"{count:,}"
    #         return result
    #     except Exception as e:
    #         st.error(f"MasterType ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    #         return {}

    df = filestats_df.copy()
    df = df[(df['MasterType'] != 'Common') & (df['MasterType'] != 'Reference') & (df['MasterType'] != 'Validation')]
    
    # KPI ê³„ì‚°
    total_files = len(df['FileName'].unique()) if 'FileName' in df.columns else 0
    total_records = df['RecordCnt'].sum() if 'RecordCnt' in df.columns else 0
    total_filesize = df['FileSize'].sum() if 'FileSize' in df.columns else 0
    total_master_types = len(df['MasterType'].unique()) if 'MasterType' in df.columns else 0
    work_date = df['WorkDate'].max() if 'WorkDate' in df.columns else ''

    if total_records < 1000:
        total_records_unit = 'ê±´'
    else:
        total_records = total_records / 10000
        total_records_unit = 'ë§Œê±´'

    if total_filesize < 1000:
        total_filesize = total_filesize 
        total_filesize_unit = 'Bytes'
    elif total_filesize < 1000000:
        total_filesize = total_filesize / 1000
        total_filesize_unit = 'KB'
    elif total_filesize < 1000000000:
        total_filesize = total_filesize / 1000000
        total_filesize_unit = 'MB'
    else:
        total_filesize = total_filesize / 1000000000
        total_filesize_unit = 'GB'        

    summary = {
        "Code File #": f"{total_files:,}",
        "Total Record #": f"{total_records:,.0f} {total_records_unit}",
        "Total File Size": f"{total_filesize:,.0f} {total_filesize_unit}",
        # "Code Type #": f"{total_master_types:,}",
        "Work Date": f"{work_date}"
    }

    # ê° ë©”íŠ¸ë¦­ì— ëŒ€í•œ ìƒ‰ìƒ ì •ì˜
    metric_colors = {
        "Code File #":      "#1f77b4",
        "Total Record #":   "#2ca02c", 
        "Total File Size":  "#ff7f0e",
        "Work Date":        "#9467bd"     # ë³´ë¼ìƒ‰
    }

    # ë©”íŠ¸ë¦­ í‘œì‹œ
    display_kpi_metrics(summary, metric_colors, 'File Statistics')


    return True
#---------------------------------------------------------------------------
def load_data_mapping():
    """ 
    1st Step: ë°ì´í„° ì¶”ì¶œ ë° ë¡œë“œ
    """
    mapping_file_path = OUTPUT_DIR / MAPPING_FILE
    
    if not mapping_file_path.exists():
        st.error(f"âš ï¸ ì›ë³¸ íŒŒì¼ '{MAPPING_FILE}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None

    # 1. ë°ì´í„° ì¶”ì¶œ ë° ë¡œë“œ
    with st.spinner(f"'{MAPPING_FILE}' íŒŒì¼ì—ì„œ ê´€ê³„ ì •ë³´ ì¶”ì¶œ ì¤‘..."):
        pk_map, fk_df, it_df = extract_and_load_erd_data(mapping_file_path)
    
    if pk_map is None or fk_df is None or it_df is None:
        st.error("ERD ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ íŒŒì¼ì˜ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None, None, None

    return pk_map, fk_df, it_df

def load_data_org():
    """ 
    1.1st Step: CodeMapping.csv ê¸°ë°˜ ë°ì´í„° ì¶”ì¶œ ë° ë¡œë“œ
    """
    try:
        file_path = OUTPUT_DIR / MAPPING_ORG_FILE
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        return df
    except Exception as e:  
        st.error(f"ì›ë³¸ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def load_data_filestats():
    """ 
    1.2nd Step: filestats.csv ê¸°ë°˜ ë°ì´í„° ì¶”ì¶œ ë° ë¡œë“œ
    """
    try:
        file_path = OUTPUT_DIR / "FileStats.csv"
        df = pd.read_csv(file_path, encoding='utf-8-sig')
    except Exception as e:  
        st.error(f"ì›ë³¸ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

    return df

def select_tables(it_df, it_org_df) -> list:
    """ 
    2nd Step: í…Œì´ë¸” ì„ íƒ
    """
    st.subheader("1. í…Œì´ë¸” ì„ íƒ")
    #-----------------------------------------------
    # CodeMapping.csv ê¸°ë°˜ ë°ì´í„° ê°€ê³µ ë° ë³‘í•©
    #-----------------------------------------------
    it_org_cols = ['FileName', 'ColumnName', 'FilePath', 'Attribute', 'ValueCnt', 'Unique(%)', 
    'Format', 'Format(%)', 'CodeColumn_1', 'Matched(%)_1', 'CodeColumn_2', 'Matched(%)_2',
        'CodeColumn_3', 'Matched(%)_3',
    ]
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    available_cols = [col for col in it_org_cols if col in it_org_df.columns]
    if not available_cols:
        st.warning("CodeMapping.csvì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    it_org_df = it_org_df[available_cols].copy()
    
    # ìˆ«ì ì»¬ëŸ¼ê³¼ ë¬¸ìì—´ ì»¬ëŸ¼ì„ êµ¬ë¶„í•˜ì—¬ fillna ì ìš©
    numeric_cols = ['ValueCnt', 'Unique(%)', 'Format(%)', 'Matched(%)_1', 'Matched(%)_2', 'Matched(%)_3']
    string_cols = ['FileName', 'ColumnName', 'FilePath', 'Attribute', 'Format', 'CodeColumn_1', 'CodeColumn_2', 'CodeColumn_3']
    
    # ì¡´ì¬í•˜ëŠ” ìˆ«ì ì»¬ëŸ¼ì—ë§Œ fillna(0) ì ìš©
    numeric_cols_exist = [col for col in numeric_cols if col in it_org_df.columns]
    if numeric_cols_exist:
        it_org_df[numeric_cols_exist] = it_org_df[numeric_cols_exist].fillna(0)
    
    # ì¡´ì¬í•˜ëŠ” ë¬¸ìì—´ ì»¬ëŸ¼ì—ë§Œ fillna('') ì ìš©
    string_cols_exist = [col for col in string_cols if col in it_org_df.columns]
    if string_cols_exist:
        it_org_df[string_cols_exist] = it_org_df[string_cols_exist].fillna('')
    
    merged_df = pd.merge(it_df, it_org_df, on=['FileName', 'ColumnName', 'FilePath'], how='left')

    #-----------------------------------------------
    all_tables = sorted(list(merged_df['FileName'].unique()))

    # ì´ˆê¸° ìš”ì•½ ì •ë³´ ìƒì„± (ì„ íƒ ì „ì´ë¯€ë¡œ ì „ì²´ ë°ì´í„° ê¸°ì¤€, selected_tables=None)
    summary_df = export_summary_result_new(it_df)

    pk_cols = merged_df[merged_df['PK'] == 1].groupby('FileName')['ColumnName'].apply(
        lambda x: ', '.join([str(item) for item in x if pd.notna(item) and str(item).strip()])
    ).reset_index()
    pk_cols.columns = ['FileName', 'PK Columns']
    it_sum_df = pk_cols

    edited_df = pd.merge(it_sum_df, summary_df,  on='FileName', how='left')
    edited_df = edited_df[(edited_df['Column #'] > 1)]
    edited_df = edited_df.sort_values(by='FileName')

    # ì„ íƒ ì²´í¬ë°•ìŠ¤ ì»¬ëŸ¼ ì¶”ê°€ (ê¸°ë³¸ê°’ False)
    if 'ì„ íƒ' not in edited_df.columns:
        edited_df['ì„ íƒ'] = False
    
    # cols_order = ['ì„ íƒ'] + [col for col in edited_df.columns if col != 'ì„ íƒ']
    cols_order = ['ì„ íƒ','FileName', 'PK Columns', 'Column #', 'Max_Level', 'Rel Table #', 'FilePath']
    edited_df = edited_df[cols_order]
    
    edited_df = st.data_editor(edited_df, hide_index=True, width=1000, height=500, column_config={
        'ì„ íƒ': st.column_config.CheckboxColumn('ì„ íƒ', width='small'),
        'FileName': st.column_config.TextColumn(help='íŒŒì¼ ì´ë¦„', width=150),
        'PK Columns': st.column_config.TextColumn(help='PK ì»¬ëŸ¼', width=150),
        'Column #': st.column_config.NumberColumn(help='ì»¬ëŸ¼ ìˆ˜', width=100),
        'Max_Level': st.column_config.NumberColumn(help='ìµœëŒ€ ë ˆë²¨', width=100),
        'Rel Table #': st.column_config.NumberColumn(help='ì—£ì§€ ê·¸ë£¹ ê°œìˆ˜', width=100),
        'FilePath': st.column_config.TextColumn(help='íŒŒì¼ ê²½ë¡œ', width='large')
    })

    # ì„ íƒëœ í…Œì´ë¸” ì¶”ì¶œ (ì„ íƒ ì»¬ëŸ¼ì´ Trueì¸ í–‰ì˜ FileName)
    selected_tables = edited_df[edited_df['ì„ íƒ'] == True]['FileName'].tolist()
    selected_tables = [t for t in selected_tables if t in all_tables]
    
    if not selected_tables:
        st.info(f"ìµœëŒ€ related_tables ìˆ˜ëŠ” í•©ê³„ {MAX_RELATED_TABLE_COUNT}ê°œê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        return None

    return selected_tables

def generate_erd(selected_tables, pk_map, it_df):
    """ 
    3rd Step: Logical ERD ìƒì„±
    """
    
    st.subheader("2. Logical ERD ë¶„ì„ ê²°ê³¼")
    related_tables = get_related_tables(selected_tables, it_df)

    related_table_count = len(related_tables) # ì—°ê²°ëœ í…Œì´ë¸” ìˆ˜    

    st.caption(f"**ì„ íƒëœ í…Œì´ë¸”:** {selected_tables}")
    st.caption(f"**ì—°ê²°ëœ ì´ í…Œì´ë¸” ìˆ˜:** {related_table_count}ê°œ")
    
    if related_table_count > MAX_RELATED_TABLE_COUNT:
        st.error(f"ì—°ê²°ëœ í…Œì´ë¸” ìˆ˜ê°€ {MAX_RELATED_TABLE_COUNT}ê°œë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
        return False

    # # Graphviz ì„¤ì¹˜ í™•ì¸
    # try:
    #     import graphviz
    #     # Graphviz ì‹¤í–‰ íŒŒì¼ í™•ì¸
    #     try:
    #         graphviz.version()
    #     except Exception:
    #         st.info("""
    #         **ERD ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.**
    #         Cloud í™˜ê²½ì—ì„œëŠ” Graphviz ì„¤ì¹˜ê°€ ì œí•œë  ìˆ˜ ìˆì–´ì„œ ERD ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
    #         ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”. 
            
    #         **ì˜ˆì œ ERDë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.**
    #         """)
    #         image = Image.open(OUTPUT_DIR / "DataSense_Logical_COMPANY.png")
    #         st.image(image, caption="ë‹¨ìˆœí•œ ì˜ˆì œ ERD", width=480)
    #         st.divider()
    #         image = Image.open(OUTPUT_DIR / "DataSense_Logical_ERD_ë³µì¡í•œì˜ˆ.png")
    #         st.image(image, caption="ë³µì¡í•œ ì˜ˆì œ ERD", width=480)
    #         return False
    # except ImportError:
    #     st.error("âŒ Graphviz ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    #     return False

    try:
        graph, erd_edge_count = generate_erd_graph(selected_tables, related_tables, pk_map, it_df)
        
        if graph is None:
            st.error("âŒ ERD ê·¸ë˜í”„ ê°ì²´ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        file_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        png_filename = f"DataSense_Logical_ERD_{file_time}.png"
        png_filepath = OUTPUT_DIR / png_filename
       
        # PNG ì €ì¥ ì‹œë„
        png_success = False
        actual_png_filepath = None
        try:
            graph.attr(dpi='300')
            erd_path = png_filepath.with_suffix('')
            graph.render(str(erd_path), format='png', cleanup=True)
            actual_png_filepath = OUTPUT_DIR / f"{erd_path.name}.png"
            
            if actual_png_filepath.exists():
                png_success = True
                st.caption(f"ğŸ“ ì €ì¥ ê²½ë¡œ: `{actual_png_filepath}`")
            else:
                st.warning("âš ï¸ PNG íŒŒì¼ì´ ìƒì„±ë˜ì—ˆì§€ë§Œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            error_msg = str(e)
            if 'ExecutableNotFound' in error_msg or 'not found' in error_msg.lower():
                st.error("âŒ Graphviz ì‹¤í–‰ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.info("""
                **ERD ìƒì„± ì‹¤íŒ¨:**
                
                Streamlit Cloud í™˜ê²½ì—ì„œëŠ” Graphviz ì‹¤í–‰ íŒŒì¼ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                
                **ëŒ€ì•ˆ:**
                - SVG í˜•ì‹ìœ¼ë¡œ ERDë¥¼ í‘œì‹œí•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤.
                """)
            else:
                st.warning(f"âš ï¸ PNG íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {error_msg}")
        
        # PNG íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ ê²½ìš°
        if png_success and actual_png_filepath:
            try:
                with open(actual_png_filepath, 'rb') as f:
                    png_data = f.read()
                if png_data:
                    st.download_button(
                        label="ğŸ“¥ PNG íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=png_data,
                        file_name=actual_png_filepath.name,
                        mime="image/png"
                    )

                image = Image.open(actual_png_filepath)
                caption = f"ERD: {', '.join(selected_tables[:5])}{'...' if len(selected_tables) > 5 else ''}"
                st.image(image, caption=caption, width=1000)
                return related_tables
            except Exception as e:
                st.warning(f"âš ï¸ PNG ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # PNG ì‹¤íŒ¨ ì‹œ SVGë¡œ ëŒ€ì²´ ì‹œë„
        try:
            st.info("ğŸ”„ SVG í˜•ì‹ìœ¼ë¡œ ERDë¥¼ í‘œì‹œí•©ë‹ˆë‹¤...")
            svg_data = graph.pipe(format='svg').decode('utf-8')
            if svg_data and len(svg_data) > 0:
                components.html(svg_data, height=800, scrolling=True)
                st.success("âœ… ERDê°€ SVG í˜•ì‹ìœ¼ë¡œ í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return related_tables
            else:
                st.error("âŒ SVG ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return False
        except Exception as e:
            error_msg = str(e)
            st.error(f"âŒ ERD ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {error_msg}")
            st.info("""
            **ERD ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•œ ìƒí™©ì…ë‹ˆë‹¤.**
            
            **ê°€ëŠ¥í•œ ì›ì¸:**
            1. Graphvizê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŒ
            2. Graphviz ì‹¤í–‰ íŒŒì¼ ê²½ë¡œ ë¬¸ì œ
            3. Streamlit Cloud í™˜ê²½ ì œí•œ
            
            **í•´ê²° ë°©ë²•:**
            - ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ê±°ë‚˜
            - ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ Graphviz ì„¤ì¹˜ë¥¼ ìš”ì²­í•˜ì„¸ìš”.
            """)
            return False

    except Exception as e:
        error_msg = str(e)
        st.error(f"âŒ ERD ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}")
        
        # Graphviz ê´€ë ¨ ì˜¤ë¥˜ì¸ì§€ í™•ì¸
        if 'graphviz' in error_msg.lower() or 'ExecutableNotFound' in error_msg:
            st.info("""
            **Graphviz ê´€ë ¨ ì˜¤ë¥˜ì…ë‹ˆë‹¤.**
            
            Streamlit Cloudì—ì„œëŠ” Graphviz ì‹¤í–‰ íŒŒì¼ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ê±°ë‚˜, ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.
            """)
        else:
            st.info("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        return False

def display_erd_result(selected_tables, related_tables, pk_map, it_df):
    """ 
    4th Step: ERD ê²°ê³¼ ìš”ì•½
    """
    st.divider()
    st.subheader("3. ERD ê²°ê³¼ ìš”ì•½")
    tab1, tab2, tab3 = st.tabs(["ERD ê²°ê³¼ ìš”ì•½", "ì„ íƒëœ í…Œì´ë¸” ìƒì„¸ ì •ë³´", "ê´€ê³„ëœ í…Œì´ë¸” ìƒì„¸ ì •ë³´"])
    with tab1:
        erd_result_df = create_erd_result_dataframe(selected_tables, related_tables, pk_map, it_df)
        st.dataframe(
            erd_result_df,
            hide_index=True,
            width='stretch',    
            height=400,
            column_config={
                'í…Œì´ë¸”ëª…': st.column_config.TextColumn('í…Œì´ë¸”ëª…', width=150),
                'ì„ íƒì—¬ë¶€': st.column_config.TextColumn('ì„ íƒ', width=50),
                'PK ì»¬ëŸ¼': st.column_config.TextColumn('PK ì»¬ëŸ¼', width=150),
                'FK ì»¬ëŸ¼': st.column_config.TextColumn('FK ì»¬ëŸ¼', width=150),
                'Parent í…Œì´ë¸”': st.column_config.TextColumn('Parent í…Œì´ë¸”', width=200),
                'Child í…Œì´ë¸”': st.column_config.TextColumn('Child í…Œì´ë¸”', width=200),
                'ê´€ê³„ ìˆ˜': st.column_config.NumberColumn('ê´€ê³„ ìˆ˜', width=50)
            }
        )

    with tab2:
        selected_tables_df = it_df[it_df['FileName'].isin(selected_tables)]
        selected_tables_df = selected_tables_df.drop(columns=['FilePath'])
        st.dataframe(selected_tables_df, hide_index=True, width=1000, height=400)

    with tab3:
        related_tables_df = it_df[it_df['FileName'].isin(related_tables)]
        related_tables_df = related_tables_df.drop(columns=['FilePath'])
        st.dataframe(related_tables_df, hide_index=True, width=1000, height=400)

    st.divider()
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ í…Œì´ë¸” ìˆ˜", len(erd_result_df))
    with col2:
        st.metric("ì„ íƒëœ í…Œì´ë¸” ìˆ˜", len(erd_result_df[erd_result_df['ì„ íƒì—¬ë¶€'] == 'âœ“']))
    with col3:
        st.metric("ì´ ê´€ê³„ ìˆ˜", erd_result_df['ê´€ê³„ ìˆ˜'].sum())
    with col4:
        st.metric("PK ë³´ìœ  í…Œì´ë¸”", len(erd_result_df[erd_result_df['PK ì»¬ëŸ¼'] != '']))

    return True

#---------------------------------------------------------------------------
# 6. main í•¨ìˆ˜
#---------------------------------------------------------------------------
def main():
    st.title(APP_TITLE)
    st.caption(APP_DESCRIPTION)

    try:
        # 1. ë°ì´í„° ì¶”ì¶œ ë° ë¡œë“œ
        pk_map, fk_df, it_df = load_data_mapping() # CodeMapping_relationship.csv ê¸°ë°˜

        it_org_df = load_data_org() # CodeMapping.csv ê¸°ë°˜
        filestats_df = load_data_filestats() # filestats.csv ê¸°ë°˜
       
        if it_org_df is None or filestats_df is None:
            st.error("CodeMapping.csv ë˜ëŠ” filestats.csv íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 1.1 KPI í‘œì‹œ
        Display_File_Statistics(filestats_df)

        # 2. í…Œì´ë¸” ì„ íƒ     
        selected_tables = select_tables(it_df, it_org_df)
        if selected_tables is None:
            return

        # ERD ìƒì„± ë²„íŠ¼
        col1, col2, col3 = st.columns([1, 2, 1])
        with col1:
            erd_button = st.button("ğŸ”— ERD ìƒì„±", type="primary", use_container_width=True)
        
        if not erd_button:
            st.info(f"ìµœëŒ€ related_tables ìˆ˜ëŠ” í•©ê³„ {MAX_RELATED_TABLE_COUNT}ê°œê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return

        # 3. ERD ìƒì„±
        related_tables = generate_erd(selected_tables, pk_map, it_df)
        if not related_tables:
            return

        erd_success = display_erd_result(selected_tables, related_tables, pk_map, it_df)
        if not erd_success:
            return
        return 

    except Exception as e:
        st.error(f"ERD ìƒì„± ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

if __name__ == '__main__':
    main()
