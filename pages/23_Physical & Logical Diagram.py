# -*- coding: utf-8 -*-
"""
ğŸ”— DataSense Physical & Logical Data Relationship Diagram Generator
âœ” Cloud / Local í™˜ê²½ ìë™ ê°ì§€ (Cloud : ì˜ˆì œ ì´ë¯¸ì§€ ì¶œë ¥, Local : ì‹¤ì œ Graphviz Physical & Logical Data Relationship Diagram ìƒì„±)
Author: Qliker 2026-01-08
"""
# -------------------------------------------------
# 1. Path / Warning setup (Streamlit import ì „)
# -------------------------------------------------
import sys
from pathlib import Path

CURRENT_DIR = Path(__file__).resolve()
PROJECT_ROOT = CURRENT_DIR.parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from util.streamlit_warnings import setup_streamlit_warnings
setup_streamlit_warnings()
# -------------------------------------------------
# 2. Standard / Third-party imports
# -------------------------------------------------
import shutil
from datetime import datetime
from collections import defaultdict
import streamlit as st
import pandas as pd
import graphviz
from graphviz import Digraph
import streamlit.components.v1 as components
from PIL import Image

Image.MAX_IMAGE_PIXELS = None # ì´ë¯¸ì§€ í¬ê¸° ì œí•œ í•´ì œ (DecompressionBombError ë°©ì§€)
# -------------------------------------------------
# 3. Local imports
# -------------------------------------------------
from util.Files_FunctionV20 import set_page_config
from util.Display import Display_File_Statistics, display_kpi_metrics
from util.ds_generate_ERD import show_example_erd_images
# -------------------------------------------------
# 4. App Config (ì ˆëŒ€ ìƒìˆ˜ì„. ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”)
# -------------------------------------------------
APP_NAME = "Physical & Logical Diagram"
APP_TITLE = "Physical & Logical Data Relationship Diagram"
APP_DESCRIPTION = "ë°ì´í„° ê°’ ë§¤í•‘ ê¸°ë°˜ ë¬¼ë¦¬ì  & ë…¼ë¦¬ì  Data Relationship Diagramì„ ìƒì„±í•©ë‹ˆë‹¤."

OUTPUT_DIR = PROJECT_ROOT /  'DS_Output'
IMAGE_DIR = PROJECT_ROOT / 'images'
IMAGE_FILE = "Datasense_DRD"
EXCLUSIVE_FILE = OUTPUT_DIR / "ERD_exclusive.csv"

MAX_RELATED_TABLE_COUNT = 100

set_page_config(APP_NAME)
# -------------------------------------------------------------------
# ERD ìƒìˆ˜ ì„¤ì •
# -------------------------------------------------------------------
MAX_TABLE_COUNT = 20    # ERD ìƒì„± ì‹œ ìµœëŒ€ í…Œì´ë¸” ìˆ˜
ERD_IMAGE_FILENAME = 'Master_ERD_2'
ERD_IMAGE_FILEEXTENSION = 'png'

ERD_FONT_SIZE = '6'
ERD_FONT_NAME = 'Malgun Gothic'

# ========================================================================
# í•¨ìˆ˜ ì •ì˜ ì„¹ì…˜
# ========================================================================

# -------------------------------------------------
# 1. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (Utility Functions)
# -------------------------------------------------
def is_cloud_env() -> bool:
    """Cloud í™˜ê²½ ê°ì§€"""
    try:
        return shutil.which("dot") is None
    except Exception:
        return True

def parse_relationship(relationship_str):
    """Level_Relationship_Internal ë¬¸ìì—´ì—ì„œ ëª¨ë“  ê´€ê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not isinstance(relationship_str, str) or '->' not in relationship_str:
        return []
    
    segments = relationship_str.split(' -> ')
    relationships = []
    
    for i in range(len(segments) - 1):
        parent_segment = segments[i].strip()
        child_segment = segments[i+1].strip()
        
        try:
            # íŒŒì¼ëª…ê³¼ ì»¬ëŸ¼ëª… ë¶„ë¦¬ (ë§ˆì§€ë§‰ '.' ê¸°ì¤€)
            parent_file, parent_col = parent_segment.rsplit('.', 1)
            child_file, child_col = child_segment.rsplit('.', 1)
            
            # Level_Relationship_Internal ìˆœì„œë¥¼ ë°˜ëŒ€ë¡œ í•´ì„í•˜ì—¬ FK ê´€ê³„ ìƒì„±
            relationships.append({
                'Child_Table': child_file,
                'Child_Column': child_col,
                'Parent_Table': parent_file,
                'Parent_Column': parent_col
            })
        except ValueError:
            continue
    return relationships

def _extract_and_load_erd_data_impl(df_raw: pd.DataFrame):
    """     2nd Step: ë°ì´í„° í†µí•© & find pk & fk    """

    required_columns = ['FileName', 'ColumnName', 'PK']
    missing_columns = [col for col in required_columns if col not in df_raw.columns]
    if missing_columns:
        st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}")
        return None, None, None

    if 'Level_Relationship_Internal' not in df_raw.columns:
        st.warning("âš ï¸ 'Level_Relationship_Internal' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. FK ê´€ê³„ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        df_raw['Level_Relationship_Internal'] = ''

    # --- 2. ERD ì •ë³´ ì¶”ì¶œ ë©”ì¸ ë¡œì§ ---
    tables_data = {}
    df_raw = df_raw.fillna('')

    # 2.1. ëª¨ë“  í…Œì´ë¸” ë° ì»¬ëŸ¼ ì •ë³´ ì¶”ì¶œ (ë²¡í„°í™”ëœ ì—°ì‚° ì‚¬ìš©)
    df_raw['FileName'] = df_raw['FileName'].astype(str).str.strip()
    df_raw['ColumnName'] = df_raw['ColumnName'].astype(str).str.strip()
    df_valid = df_raw[(df_raw['FileName'] != '') & (df_raw['ColumnName'] != '')].copy()
    
    for file_name, group in df_valid.groupby('FileName'):
        if file_name not in tables_data:
            tables_data[file_name] = defaultdict(lambda: {'PK': '', 'FK': '', 'Parent_Table': ''})
        
        for _, row in group.iterrows():
            col_name = row['ColumnName']
            pk_status = 'PK' if str(row.get('PK', '')).strip() == '1' else ''
            tables_data[file_name][col_name]['PK'] = pk_status

    # 2.2. ê´€ê³„ ì •ë³´ ì¶”ì¶œ ë° FK ì—…ë°ì´íŠ¸ (í•„í„°ë§ëœ ë°ì´í„°ë§Œ ì²˜ë¦¬)
    all_relationships = []
    # Level_Relationship_Internal ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë¹ˆ ë¬¸ìì—´ë¡œ ìƒì„±
    if 'Level_Relationship_Internal' not in df_valid.columns:
        df_valid['Level_Relationship_Internal'] = ''
    df_with_rel = df_valid[df_valid['Level_Relationship_Internal'].astype(str).str.strip() != ''].copy()
    
    for _, row in df_with_rel.iterrows():
        rel_str = str(row.get('Level_Relationship_Internal', '')).strip()
        parsed_rels = parse_relationship(rel_str)
        
        for rel in parsed_rels:
            all_relationships.append(rel)
            
            child_table = str(rel['Child_Table']).strip()
            child_col = str(rel['Child_Column']).strip()
            parent_table = str(rel['Parent_Table']).strip()
            
            if not child_table or not child_col or not parent_table:
                continue
            
            if child_table in tables_data and child_col in tables_data[child_table]:
                tables_data[child_table][child_col]['FK'] = 'FK'
                
                current_parents = str(tables_data[child_table][child_col]['Parent_Table']).strip()
                if current_parents:
                    parent_list = [p.strip() for p in current_parents.split(',') if p.strip()]
                    if parent_table not in parent_list:
                        parent_list.append(parent_table)
                        tables_data[child_table][child_col]['Parent_Table'] = ', '.join(parent_list)
                else:
                    tables_data[child_table][child_col]['Parent_Table'] = parent_table


    # 2.3. ìµœì¢… í†µí•© DataFrame ìƒì„± (ë²¡í„°í™”ëœ ì—°ì‚° ì‚¬ìš©)
    df_raw['FileName'] = df_raw['FileName'].astype(str).str.strip()
    df_raw['ColumnName'] = df_raw['ColumnName'].astype(str).str.strip()
    df_raw = df_raw[(df_raw['FileName'] != '') & (df_raw['ColumnName'] != '')]
    
    # Level_Depth ì²˜ë¦¬
    if 'Level_Depth_Internal' in df_raw.columns:
        df_raw['Level_Depth_Internal'] = pd.to_numeric(df_raw['Level_Depth_Internal'], errors='coerce').fillna(0).astype(int)
    else:
        df_raw['Level_Depth_Internal'] = 0
    
    # FilePath ì²˜ë¦¬
    if 'FilePath' in df_raw.columns:
        df_raw['FilePath'] = df_raw['FilePath'].astype(str).str.strip()
    else:
        df_raw['FilePath'] = ''
    
    # Level_Relationship_Internal ì²˜ë¦¬
    if 'Level_Relationship_Internal' in df_raw.columns:
        df_raw['Level_Relationship_Internal'] = df_raw['Level_Relationship_Internal'].astype(str).str.strip()
    else:
        df_raw['Level_Relationship_Internal'] = ''
    
    # tables_dataì™€ ë³‘í•©í•˜ì—¬ PK/FK ì •ë³´ ì¶”ê°€
    erd_data_list = []
    for _, row in df_raw.iterrows():
        file_name = row['FileName']
        col_name = row['ColumnName']
        
        if file_name in tables_data and col_name in tables_data[file_name]:
            info = tables_data[file_name][col_name]
            erd_data_list.append({
                'FileName': file_name,
                'ColumnName': col_name,
                'PK': 1 if info['PK'] == 'PK' else 0,
                'FK': 1 if info['FK'] == 'FK' else 0,
                'Parent_Table': str(info['Parent_Table']).strip(),
                'Level_Relationship_Internal': row['Level_Relationship_Internal'],
                'Level_Depth_Internal': int(row['Level_Depth_Internal']),
                'FilePath': row['FilePath']
            })
    
    if not erd_data_list:
        st.error("ERD ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ íŒŒì¼ì˜ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None, None, None
    
    df_erd_attributes = pd.DataFrame(erd_data_list)

    unique_relationships = {}
    for rel in all_relationships:
        key = (rel['Child_Table'], rel['Parent_Table'])
        
        if key not in unique_relationships:
            unique_relationships[key] = {
                'Child Table': rel['Child_Table'],
                'Parent Table': rel['Parent_Table'],
                'FK Columns': set(),
                'PK Columns': set()
            }
        
        unique_relationships[key]['FK Columns'].add(rel['Child_Column'])
        unique_relationships[key]['PK Columns'].add(rel['Parent_Column'])

    df_erd_relationships = pd.DataFrame([
        {
            'Child Table': rel['Child Table'],
            'Parent Table': rel['Parent Table'],
            'FK Columns': ', '.join(sorted(rel['FK Columns'])),
            'PK Columns': ', '.join(sorted(rel['PK Columns']))
        }
        for rel in unique_relationships.values()
    ])
    
    pk_map = df_erd_attributes[df_erd_attributes['PK'] == 1].groupby('FileName')['ColumnName'].apply(
        lambda x: list(x.astype(str))
    ).to_dict()
    
    return pk_map, df_erd_relationships, df_erd_attributes

try:
    from streamlit.runtime.scriptrunner.script_run_context import get_script_run_ctx
    if get_script_run_ctx(suppress_warning=True) is not None:
        extract_and_load_erd_data = st.cache_data(_extract_and_load_erd_data_impl)
    else:
        extract_and_load_erd_data = _extract_and_load_erd_data_impl
except:
    extract_and_load_erd_data = _extract_and_load_erd_data_impl

# -------------------------------------------------
# 2. ë°ì´í„° ë¡œë“œ/ì²˜ë¦¬ í•¨ìˆ˜ (Data Loading & Processing)
# -------------------------------------------------
def load_data_all(files_to_load):
    """ì—¬ëŸ¬ CSV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    loaded_data = {}
    for name, path in files_to_load.items():
        if not path.exists():
            st.error(f"{path.name} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return None
        df = pd.read_csv(path, encoding='utf-8-sig')
        loaded_data[name] = df
    return loaded_data

# def create_pk_fk_from_mapping(df_cr):
#     """ë°ì´í„° í†µí•© & find pk & fk"""
#     # 1. ë°ì´í„° ì¶”ì¶œ ë° ë¡œë“œ
#     pk_map, fk_map, it_df = _extract_and_load_erd_data_impl(df_cr)
    
#     if pk_map is None or fk_map is None or it_df is None:
#         st.error("ERD ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ íŒŒì¼ì˜ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
#         return None, None, None

#     return pk_map, fk_map, it_df

# -------------------------------------------------
# 3. ê´€ê³„ ì¶”ì¶œ í•¨ìˆ˜ (Relationship Extraction)
# -------------------------------------------------
def _extract_relationships_from_erd_logic(selected_files: list, all_tables: set, it_df: pd.DataFrame):
    """
    22_Data Relationship Diagram.pyìš© ë…¼ë¦¬ì  ê´€ê³„ ì¶”ì¶œ í•¨ìˆ˜
    Level_Relationship ë˜ëŠ” Level_Relationship_Internalì„ ì‚¬ìš©
    ë°˜í™˜: relationships_list = [(from_file, from_col, to_file, to_col), ...]
    """
    relationships_list = []
    
    # Level_Relationship_Internal ë˜ëŠ” Level_Relationship ì»¬ëŸ¼ í™•ì¸
    rel_col = None
    if 'Level_Relationship_Internal' in it_df.columns:
        rel_col = 'Level_Relationship_Internal'
    elif 'Level_Relationship' in it_df.columns:
        rel_col = 'Level_Relationship'
    else:
        return relationships_list
    
    # selected_filesê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì „ì²´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬
    if selected_files is None:
        selected_files = []
    use_all_data = (len(selected_files) == 0)
    
    # ì„ íƒëœ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
    selected_table_columns = {}
    if not use_all_data:
        selected_df = it_df[it_df['FileName'].isin(selected_files)]
        for table_name, group in selected_df.groupby('FileName'):
            selected_table_columns[table_name] = set(group['ColumnName'].dropna().astype(str).str.strip())
    
    # ê´€ê³„ ì»¬ëŸ¼ì´ ìˆëŠ” í–‰ë§Œ í•„í„°ë§
    df_with_rel = it_df[
        (it_df[rel_col].notna()) & 
        (it_df[rel_col].astype(str).str.strip() != '')
    ].copy()
    
    # all_tablesê°€ Noneì´ê±°ë‚˜ ë¹ˆ setì¸ ê²½ìš° ëª¨ë“  í…Œì´ë¸” í—ˆìš©
    if all_tables is None:
        all_tables = set()
    use_all_tables = (len(all_tables) == 0)
    
    for _, row in df_with_rel.iterrows():
        file_name = str(row['FileName']).strip()
        col_name = str(row['ColumnName']).strip()
        rel_str = str(row[rel_col]).strip()
        
        is_selected_column = False
        if not use_all_data:
            is_selected_column = (file_name in selected_files and 
                                 col_name in selected_table_columns.get(file_name, set()))
        
        segments = rel_str.split(' -> ')
        parsed_segments = []
        for segment in segments:
            segment = segment.strip()
            if not segment:
                continue
            try:
                file_part, col_part = segment.rsplit('.', 1)
                parsed_segments.append((file_part.strip(), col_part.strip()))
            except ValueError:
                continue
        
        # ì „ì²´ ë°ì´í„° ëª¨ë“œì´ê±°ë‚˜ ì„ íƒëœ ì»¬ëŸ¼/í…Œì´ë¸”ì´ í¬í•¨ëœ ê²½ìš°
        should_process = use_all_data or is_selected_column or any(seg_file in selected_files for seg_file, _ in parsed_segments)
        
        if should_process:
            for i in range(len(parsed_segments) - 1):
                from_file, from_col = parsed_segments[i]
                to_file, to_col = parsed_segments[i+1]
                
                # all_tables í•„í„°ë§ (ì „ì²´ ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ)
                if not use_all_tables:
                    if from_file not in all_tables or to_file not in all_tables:
                        continue
                
                relationships_list.append((from_file, from_col, to_file, to_col))
                
                if is_selected_column and i == 0 and file_name != from_file:
                    if use_all_tables or (file_name in all_tables and from_file in all_tables):
                        relationships_list.append((file_name, col_name, from_file, from_col))
    
    return relationships_list

def _extract_edge_groups_from_relationships(it_df: pd.DataFrame, selected_files: list = None, all_tables: set = None):
    """Level_Relationship_Internalì—ì„œ ì—£ì§€ ê·¸ë£¹ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ERDì™€ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©."""
    if selected_files is None:
        selected_files = []
    if all_tables is None:
        all_tables = set()
    
    # ERDì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ê´€ê³„ ì¶”ì¶œ
    relationships_list = _extract_relationships_from_erd_logic(selected_files, all_tables, it_df)
    
    # ì—£ì§€ ê·¸ë£¹ìœ¼ë¡œ ì§‘ê³„ (ERDì™€ ë™ì¼í•˜ê²Œ all_tables í•„í„°ë§)
    edge_groups = {}  # {(from_file, to_file): set()}
    edge_groups_by_file = {}  # {file_name: set of (from_file, to_file)}
    
    for from_file, from_col, to_file, to_col in relationships_list:
        # ERDì™€ ë™ì¼í•˜ê²Œ all_tables í•„í„°ë§
        if all_tables and (from_file not in all_tables or to_file not in all_tables):
            continue
            
        key = (from_file, to_file)
        if key not in edge_groups:
            edge_groups[key] = set()
        edge_groups[key].add((from_col, to_col))
        
        # ê° íŒŒì¼ë³„ë¡œ ì—£ì§€ ê·¸ë£¹ ìˆ˜ì§‘
        if from_file not in edge_groups_by_file:
            edge_groups_by_file[from_file] = set()
        edge_groups_by_file[from_file].add(key)
        
        if to_file not in edge_groups_by_file:
            edge_groups_by_file[to_file] = set()
        edge_groups_by_file[to_file].add(key)
    
    return edge_groups_by_file

# -------------------------------------------------
# 4. ë°ì´í„° ë¶„ì„/ìš”ì•½ í•¨ìˆ˜ (Data Analysis & Summary)
# -------------------------------------------------
def export_summary_result(integrated_df: pd.DataFrame):
    """    FileName ê¸°ì¤€ìœ¼ë¡œ ì§‘ê³„í•˜ì—¬ ìš”ì•½ ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. (Level, Rel Table #, íŒŒì¼ë¦¿ ê³„ì‚° ì¶”ê°€)    """
    # Level_Relationship_Internal ë¬¸ìì—´ì—ì„œ ëª¨ë“  ê³ ìœ  íŒŒì¼ ì´ë¦„ì„ ì¶”ì¶œí•˜ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
    def extract_unique_files_from_chain(relationship_str):
        if not isinstance(relationship_str, str) or not relationship_str.strip():
            return set()
        files = set()
        segments = relationship_str.split(' -> ')
        for segment in segments:
            segment = segment.strip()
            if not segment: continue
            try:
                # FileName.Columnì—ì„œ FileNameë§Œ ì¶”ì¶œ
                file_part, _ = segment.rsplit('.', 1)
                files.add(file_part.strip())
            except ValueError:
                continue
        return files

    # 1. íŒŒì¼ë³„ ê¸°ë³¸ í†µê³„ ê³„ì‚° (Column #, FilePath, Max_Level_Depth)
    def get_max_level_depth(series):
        if 'Level_Depth_Internal' not in integrated_df.columns: return 0
        non_na = series.dropna()
        if non_na.empty: return 0
        try:
            return int(pd.to_numeric(non_na, errors='coerce').max())
        except (ValueError, TypeError):
            return 0

    # Level_Depth_Internal ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 0ìœ¼ë¡œ ìƒì„±
    if 'Level_Depth_Internal' not in integrated_df.columns:
        integrated_df['Level_Depth_Internal'] = 0
    
    # groupby().agg() ë”•ì…”ë„ˆë¦¬ ë™ì  ìƒì„±
    agg_dict = {
        'ColumnName': 'nunique',
        'FilePath': lambda x: x.iloc[0] if not x.empty and 'FilePath' in integrated_df.columns else ''
    }
    
    # Level_Depth_Internal ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì¶”ê°€
    if 'Level_Depth_Internal' in integrated_df.columns:
        agg_dict['Level_Depth_Internal'] = get_max_level_depth
    
    table_stats = integrated_df.groupby('FileName').agg(agg_dict).reset_index()
    
    # ì»¬ëŸ¼ëª… ë³€ê²½
    table_stats.rename(columns={'ColumnName': 'Column #'}, inplace=True)
    if 'Level_Depth_Internal' in table_stats.columns:
        table_stats.rename(columns={'Level_Depth_Internal': 'Max_Level'}, inplace=True)
    else:
        table_stats['Max_Level'] = 0
    
    # 2. Level_Relationship_Internal ê¸°ë°˜ ì´ ê´€ë ¨ íŒŒì¼ ê°œìˆ˜ ë° íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê³„ì‚° (â˜…â˜…â˜… ì‚¬ìš©ì ìš”ì²­ ì§€í‘œ ìµœì í™” â˜…â˜…â˜…)
    # Level_Relationship_Internal ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë¹ˆ ë¬¸ìì—´ë¡œ ìƒì„±
    if 'Level_Relationship_Internal' not in integrated_df.columns:
        integrated_df['Level_Relationship_Internal'] = ''
    
    # Level_Relationship_Internalì´ ìˆëŠ” í–‰ë§Œ í•„í„°ë§
    temp_df = integrated_df[integrated_df['Level_Relationship_Internal'].astype(bool)].copy()
    
    # FileNameë³„ë¡œ ê´€ë ¨ íŒŒì¼ ìˆ˜ì§‘ (ë” ì§ì ‘ì ì¸ ë°©ë²•)
    related_files_info = {}
    
    for file_name, group in temp_df.groupby('FileName'):
        all_files = set()
        # ê° í–‰ì˜ Level_Relationship_Internalì—ì„œ íŒŒì¼ ì¶”ì¶œ
        for _, row in group.iterrows():
            rel_str = row['Level_Relationship_Internal']
            if pd.notna(rel_str) and isinstance(rel_str, str) and rel_str.strip():
                files = extract_unique_files_from_chain(rel_str)
                all_files.update(files)
        
        # ìê¸° ìì‹ (FileName)ì€ ì œì™¸
        all_files.discard(file_name)
        
        # ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        sorted_files = sorted(list(all_files))
        related_files_info[file_name] = {
            'count': len(all_files),
            'list': sorted_files
        }

    summary_df = table_stats.copy()

    # Rel Table # (ì—°ê´€ íŒŒì¼ ê°œìˆ˜)
    summary_df['Rel Table #'] = summary_df['FileName'].apply(
        lambda x: related_files_info.get(x, {}).get('count', 0) if x in related_files_info else 0
    )
    
    # Related Files List (ì—°ê´€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸)
    summary_df['Related Files List'] = summary_df['FileName'].apply(
        lambda x: ', '.join(related_files_info.get(x, {}).get('list', [])) if x in related_files_info else ''
    )
    
    summary_df = summary_df.sort_values(by='FileName').fillna(0)
    return summary_df

# -------------------------------------------------
# 5. ê´€ê³„ íƒìƒ‰ í•¨ìˆ˜ (Relationship Discovery)
# -------------------------------------------------
def get_related_tables(selected_files: list, it_df: pd.DataFrame):
    """ì„ íƒëœ í…Œì´ë¸”ê³¼ ê´€ë ¨ëœ ëª¨ë“  í…Œì´ë¸”ì„ ì°¾ìŠµë‹ˆë‹¤."""
    # Level_Relationship_Internal ë˜ëŠ” Level_Relationship ì»¬ëŸ¼ í™•ì¸
    rel_col = None
    if 'Level_Relationship_Internal' in it_df.columns:
        rel_col = 'Level_Relationship_Internal'
    elif 'Level_Relationship' in it_df.columns:
        rel_col = 'Level_Relationship'
    else:
        return set(selected_files)
    
    # ì„ íƒëœ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘ (ë²¡í„°í™”ëœ ì—°ì‚°)
    selected_table_columns = {}
    selected_df = it_df[it_df['FileName'].isin(selected_files)]
    for table_name, group in selected_df.groupby('FileName'):
        selected_table_columns[table_name] = set(group['ColumnName'].dropna().astype(str).str.strip())
    
    # ê´€ê³„ ì»¬ëŸ¼ì´ ìˆëŠ” í–‰ë§Œ í•„í„°ë§
    df_with_rel = it_df[
        (it_df[rel_col].notna()) & 
        (it_df[rel_col].astype(str).str.strip() != '')
    ].copy()
    
    all_relations = []
    for _, row in df_with_rel.iterrows():
        file_name = str(row['FileName']).strip()
        col_name = str(row['ColumnName']).strip()
        rel_str = str(row[rel_col]).strip()
        
        is_selected_column = (file_name in selected_files and 
                             col_name in selected_table_columns.get(file_name, set()))
        
        segments = rel_str.split(' -> ')
        parsed_segments = []
        for segment in segments:
            segment = segment.strip()
            if not segment:
                continue
            try:
                file_part, _ = segment.rsplit('.', 1)
                parsed_segments.append((file_part.strip(), ''))
            except ValueError:
                continue
        
        if is_selected_column or any(seg_file in selected_files for seg_file, _ in parsed_segments):
            for i in range(len(parsed_segments) - 1):
                from_file, _ = parsed_segments[i]
                to_file, _ = parsed_segments[i+1]
                all_relations.append((from_file, to_file))
                
                if is_selected_column and i == 0 and file_name != from_file:
                    all_relations.append((file_name, from_file))
    
    related_tables = set(selected_files)
    tables_to_check = set(selected_files)
    
    for _ in range(5):
        newly_added = set()
        for from_table, to_table in all_relations:
            if from_table in tables_to_check:
                newly_added.add(to_table)
            if to_table in tables_to_check:
                newly_added.add(from_table)
        
        if not newly_added:
            break
        
        newly_added -= related_tables
        related_tables.update(newly_added)
        tables_to_check = newly_added
    
    return related_tables

def generate_logical_erd_image(selected_files: list, all_tables: set, pk_map: dict, it_df: pd.DataFrame, show_all_columns:bool):
    """
    ë…¼ë¦¬ì  ERD ì´ë¯¸ì§€ ìƒì„± (ë¬¼ë¦¬ì  ERDì™€ ì¼ê´€ëœ ìŠ¤íƒ€ì¼)
    - ë…¼ë¦¬ì  ê´€ê³„: ì»¬ëŸ¼ ë°ì´í„°ê°’ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” ê´€ê³„
    - ë¬¼ë¦¬ì  ERDì™€ ë™ì¼í•œ node ë° edge í‘œí˜„ ë°©ë²• ë° ìƒ‰ìƒ ì‚¬ìš©
    """
    # === 1. Graphviz ì‹œê°í™” ìƒì„± (ë¬¼ë¦¬ì  ERDì™€ ë™ì¼í•œ ì„¤ì •) ===
    dot = Digraph(comment='Logical ERD', encoding='utf-8')
    dot.attr(rankdir='LR', nodesep='0.5', ranksep='2.5', splines='polyline')
    dot.attr('node', fontname='Malgun Gothic', fontsize='10', shape='none')
    dot.attr('edge', fontname='Malgun Gothic', fontsize='8')
    
    # === 2. ë…¼ë¦¬ì  ê´€ê³„ ì¶”ì¶œ ===
    relationships_list = _extract_relationships_from_erd_logic(selected_files, all_tables, it_df)
    
    # ì—°ê²°ëœ ì»¬ëŸ¼ ìˆ˜ì§‘
    connected_columns = {}
    for from_file, from_col, to_file, to_col in relationships_list:
        if from_file not in connected_columns:
            connected_columns[from_file] = set()
        connected_columns[from_file].add(from_col)
        
        if to_file not in connected_columns:
            connected_columns[to_file] = set()
        connected_columns[to_file].add(to_col)
    
    # === 3. ê° í…Œì´ë¸”ë³„ë¡œ í‘œì‹œí•  ì»¬ëŸ¼ ê²°ì • ===
    display_columns = {}
    for table_name in all_tables:
        is_selected = table_name in selected_files
        pk_cols_ordered = pk_map.get(table_name, [])
        pk_cols_set = set(pk_cols_ordered)
        connected_cols = connected_columns.get(table_name, set())
        
        if show_all_columns and is_selected:
            # ìƒì„¸ ëª¨ë“œ & ì„ íƒëœ í…Œì´ë¸”: ëª¨ë“  ì»¬ëŸ¼ í‘œì‹œ
            all_cols = it_df[it_df['FileName'] == table_name]['ColumnName'].unique().tolist()
            all_cols_set = set(all_cols)
            # PK ì»¬ëŸ¼ì€ ìˆœì„œ ìœ ì§€
            pk_to_display = [col for col in pk_cols_ordered if col in all_cols_set]
            # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ì€ ì •ë ¬
            other_to_display = sorted(list(all_cols_set - pk_cols_set))
            display_columns[table_name] = pk_to_display + other_to_display
        else:
            # ìš”ì•½ ëª¨ë“œ ë˜ëŠ” ì„ íƒë˜ì§€ ì•Šì€ í…Œì´ë¸”: ì—°ê²°ëœ ì»¬ëŸ¼ë§Œ í‘œì‹œ
            pk_to_display = [col for col in pk_cols_ordered if col in connected_cols]
            other_to_display = sorted(list(connected_cols - pk_cols_set))
            display_columns[table_name] = pk_to_display + other_to_display

    # === 4. í…Œì´ë¸” ë…¸ë“œ ìƒì„± (ë¬¼ë¦¬ì  ERDì™€ ë™ì¼í•œ ìŠ¤íƒ€ì¼) ===
    def escape_html(text):
        return text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
    
    # OracleType ì •ë³´ ìˆ˜ì§‘ (ìˆëŠ” ê²½ìš°)
    oracle_types = {}
    if 'OracleType' in it_df.columns:
        for _, row in it_df.iterrows():
            table_name = str(row['FileName']).strip()
            col_name = str(row['ColumnName']).strip()
            o_type = str(row['OracleType']).strip() if pd.notna(row['OracleType']) else ""
            if table_name not in oracle_types:
                oracle_types[table_name] = {}
            oracle_types[table_name][col_name] = o_type
    
    # FK ê´€ê³„ì— ì‚¬ìš©ëœ ì»¬ëŸ¼ ì¶”ì¶œ
    fk_columns = set()
    for from_file, from_col, to_file, to_col in relationships_list:
        fk_columns.add((from_file, from_col))
        fk_columns.add((to_file, to_col))
    
    for table_name in sorted(all_tables):
        pk_cols_ordered = pk_map.get(table_name, [])
        pk_cols_set = set(pk_cols_ordered)
        table_cols = display_columns.get(table_name, [])
        
        # selected_filesì— table_nameì´ ìˆìœ¼ë©´ ì˜¤ë Œì§€ìƒ‰ ì•„ë‹ˆë©´ ì—°í•œ íŒŒë‘ìƒ‰ (ë¬¼ë¦¬ì  ERDì™€ ë™ì¼)
        header_color = '#FFA500' if table_name in selected_files else '#BBDEFB'
        font_color = 'black'
        is_sel = table_name in selected_files
        
        label = f'<<TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" PORT="title">'
        label += f'<TR><TD BGCOLOR="{header_color}"><FONT COLOR="{font_color}"><B>{escape_html(table_name)}</B></FONT></TD></TR>'
        
        pk_to_display = [col for col in table_cols if col in pk_cols_set]
        other_to_display = [col for col in table_cols if col not in pk_cols_set]
        
        # PK ë Œë”ë§ (ë¬¼ë¦¬ì  ERDì™€ ë™ì¼í•œ ìŠ¤íƒ€ì¼)
        for col in sorted(pk_to_display):
            safe_col = escape_html(col)
            label += f'<TR><TD ALIGN="LEFT" BGCOLOR="#E3F2FD" PORT="{safe_col}"><B>ğŸ”‘ {safe_col}</B></TD></TR>'
        
        # ì¼ë°˜/FK ë Œë”ë§ (ë¬¼ë¦¬ì  ERDì™€ ë™ì¼í•œ ìŠ¤íƒ€ì¼)
        for col in sorted(other_to_display):
            safe_col = escape_html(col)
            is_fk = (table_name, col) in fk_columns
            prefix = "ğŸ”— " if is_fk else "  "
            label += f'<TR><TD ALIGN="LEFT" PORT="{safe_col}">{prefix}{safe_col}</TD></TR>'
        
        label += '</TABLE>>'
        dot.node(table_name, label)

    # === 5. ë…¼ë¦¬ì  ê´€ê³„ Edge ì¶”ê°€ (ë¬¼ë¦¬ì  ERDì™€ ë™ì¼í•œ ìŠ¤íƒ€ì¼) ===
    edge_groups = {}
    for from_file, from_col, to_file, to_col in relationships_list:
        key = (from_file, to_file)
        if key not in edge_groups:
            edge_groups[key] = []
        edge_groups[key].append((from_col, to_col))
    
    edge_count = 0
    for (from_file, to_file), cols_list in edge_groups.items():
        if from_file not in all_tables or to_file not in all_tables:
            continue
        
        from_col, to_col = cols_list[0]
        safe_from_col = escape_html(from_col)
        safe_to_col = escape_html(to_col)
        
        # ë¬¼ë¦¬ì  ERDì™€ ë™ì¼í•œ edge ìŠ¤íƒ€ì¼
        dot.edge(f'{from_file}:{safe_from_col}', 
                f'{to_file}:{safe_to_col}',
                dir='both',
                arrowhead='none',
                arrowtail='crow',
                color='#555555',
                penwidth='1.0')
        edge_count += 1
    
    # ERD ìƒì„± ì •ë³´ ìˆ˜ì§‘
    erd_info = {
        'relationships_list': relationships_list,
        'all_tables': all_tables,
        'pk_map': pk_map,
        'connected_columns': connected_columns,
        'display_columns': display_columns,
        'show_all_columns': show_all_columns,
        'selected_files': selected_files,
        'mode': 'Logical'
    }
    
    return dot, edge_count, erd_info

def create_erd_result_dataframe(selected_files: list, all_tables: set, pk_map: dict, it_df: pd.DataFrame):
    """ERD ìƒì„± ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤. ERDì™€ ë™ì¼í•œ í•„í„°ë§ ë¡œì§ ì‚¬ìš©."""
    # ERDì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ê´€ê³„ ì¶”ì¶œ
    relationships_list = _extract_relationships_from_erd_logic(selected_files, all_tables, it_df)
    
    # ì—£ì§€ ê·¸ë£¹ìœ¼ë¡œ ì§‘ê³„ (ERDì™€ ë™ì¼)
    edge_groups = {}  # {(from_file, to_file): list of (from_col, to_col)}
    from_edge_groups = {}  # {table_name: set of (from_file, to_file)}
    to_edge_groups = {}  # {table_name: set of (from_file, to_file)}
    
    for from_file, from_col, to_file, to_col in relationships_list:
        # ERDì™€ ë™ì¼í•˜ê²Œ all_tables í•„í„°ë§
        if from_file not in all_tables or to_file not in all_tables:
            continue
            
        key = (from_file, to_file)
        if key not in edge_groups:
            edge_groups[key] = []
        edge_groups[key].append((from_col, to_col))
        
        # From ê´€ê³„ (ì´ í…Œì´ë¸”ì´ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”)
        if from_file not in from_edge_groups:
            from_edge_groups[from_file] = set()
        from_edge_groups[from_file].add(key)
        
        # To ê´€ê³„ (ì´ í…Œì´ë¸”ì„ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”)
        if to_file not in to_edge_groups:
            to_edge_groups[to_file] = set()
        to_edge_groups[to_file].add(key)
    
    # ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
    from_relations = {}  # {table_name: [(col, to_table, to_col), ...]}
    to_relations = {}  # {table_name: [(from_table, from_col, col), ...]}
    
    for from_file, from_col, to_file, to_col in relationships_list:
        if from_file not in from_relations:
            from_relations[from_file] = []
        from_relations[from_file].append((from_col, to_file, to_col))
        
        if to_file not in to_relations:
            to_relations[to_file] = []
        to_relations[to_file].append((from_file, from_col, to_col))
    
    result_data = []
    for table_name in sorted(all_tables):
        is_selected = table_name in selected_files
        pk_cols_ordered = pk_map.get(table_name, [])
        pk_cols_str = ', '.join(pk_cols_ordered) if pk_cols_ordered else ''
        
        all_fk_cols = set()
        parent_tables_set = set()
        child_tables_set = set()
        
        if table_name in from_relations:
            for from_col, to_table, _ in from_relations[table_name]:
                all_fk_cols.add(from_col)
                if to_table:
                    parent_tables_set.add(to_table)
        
        if table_name in to_relations:
            for from_table, _, to_col in to_relations[table_name]:
                all_fk_cols.add(to_col)
                if from_table:
                    child_tables_set.add(from_table)
        
        from_edge_count = len(from_edge_groups.get(table_name, set()))
        to_edge_count = len(to_edge_groups.get(table_name, set()))
        
        result_data.append({
            'í…Œì´ë¸”ëª…': table_name,
            'ì„ íƒì—¬ë¶€': 'âœ“' if is_selected else '',
            'PK ì»¬ëŸ¼': pk_cols_str,
            'FK ì»¬ëŸ¼': ', '.join(sorted(all_fk_cols)) if all_fk_cols else '',
            'Parent í…Œì´ë¸”': ', '.join(sorted(parent_tables_set)) if parent_tables_set else '',
            'Child í…Œì´ë¸”': ', '.join(sorted(child_tables_set)) if child_tables_set else '',
            'ê´€ê³„ ìˆ˜': from_edge_count + to_edge_count
        })
    
    return pd.DataFrame(result_data)

# #----------------------------------------------------------------------------------------
# # ë°ì´í„° ì¶”ì¶œ ë° ë¡œë“œ
# #-----------------------------------------------------------------------------------------
# def load_data_all(files_to_load):
#     """  ë°ì´í„° ì¶”ì¶œ ë° ë¡œë“œ    """
#     loaded_data = {}

#     for name, path in files_to_load.items():
#         if not path.exists():
#             st.error(f"{path.name} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
#             return None
#         df = pd.read_csv(path, encoding='utf-8-sig')
#         loaded_data[name] = df
#     return loaded_data

# def create_pk_fk_from_mapping(df_cr):
#     """     2nd Step: ë°ì´í„° í†µí•© & find pk & fk    """

#     # 1. ë°ì´í„° ì¶”ì¶œ ë° ë¡œë“œ
#     pk_map, fk_map, it_df = _extract_and_load_erd_data_impl(df_cr)
    
#     if pk_map is None or fk_map is None or it_df is None:
#         st.error("ERD ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ íŒŒì¼ì˜ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
#         return None, None, None

#     return pk_map, fk_map, it_df

def render_column_control_tab(df_cm):
    """
    ì»¬ëŸ¼ ì œì–´ ì„¤ì • íƒ­ ë Œë”ë§ (24_ERD_Column_Setup.py ê¸°ëŠ¥ í†µí•©)
    
    Args:
        df_cm: CodeMapping.csv ë°ì´í„°í”„ë ˆì„
    """
    if df_cm is None or df_cm.empty:
        st.warning("CodeMapping.csv ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # MasterTypeì´ 'Master'ì¸ ë°ì´í„°ë§Œ í•„í„°ë§
    df_cm_master = df_cm[df_cm['MasterType'] == 'Master'].copy() if 'MasterType' in df_cm.columns else df_cm.copy()
    
    # 1. ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì„¤ì • ê¸°ëŠ¥
    def manage_exclusive_config_inline(df):
        """ERD_exclusive.csv ê´€ë¦¬ ë° ë°ì´í„° ëª¨ë¸ ë¶ˆì¼ì¹˜ ìƒì„¸ ë¶„ì„ ê¸°ëŠ¥"""
        from collections import defaultdict
        
        # ìµœì‹  ì •ë³´(í†µê³„) ìƒì„±
        def get_fresh_stats(df_inner):
            col_to_tables = defaultdict(set)
            col_types = {}
            for _, row in df_inner.iterrows():
                c = str(row['ColumnName']).strip()
                f = str(row['FileName']).strip()
                t = str(row.get('OracleType', '')).strip().upper() if pd.notna(row.get('OracleType')) else ""
                if c and f:
                    col_to_tables[c].add(f)
                    if c not in col_types or t in ['DATE', 'TIMESTAMP', 'DATETIME']:
                        col_types[c] = t
            
            data = []
            for col, tables in col_to_tables.items():
                t_type = col_types.get(col, "")
                data.append({
                    "ColumnName": col,
                    "OracleType": t_type,
                    "ConnectionCount": len(tables),
                    "exclusive": 1 if t_type in ['DATE', 'TIMESTAMP', 'DATETIME'] else 0
                })
            return pd.DataFrame(data)
        
        current_df = get_fresh_stats(df)
        
        # íŒŒì¼ ë¡œë“œ ë° ë³‘í•©
        if EXCLUSIVE_FILE.exists():
            try:
                old_df = pd.read_csv(EXCLUSIVE_FILE, encoding='utf-8-sig')
                if 'exclusive' in old_df.columns:
                    old_settings = old_df[['ColumnName', 'exclusive']].drop_duplicates('ColumnName')
                    final_df = pd.merge(current_df, old_settings, on='ColumnName', how='left', suffixes=('_init', ''))
                    final_df['exclusive'] = final_df['exclusive'].fillna(final_df['exclusive_init']).astype(int)
                    final_df = final_df.drop(columns=['exclusive_init'])
                else:
                    final_df = current_df
            except Exception as e:
                st.warning(f"ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                final_df = current_df
        else:
            final_df = current_df
        
        final_df = final_df.sort_values(by="ConnectionCount", ascending=False)
        
        # UI: ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì„¤ì •
        st.subheader("ë¬¼ë¦¬ì  ê´€ê³„ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ ì„¤ì •")
        final_df['exclusive_bool'] = final_df['exclusive'].astype(bool)
        
        edited_df = st.data_editor(
            final_df,
            column_config={"exclusive_bool": st.column_config.CheckboxColumn("ì œì™¸"), "exclusive": None},
            disabled=["ColumnName", "OracleType", "ConnectionCount"],
            hide_index=True, width='stretch', key="ex_editor_select_files"
        )
        
        if st.button("ì„¤ì • ì €ì¥í•˜ê¸°", type="primary", key="save_exclusive_select_files"):
            save_df = edited_df.copy()
            save_df['exclusive'] = save_df['exclusive_bool'].astype(int)
            OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
            save_df.drop(columns=['exclusive_bool']).to_csv(EXCLUSIVE_FILE, index=False, encoding='utf-8-sig')
            st.toast("ì„¤ì •ì´ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!", icon="âœ…")
            st.rerun()
        
        return edited_df[edited_df['exclusive_bool'] == True]['ColumnName'].tolist()
    
    # 2. ë°ì´í„° ëª¨ë¸ ì¼ê´€ì„± ë¶„ì„ ê¸°ëŠ¥
    def render_consistency_checks_inline(df):
        st.write("---")
        st.subheader("ğŸ§ª 2. ë°ì´í„° ëª¨ë¸ ì¼ê´€ì„± ë¶„ì„")
        tab_inner1, tab_inner2 = st.tabs(["âš ï¸ OracleType ë¶ˆì¼ì¹˜", "ğŸ“ Format ë¶ˆì¼ì¹˜ (FormatCnt â‰¤ 3)"])
        
        with tab_inner1:
            # Group By: ColumnName, OracleType ë³„ ê±´ìˆ˜ ë° íŒŒì¼ ë¦¬ìŠ¤íŠ¸
            type_group = df.groupby(['ColumnName', 'OracleType']).agg(
                Count=('FileName', 'count'),
                FileList=('FileName', lambda x: ", ".join(sorted(x.unique())))
            ).reset_index()
            
            # 2ê°œ ì´ìƒì˜ íƒ€ì…ì„ ê°€ì§„ ì»¬ëŸ¼ëª… ì¶”ì¶œ
            diff_type_cols = type_group.groupby('ColumnName').filter(lambda x: len(x) > 1)['ColumnName'].unique()
            
            if len(diff_type_cols) > 0:
                st.warning(f"ë™ì¼ ì»¬ëŸ¼ëª… ë‚´ OracleTypeì´ ë‹¤ë¥¸ ì‚¬ë¡€: {len(diff_type_cols)}ê±´")
                res_type = type_group[type_group['ColumnName'].isin(diff_type_cols)]
                st.dataframe(res_type.sort_values('ColumnName'), width='stretch', hide_index=True)
            else:
                st.success("ëª¨ë“  ë™ì¼ ì»¬ëŸ¼ì˜ OracleTypeì´ ì¼ì¹˜í•©ë‹ˆë‹¤.")
        
        with tab_inner2:
            if 'Format' in df.columns and 'FormatCnt' in df.columns:
                f_base = df[df['FormatCnt'] <= 3].copy()
                # Group By: ColumnName, Format ë³„ ê±´ìˆ˜ ë° íŒŒì¼ ë¦¬ìŠ¤íŠ¸
                format_group = f_base.groupby(['ColumnName', 'Format']).agg(
                    Count=('FileName', 'count'),
                    FileList=('FileName', lambda x: ", ".join(sorted(x.unique())))
                ).reset_index()
                
                diff_format_cols = format_group.groupby('ColumnName').filter(lambda x: len(x) > 1)['ColumnName'].unique()
                
                if len(diff_format_cols) > 0:
                    st.warning(f"FormatCnt 3ì´í•˜ ì»¬ëŸ¼ ì¤‘ Format ë¶ˆì¼ì¹˜: {len(diff_format_cols)}ê±´")
                    res_format = format_group[format_group['ColumnName'].isin(diff_format_cols)]
                    st.dataframe(res_format.sort_values('ColumnName'), width='stretch', hide_index=True)
                else:
                    st.success("ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ì»¬ëŸ¼ì˜ Formatì´ ì¼ì¹˜í•©ë‹ˆë‹¤.")
            else:
                st.info("Format ì •ë³´ê°€ ë°ì´í„°í”„ë ˆì„ì— ì—†ìŠµë‹ˆë‹¤.")
    
    # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì„¤ì • ì‹¤í–‰
    blacklist = manage_exclusive_config_inline(df_cm_master)
    if blacklist:
        st.caption(f"í˜„ì¬ ì œì™¸ëœ ì»¬ëŸ¼ ìˆ˜: {len(blacklist)}ê°œ")
    
    # ë°ì´í„° ëª¨ë¸ ì¼ê´€ì„± ë¶„ì„ ì‹¤í–‰ (ë³„ë„ í”„ë¡œê·¸ë¨ì—ì„œ í™œìš©í•  ì˜ˆì •)
    # render_consistency_checks_inline(df_cm_master)

# -------------------------------------------------
# 7. íŒŒì¼ ì„ íƒ ê´€ë ¨ í•¨ìˆ˜ (File Selection)
# -------------------------------------------------
def prepare_file_selection_data(df_cr, df_cm=None, df_ex=None):
    """
    íŒŒì¼ ì„ íƒì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜
    
    Args:
        df_cr: ë…¼ë¦¬ì  ì •ë³´ë¥¼ ì¶”ì¶œí•  ë°ì´í„°í”„ë ˆì„ (CodeMapping_erd.csv ë˜ëŠ” CodeMapping.csv)
        df_ex: ERD_exclusive.csv (ì œì™¸í•  ì»¬ëŸ¼ ì •ë³´)
    
    Returns:
        tuple: (total_df, df_cm) - ì¤€ë¹„ëœ ë°ì´í„°í”„ë ˆì„ê³¼ ì›ë³¸ df_cm
        None: í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ
    """
    # df_cmì´ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ df_input ì‚¬ìš©
    if df_cm is None:
        df_cm = df_cr

    # df_exì—ì„œ exclusive == 1ì¸ ì»¬ëŸ¼ ì œì™¸ ëª©ë¡ ìƒì„±
    excluded_columns = set()
    if df_ex is not None and not df_ex.empty:
        if 'ColumnName' in df_ex.columns and 'exclusive' in df_ex.columns:
            excluded_df = df_ex[df_ex['exclusive'] == 1]
            if not excluded_df.empty:
                excluded_columns = set(excluded_df['ColumnName'].astype(str).str.strip().unique())
    
    # ì´ˆê¸° ë°ì´í„°í”„ë ˆì„ì—ì„œ exclusive == 1ì¸ ì»¬ëŸ¼ ì œì™¸
    df_cr_filtered = df_cr.copy()
    df_cm_filtered = df_cm.copy()
    
    if excluded_columns:
        # df_inputì—ì„œ ì œì™¸
        if 'ColumnName' in df_cr_filtered.columns:
            df_cr_filtered = df_cr_filtered[
                ~df_cr_filtered['ColumnName'].astype(str).str.strip().isin(excluded_columns)
            ]
        
        # df_cmì—ì„œ ì œì™¸
        if 'ColumnName' in df_cm_filtered.columns:
            df_cm_filtered = df_cm_filtered[
                ~df_cm_filtered['ColumnName'].astype(str).str.strip().isin(excluded_columns)
            ]

    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_cols = ['FileName', 'ColumnName', 'FilePath', 'PK']
    if not all(col in df_cm_filtered.columns for col in required_cols):
        st.warning("CodeMapping.csvì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼(FileName, ColumnName, FilePath, PK)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    # 1. ë…¼ë¦¬ì  íŒŒì¼ ìš”ì•½ ì •ë³´ ìƒì„± (df_input_filtered ì‚¬ìš© - Level_Relationship_Internal í¬í•¨ ê°€ëŠ¥)
    summary_df = export_summary_result(df_cr_filtered)

    # 2. PK ì»¬ëŸ¼ ì •ë³´ ì¶”ì¶œ (df_cm_filtered ì‚¬ìš©)
    pk_cols = df_cm_filtered[df_cm_filtered['PK'] == 1].groupby('FileName')['ColumnName'].apply(
        lambda x: ', '.join([str(item) for item in x if pd.notna(item) and str(item).strip()])
    ).reset_index()
    pk_cols.columns = ['FileName', 'PK Columns']

    # 3. ë¬¼ë¦¬ì  ê´€ê³„ ê³„ì¸µ ì •ë³´ ê³„ì‚° (precompute_physical_hierarchy ê²°ê³¼, df_cm_filtered ì‚¬ìš©)
    if 'physical_hierarchy_df' not in st.session_state:
        st.session_state.physical_hierarchy_df = precompute_physical_hierarchy(df_cm_filtered)
    physical_hierarchy_df = st.session_state.physical_hierarchy_df

    # 4. ëª¨ë“  ì •ë³´ í†µí•© (PK Columns + Summary + Physical Hierarchy)
    # summary_dfì— ì´ë¯¸ ë…¼ë¦¬ì  ì •ë³´(Column #, Max_Level, Rel Table #, Related Files List)ê°€ í¬í•¨ë˜ì–´ ìˆìŒ
    total_df = pd.merge(pk_cols, summary_df, on='FileName', how='left')
    total_df = pd.merge(total_df, physical_hierarchy_df, on='FileName', how='left')
    total_df = total_df[(total_df['Column #'].fillna(0) > 1)]
    total_df = total_df.sort_values(by='FileName')

    # 5. ì„ íƒ ì²´í¬ë°•ìŠ¤ ì»¬ëŸ¼ ì¶”ê°€
    total_df['ì„ íƒ'] = False

    # 6. ì»¬ëŸ¼ ìˆœì„œ : ì„ íƒ -> ê¸°ë³¸ ì •ë³´ -> ë¬¼ë¦¬ì  ê´€ê³„ ì •ë³´ -> ë…¼ë¦¬ì  ê´€ê³„ ì •ë³´ -> ì¶”ê°€ ì •ë³´
    base_cols = ['ì„ íƒ', 'FileName', 'PK Columns']
    physical_cols = ['Level1_Cnt', 'Level2_Cnt', 'Level3_Cnt', 'Total_Related', 'Related_List']
    logical_cols = ['Column #', 'Max_Level', 'Rel Table #', 'Related Files List']
    extra_cols = ['FilePath']

    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    cols_order = []
    for col_group in [base_cols, physical_cols, logical_cols, extra_cols]:
        cols_order.extend([col for col in col_group if col in total_df.columns])

    total_df = total_df[cols_order]
    
    return total_df, df_cm

def select_files(df_cr, df_cm=None, df_ex=None) -> list:
    """
    2nd Step: File Information
    ë…¼ë¦¬ì  ì—°ê²°ê´€ê³„(logical_cols) ì •ë³´ë¥¼ êµ¬í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ì—ë„ í•¨ìˆ˜ê°€ ì—ëŸ¬ ì—†ì´ ë™ì‘í•˜ë„ë¡ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    df_cr: ë…¼ë¦¬ì  ì •ë³´ë¥¼ ì¶”ì¶œí•  ë°ì´í„°í”„ë ˆì„ (CodeMapping_erd.csv ë˜ëŠ” CodeMapping.csv)
    df_ex: ERD_exclusive.csv (ì œì™¸í•  ì»¬ëŸ¼ ì •ë³´)
    """
    st.subheader("File Information & Select File")
    
    # ë°ì´í„° ì¤€ë¹„
    total_df, df_cm = prepare_file_selection_data(df_cr, df_cm, df_ex)
    if total_df is None:
        return None

    tab1, tab2, tab3, tab4 = st.tabs(["ë¶„ì„ íŒŒì¼ ì„ íƒ", "ë¬¼ë¦¬ì  ì—°ê²°ê´€ê³„ ì •ë³´", "ë…¼ë¦¬ì  ì—°ê²°ê´€ê³„ ì •ë³´", "ì»¬ëŸ¼ ì œì–´ ì„¤ì •"])
    with tab1:
        st.write("íŒŒì¼ë³„ ë¬¼ë¦¬ì , ë…¼ë¦¬ì  ì—°ê²°ê´€ê³„ ì •ë³´ ìš”ì•½ì…ë‹ˆë‹¤. (ì»¬ëŸ¼í—¤ë“œì— ë§ˆìš°ìŠ¤ë¥¼ ìœ„ì¹˜í•˜ë©´ ì„¤ëª…ì´ ìˆìŠµë‹ˆë‹¤)")
        cols = ['ì„ íƒ', 'FileName', 'PK Columns', 'Column #', 'Level1_Cnt', 'Level2_Cnt', 'Level3_Cnt', 'Total_Related', 'Rel Table #', 'Max_Level']
        select_df = total_df[cols].copy()
        select_df = st.data_editor(select_df, hide_index=True, width=1600, height=500, column_config={
            'ì„ íƒ': st.column_config.CheckboxColumn('ì„ íƒ', width=80),
            'FileName': st.column_config.TextColumn(help='íŒŒì¼ ì´ë¦„', width=150),
            'PK Columns': st.column_config.TextColumn('PKì»¬ëŸ¼', help='PK ì»¬ëŸ¼', width=100),
            'Column #': st.column_config.NumberColumn('ì»¬ëŸ¼ìˆ˜', help='ì»¬ëŸ¼ ìˆ˜', width=50),
            'Level1_Cnt': st.column_config.NumberColumn('1ê´€ê³„', help='ë¬¼ë¦¬ì  1ë‹¨ê³„ ì—°ê²° íŒŒì¼ ìˆ˜', width=50),
            'Level2_Cnt': st.column_config.NumberColumn('2ê´€ê³„', help='ë¬¼ë¦¬ì  2ë‹¨ê³„ ì—°ê²° íŒŒì¼ ìˆ˜', width=50),
            'Level3_Cnt': st.column_config.NumberColumn('3ê´€ê³„', help='ë¬¼ë¦¬ì  3ë‹¨ê³„ ì—°ê²° íŒŒì¼ ìˆ˜', width=50),
            'Total_Related': st.column_config.NumberColumn('ë¬¼ë¦¬ê´€ê³„', help='ë¬¼ë¦¬ì  ì´ ì—°ê²° íŒŒì¼ ìˆ˜', width=80),
            'Rel Table #': st.column_config.NumberColumn('ë…¼ë¦¬ê´€ê³„', help='ë…¼ë¦¬ì  íŒŒì¼ ì—°ê²° ê·¸ë£¹ ê°œìˆ˜', width=80),
        })

    with tab2:
        cols = ['FileName', 'PK Columns', 'Column #', 'Level1_Cnt', 'Level2_Cnt', 'Level3_Cnt', 'Total_Related', 'Related_List', 'FilePath']
        display_df = total_df[cols].copy()
        st.write("íŒŒì¼ë³„ ë¬¼ë¦¬ì  ì—°ê²°ê´€ê³„ ì •ë³´ ìš”ì•½ì…ë‹ˆë‹¤. (ì»¬ëŸ¼í—¤ë“œì— ë§ˆìš°ìŠ¤ë¥¼ ìœ„ì¹˜í•˜ë©´ ì„¤ëª…ì´ ìˆìŠµë‹ˆë‹¤)")
        st.dataframe(display_df, hide_index=True, width=1200, height=500, column_config={
            'FileName': st.column_config.TextColumn(help='íŒŒì¼ ì´ë¦„', width=150),
            'PK Columns': st.column_config.TextColumn('PKì»¬ëŸ¼', help='PK ì»¬ëŸ¼', width=100),
            'Column #': st.column_config.NumberColumn('ì»¬ëŸ¼ìˆ˜', help='ì»¬ëŸ¼ ìˆ˜', width=50),
            'Level1_Cnt': st.column_config.NumberColumn('1ê´€ê³„', help='ë¬¼ë¦¬ì  1ë‹¨ê³„ ì—°ê²° íŒŒì¼ ìˆ˜', width=50),
            'Level2_Cnt': st.column_config.NumberColumn('2ê´€ê³„', help='ë¬¼ë¦¬ì  2ë‹¨ê³„ ì—°ê²° íŒŒì¼ ìˆ˜', width=50),
            'Level3_Cnt': st.column_config.NumberColumn('3ê´€ê³„', help='ë¬¼ë¦¬ì  3ë‹¨ê³„ ì—°ê²° íŒŒì¼ ìˆ˜', width=50),
            'Total_Related': st.column_config.NumberColumn('ë¬¼ë¦¬ê´€ê³„', help='ë¬¼ë¦¬ì  ì´ ì—°ê²° íŒŒì¼ ìˆ˜', width=50),
            'Related_List': st.column_config.TextColumn('ë¬¼ë¦¬ê´€ê³„íŒŒì¼', help='ë¬¼ë¦¬ì  ì—°ê²°ëœ íŒŒì¼ ëª©ë¡', width=150),
        })
    with tab3:
        cols = ['FileName', 'PK Columns', 'Column #', 'Max_Level', 'Rel Table #', 'Related_List']
        display_df = total_df[cols].copy()
        st.write("íŒŒì¼ë³„ ë…¼ë¦¬ì  ì—°ê²°ê´€ê³„ ì •ë³´ ìš”ì•½ì…ë‹ˆë‹¤. (ì»¬ëŸ¼í—¤ë“œì— ë§ˆìš°ìŠ¤ë¥¼ ìœ„ì¹˜í•˜ë©´ ì„¤ëª…ì´ ìˆìŠµë‹ˆë‹¤)")
        st.dataframe(display_df, hide_index=True, width=1200, height=500, column_config={
            'FileName': st.column_config.TextColumn(help='íŒŒì¼ ì´ë¦„', width=150),
            'PK Columns': st.column_config.TextColumn('PKì»¬ëŸ¼', help='PK ì»¬ëŸ¼', width=100),
            'Column #': st.column_config.NumberColumn('ì»¬ëŸ¼ìˆ˜', help='ì»¬ëŸ¼ ìˆ˜', width=50),
            'Max_Level': st.column_config.NumberColumn('ë…¼ë¦¬ë ˆë²¨', help='ë…¼ë¦¬ì  ìµœëŒ€ ë ˆë²¨', width=50),
            'Rel Table #': st.column_config.NumberColumn('ë…¼ë¦¬ê´€ê³„', help='ë…¼ë¦¬ì  íŒŒì¼ ì—°ê²° ê·¸ë£¹ ê°œìˆ˜', width=50),
            'Related_List': st.column_config.TextColumn('ë…¼ë¦¬ê´€ê³„íŒŒì¼', help='ë…¼ë¦¬ì  ì—°ê²°ëœ íŒŒì¼ ëª©ë¡', width=150),
        })
    
    with tab4:
        # ì»¬ëŸ¼ ì œì–´ ì„¤ì • íƒ­ ë Œë”ë§
        render_column_control_tab(df_cm)

    # 8. ì„ íƒëœ í…Œì´ë¸” ì¶”ì¶œ
    selected_files = select_df[select_df['ì„ íƒ'] == True]['FileName'].tolist()
    
    if not selected_files:
        st.info(f"íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”. ê´€ê³„ìˆ˜ê°€ ë§ì€ë©´ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±ì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return None

    return selected_files
#-----------------------------------------------------------------------------------------
# -------------------------------------------------
# 11. ERD í‘œì‹œ í•¨ìˆ˜ (ERD Display)
# -------------------------------------------------
def generate_logical_erd(selected_files, pk_map, it_df, show_all_columns:bool):
    """
    selected_files: ì„ íƒí•œ íŒŒì¼í…Œì´ë¸” ë¦¬ìŠ¤íŠ¸
    pk_map: PK ì»¬ëŸ¼ ë§µ
    it_df: CodeMapping_erd.csv ë°ì´í„°í”„ë ˆì„
    show_all_columns: ìƒì„¸ ì •ë³´ í‘œì‹œ ì—¬ë¶€
    """
    
    st.write("---")
    st.subheader("âš™ï¸ Logical ERD ìƒì„± ë° íƒìƒ‰ ì„¤ì •")
    
    anchor_table = selected_files[0] if isinstance(selected_files[0], str) else str(selected_files[0])

    try:
        # ê´€ë ¨ í…Œì´ë¸” íƒìƒ‰
        related_tables = get_related_tables(selected_files, it_df)
        
        related_table_count = len(related_tables) # ì—°ê²°ëœ í…Œì´ë¸” ìˆ˜
        
        if related_table_count > MAX_RELATED_TABLE_COUNT:
            st.error(f"ì—°ê²°ëœ í…Œì´ë¸” ìˆ˜ê°€ {MAX_RELATED_TABLE_COUNT}ê°œë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
            return False
        
        if not related_tables or len(related_tables) == 0:
            st.warning(f"âš ï¸ '{anchor_table}'ì™€ ì—°ê²°ëœ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # related_tablesë¥¼ setìœ¼ë¡œ ë³€í™˜
            if isinstance(related_tables, list):
                related_list = related_tables
            else:
                related_list = list(related_tables) if hasattr(related_tables, '__iter__') else [related_tables]
            
            # ERD ìƒì„±
            dot, edge_count, erd_info = generate_logical_erd_image(selected_files, set(related_list), pk_map, it_df, show_all_columns)
            
            if dot:
                suffix = f"Logical_{anchor_table}"
                display_erd_with_download(dot, suffix, edge_count)
                st.success(f"âœ… ë¶„ì„ ì™„ë£Œ: ì´ {len(related_list)}ê°œ í…Œì´ë¸” ì—°ê²°ë¨")
    except Exception as e:
        st.error(f"âŒ ERD ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        import traceback
        st.error(traceback.format_exc())

#-----------------------------------------------------------------------------------------
def display_erd_result(selected_files, pk_map, it_df):
    """     4th Step: Data Relationship Diagram ê²°ê³¼ ìš”ì•½    """
    st.divider()
    st.subheader("3. Data Relationship Diagram ê²°ê³¼ ìš”ì•½")

    related_tables = get_related_tables(selected_files, it_df)

    tab1, tab2, tab3 = st.tabs(["Data Relationship Diagram ê²°ê³¼ ìš”ì•½", "ì„ íƒëœ í…Œì´ë¸” ìƒì„¸ ì •ë³´", "ê´€ê³„ëœ í…Œì´ë¸” ìƒì„¸ ì •ë³´"])
    with tab1:
        erd_result_df = create_erd_result_dataframe(selected_files, related_tables, pk_map, it_df)
        st.dataframe(
            erd_result_df, hide_index=True, width='stretch', height=500,
            column_config={
                'í…Œì´ë¸”ëª…': st.column_config.TextColumn('í…Œì´ë¸”ëª…', width=150),
                'ì„ íƒì—¬ë¶€': st.column_config.TextColumn('ì„ íƒ', width=50),
                'PK ì»¬ëŸ¼': st.column_config.TextColumn('PK ì»¬ëŸ¼', width=150),
                'FK ì»¬ëŸ¼': st.column_config.TextColumn('FK ì»¬ëŸ¼', width=150),
                'Parent í…Œì´ë¸”': st.column_config.TextColumn('Parent í…Œì´ë¸”', width=200),
                'Child í…Œì´ë¸”': st.column_config.TextColumn('Child í…Œì´ë¸”', width=200),
                'ê´€ê³„ ìˆ˜': st.column_config.NumberColumn('ê´€ê³„ ìˆ˜', width=50)
            }
        )

    with tab2:
        selected_files_df = it_df[it_df['FileName'].isin(selected_files)]
        selected_files_df = selected_files_df.drop(columns=['FilePath'])
        st.dataframe(selected_files_df, hide_index=True, width=1000, height=500)

    with tab3:
        related_tables_df = it_df[it_df['FileName'].isin(related_tables)]
        related_tables_df = related_tables_df.drop(columns=['FilePath'])
        st.dataframe(related_tables_df, hide_index=True, width=1000, height=500)

    st.divider()
    summary = {
        "ì´ í…Œì´ë¸” ìˆ˜": f"{len(erd_result_df)}",
        "ì„ íƒëœ í…Œì´ë¸” ìˆ˜": f"{len(erd_result_df[erd_result_df['ì„ íƒì—¬ë¶€'] == 'âœ“'])}",
        "ì´ ê´€ê³„ ìˆ˜": f"{erd_result_df['ê´€ê³„ ìˆ˜'].sum()}",
        "PK ë³´ìœ  í…Œì´ë¸”": f"{len(erd_result_df[erd_result_df['PK ì»¬ëŸ¼'] != ''])}"
    }

    metric_colors = {
        "ì´ í…Œì´ë¸” ìˆ˜":     "#1f77b4",       # íŒŒë‘ìƒ‰
        "ì„ íƒëœ í…Œì´ë¸” ìˆ˜":  "#2ca02c",       # ì´ˆë¡ìƒ‰
        "ì´ ê´€ê³„ ìˆ˜":       "#9467bd",       # ë³´ë¼ìƒ‰
        "PK ë³´ìœ  í…Œì´ë¸”":   "#ff7f0e",       # ë¹¨ê°•ìƒ‰
    }

    display_kpi_metrics(summary, metric_colors, 'Data Relationship Diagram ê²°ê³¼ ìš”ì•½ ì§€í‘œ')

#-----------------------------------------------------------------------------------------
# ERD ìƒì„± Function
# 6. ë¬¼ë¦¬ì  ê³„ì¸µ ë¶„ì„ í•¨ìˆ˜ (Physical Hierarchy Analysis)
#-----------------------------------------------------------------------------------------
def precompute_physical_hierarchy(df):
    """ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ 4ë‹¨ê³„ê¹Œì§€ì˜ ë¬¼ë¦¬ì  ê´€ê³„ ê³„ì¸µì„ ê³„ì‚°"""
    # 1. ì¸ë±ì‹± (ì´ì „ ë¡œì§ ë™ì¼)
    table_to_cols = defaultdict(dict)
    col_to_tables = defaultdict(set)
    for _, row in df.iterrows():
        f, c, pk, o = str(row['FileName']), str(row['ColumnName']), str(row['PK']), str(row['OracleType'])
        # ë‚ ì§œ ë° ê³µí†µí•„ë“œ ì œì™¸ ë¡œì§ ì ìš© (ìƒëµ)
        table_to_cols[f][c] = pk.upper() in ['1', 'Y', 'TRUE']
        col_to_tables[c].add(f)

    # 2. ì „ìˆ˜ ì¡°ì‚¬
    hierarchy_data = []
    all_tables = sorted(table_to_cols.keys())

    for start_node in all_tables:
        levels = {0: {start_node}}
        visited = {start_node}
        
        for i in range(1, 4): # 3ë‹¨ê³„ê¹Œì§€
            next_layer = set()
            for current_node in levels[i-1]:
                if current_node not in table_to_cols: continue
                for col, is_pk in table_to_cols[current_node].items():
                    neighbors = col_to_tables.get(col, set())
                    for nb in neighbors:
                        if nb not in visited:
                            # ë¬¼ë¦¬ì  ê´€ê³„ ì„±ë¦½ ì¡°ê±´
                            if is_pk or table_to_cols[nb].get(col, False):
                                next_layer.add(nb)
                                visited.add(nb)
            levels[i] = next_layer
        
        hierarchy_data.append({
            "FileName": start_node,
            "Level1_Cnt": len(levels[1]),
            "Level2_Cnt": len(levels[2]),
            "Level3_Cnt": len(levels[3]),
            "Total_Related": len(visited) - 1,
            "Related_List": ", ".join(list(visited)[1:6]) # + "..." ì¼ë¶€ ìƒ˜í”Œ í‘œì‹œ
        })
    
    return pd.DataFrame(hierarchy_data)

def get_physical_n_level_tables(codemapping_df, start_table, level, df_ex:pd.DataFrame = None):
    """
    ë¬¼ë¦¬ì  ì»¬ëŸ¼ ë§¤ì¹­ ê¸°ë°˜ N-Level í…Œì´ë¸” íƒìƒ‰ (ì‹¬ì¸µ íƒìƒ‰ ë³´ê°•) 
    df_ex: ERD_exclusive.csv ë°ì´í„°í”„ë ˆì„ (ì œì™¸í•  ì»¬ëŸ¼ ì •ë³´)
    ë°˜í™˜: (í…Œì´ë¸” ë¦¬ìŠ¤íŠ¸, í…Œì´ë¸”ë³„ ë ˆë²¨ ë”•ì…”ë„ˆë¦¬)
    """
    
    # df_exì—ì„œ exclusive == 1ì¸ ì»¬ëŸ¼ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ìƒì„±
    blacklist_columns = set()
    if df_ex is not None and not df_ex.empty:
        if 'ColumnName' in df_ex.columns and 'exclusive' in df_ex.columns:
            # exclusive == 1ì¸ ì»¬ëŸ¼ëª… ì¶”ì¶œ
            excluded_df = df_ex[df_ex['exclusive'] == 1]
            if not excluded_df.empty:
                blacklist_columns = set(excluded_df['ColumnName'].astype(str).str.strip().unique())
    
    # 3. ê³ ì† íƒìƒ‰ì„ ìœ„í•œ ë°ì´í„° êµ¬ì¡° ë¹Œë“œ
    # table_to_cols: { í…Œì´ë¸”ëª…: { ì»¬ëŸ¼ëª…: PKì—¬ë¶€ } }
    # col_to_tables: { ì»¬ëŸ¼ëª…: { í…Œì´ë¸”ëª…1, í…Œì´ë¸”ëª…2 } }
    table_to_cols = defaultdict(dict)
    col_to_tables = defaultdict(set)
    
    for _, row in codemapping_df.iterrows():
        f_name = str(row['FileName']).strip()
        c_name = str(row['ColumnName']).strip()
        is_pk = str(row['PK']).upper() in ['1', '1.0', 'Y', 'TRUE']
        
        # ì œì™¸ ì¡°ê±´ í•„í„°ë§ (ë¸”ë™ë¦¬ìŠ¤íŠ¸ë§Œ)
        if c_name in blacklist_columns:
            continue
            
        table_to_cols[f_name][c_name] = is_pk
        col_to_tables[c_name].add(f_name)

    # 3. N-Level íƒìƒ‰ (BFS) - ë ˆë²¨ ì •ë³´ ì¶”ì 
    visited_tables = {start_table}
    table_levels = {start_table: 0}  # ê° í…Œì´ë¸”ì˜ ë ˆë²¨ ì •ë³´
    current_layer = {start_table}
    
    # ì§€ì •ëœ levelë§Œí¼ ë°˜ë³µ íƒìƒ‰
    for i in range(level):
        next_layer = set()
        
        for table in current_layer:
            # í˜„ì¬ ë ˆì´ì–´ì˜ í…Œì´ë¸”ì´ ê°€ì§„ ëª¨ë“  ì»¬ëŸ¼ì„ ì¡°ì‚¬
            my_columns = table_to_cols.get(table, {})
            
            for col_name, my_is_pk in my_columns.items():
                # í•´ë‹¹ ì»¬ëŸ¼ì„ ê³µìœ í•˜ëŠ” ë‹¤ë¥¸ í…Œì´ë¸”ë“¤(ì´ì›ƒ)ì„ ì°¾ìŒ
                potential_neighbors = col_to_tables.get(col_name, set())
                
                for neighbor in potential_neighbors:
                    if neighbor in visited_tables:
                        continue
                    
                    # [í•µì‹¬] ë¬¼ë¦¬ì  ê´€ê³„ ì„±ë¦½ ì¡°ê±´: 
                    # ë‚´ ì»¬ëŸ¼ì´ PKê±°ë‚˜, ìƒëŒ€ë°©ì˜ ë™ì¼í•œ ì»¬ëŸ¼ì´ PKì—¬ì•¼ í•¨
                    neighbor_is_pk = table_to_cols[neighbor].get(col_name, False)
                    
                    if my_is_pk or neighbor_is_pk:
                        next_layer.add(neighbor)
                        visited_tables.add(neighbor)
                        table_levels[neighbor] = i + 1  # ë ˆë²¨ ì •ë³´ ì €ì¥
        
        # ë‹¤ìŒ ë ˆì´ì–´ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
        if not next_layer:
            break
        current_layer = next_layer
        
    return list(visited_tables), table_levels

# -------------------------------------------------
# 8. ERD ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ERD Utilities)
# -------------------------------------------------
def get_optimal_dpi(table_count: int) -> str:
    """í…Œì´ë¸” ìˆ˜ì— ë”°ë¼ ê°€ë…ì„±ì´ ê°€ì¥ ì¢‹ì€ DPI ë°˜í™˜"""
    if table_count <= 10: return '100'   # ì ì€ í…Œì´ë¸”ì€ ë„ˆë¬´ í¬ì§€ ì•Šê²Œ
    if table_count <= 20: return '200'  # ì¤‘ê°„ ê·œëª¨
    if table_count <= 50: return '300'  # ê³ í•´ìƒë„ í•„ìš”
    return '450' # ëŒ€ê·œëª¨ ê´€ê³„ë§ (í™•ëŒ€ìš©)

def display_erd_with_download(dot, suffix: str, table_count: int):
    """ERD í‘œì‹œ ë° ê³ í•´ìƒë„ ë‹¤ìš´ë¡œë“œ ê³µí†µ ì²˜ë¦¬"""
    # st.subheader(f"ğŸ“Š {suffix} ë‹¤ì´ì–´ê·¸ë¨")
    st.write(f"ğŸ” ë¶„ì„ ì™„ë£Œ: ì´ {table_count}ê°œ í…Œì´ë¸”ì´ ë‹¤ì´ì–´ê·¸ë¨ì— í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 1. í™”ë©´ í‘œì‹œìš© (Streamlit ê¸°ë³¸ ë Œë”ë§)
    st.graphviz_chart(dot, width='stretch')
    
    # 2. ê³ í•´ìƒë„ íŒŒì¼ ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    file_time = datetime.now().strftime("%Y%m%d_%H%M%S")
    # filename = f"ERD_{suffix}_{file_time}"
    filename = f"ERD_{suffix}"
    
    # DPI ì„¤ì • ì ìš©
    dpi_val = get_optimal_dpi(table_count)
    dot.attr(dpi=dpi_val)
    
    try:
        IMAGE_DIR.mkdir(parents=True, exist_ok=True)
        output_path_no_ext = IMAGE_DIR / filename
        
        # íŒŒì¼ ì €ì¥
        rendered_path = dot.render(str(output_path_no_ext), format='png', cleanup=True)
        actual_path = Path(rendered_path)
        
        if actual_path.exists():
            with open(actual_path, "rb") as f:
                st.download_button(
                    label=f"ğŸ’¾ PNG ë‹¤ìš´ë¡œë“œ ",
                    data=f.read(),
                    file_name=actual_path.name,
                    mime="image/png",
                    key=f"dl_{filename}"
                )
    except Exception as e:
        st.warning(f"âš ï¸ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìœ¼ë‚˜ ì°¨íŠ¸ëŠ” í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤: {e}")

# -------------------------------------------------
# 9. ERD ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (ERD Image Generation)
# -------------------------------------------------
def generate_physical_erd_image(codemapping_df, df_ex, selected_files, related_tables, show_all_columns=False, table_levels=None):
    """
    ë¬¼ë¦¬ì  ê´€ê³„ ê¸°ë°˜ ERD ìƒì„± (N-Level ì§ì ‘ ì—°ê²°ë§Œ í‘œì‹œ)
    table_levels: {í…Œì´ë¸”ëª…: ë ˆë²¨} ë”•ì…”ë„ˆë¦¬ (ì„ íƒëœ í…Œì´ë¸”ì€ ë ˆë²¨ 0)
    """
    # ì´ˆê¸° í…Œì´ë¸” ì…‹ ì„¤ì •
    related_tables_set = set(related_tables)
    
    # ë ˆë²¨ ì •ë³´ê°€ ì—†ìœ¼ë©´ ëª¨ë“  í…Œì´ë¸”ì„ ë ˆë²¨ 0ìœ¼ë¡œ ì„¤ì •
    if table_levels is None:
        table_levels = {table: 0 for table in related_tables_set}
        for table in selected_files:
            table_levels[table] = 0
    
    # 1. ë¸”ë™ë¦¬ìŠ¤íŠ¸(exclusive) ì²˜ë¦¬
    ex_cols = set()
    if df_ex is not None and not df_ex.empty and 'exclusive' in df_ex.columns:
        ex_cols = set(df_ex[df_ex['exclusive'] == 1]['ColumnName'].astype(str).str.strip().unique())

    # 2. ë°ì´í„° ì¸ë±ì‹± (ì„±ëŠ¥ ìµœì í™”)
    table_info = defaultdict(dict)
    col_to_tables = defaultdict(set)
    
    for _, row in codemapping_df.iterrows():
        f = str(row['FileName']).strip()
        c = str(row['ColumnName']).strip()
        is_pk = str(row.get('PK', '')).upper() in ['1', '1.0', 'Y', 'TRUE']
        o_type = str(row.get('OracleType', '')).strip().upper()
        
        table_info[f][c] = {'is_pk': is_pk, 'o_type': o_type}
        if c not in ex_cols:
            col_to_tables[c].add(f)

    # 3. N-Level ê´€ê³„ ì¶”ë¡  (ì¸ì ‘í•œ ë ˆë²¨ ê°„ì˜ ê´€ê³„ë§Œ ì°¾ê¸° - ì§ì ‘ ì—°ê²°ë§Œ í‘œì‹œ)
    # ì„ íƒëœ í…Œì´ë¸”(ë ˆë²¨ 0)ê³¼ ì§ì ‘ ì—°ê²°ëœ ë ˆë²¨ 1 í…Œì´ë¸” ê°„ì˜ ê´€ê³„ë§Œ ì°¾ìŒ
    # ë ˆë²¨ 1ê³¼ ë ˆë²¨ 2 ê°„ì˜ ê´€ê³„ë„ ì°¾ì§€ë§Œ, ê°™ì€ ë ˆë²¨ ë‚´ ê´€ê³„ëŠ” ì°¾ì§€ ì•ŠìŒ
    fk_candidates = set()
    
    # related_tables_setì— í¬í•¨ëœ í…Œì´ë¸”ë“¤ ê°„ì˜ ê´€ê³„ ì°¾ê¸° (ë ˆë²¨ ì œí•œ ì ìš©)
    for from_table in related_tables_set:
        if from_table not in table_info: continue
        
        from_level = table_levels.get(from_table, 0)
        
        for col, info in table_info[from_table].items():
            if col not in col_to_tables: continue
            
            for to_table in col_to_tables[col]:
                # to_tableë„ related_tables_setì— í¬í•¨ëœ ê²½ìš°ì—ë§Œ ê´€ê³„ ì¶”ê°€
                if to_table not in related_tables_set:
                    continue
                    
                if from_table == to_table: continue
                
                to_level = table_levels.get(to_table, 0)
                
                # ë ˆë²¨ ì œí•œ: ì¸ì ‘í•œ ë ˆë²¨ ê°„ì˜ ê´€ê³„ë§Œ ì°¾ê¸° (ë ˆë²¨ ì°¨ì´ê°€ 1 ì´í•˜)
                # ê°™ì€ ë ˆë²¨ ë‚´ ê´€ê³„ëŠ” ì°¾ì§€ ì•ŠìŒ (ì„±ëŠ¥ í–¥ìƒ ë° ëª…í™•ì„±)
                level_diff = abs(from_level - to_level)
                if level_diff > 1:
                    continue
                
                # ì´ë¯¸ ì°¾ì€ ê´€ê³„ë¼ë©´ ìŠ¤í‚µ
                if (from_table, to_table, col) in fk_candidates or (to_table, from_table, col) in fk_candidates:
                    continue
                
                # ê´€ê³„ ì„±ë¦½ ì¡°ê±´ (ìµœì†Œ í•œìª½ì€ PK)
                to_is_pk = table_info[to_table].get(col, {}).get('is_pk', False)
                if info['is_pk'] or to_is_pk:
                    # ë°©í–¥ì„± ê²°ì • (PKê°€ ë¶€ëª¨, ë ˆë²¨ì´ ë‚®ì€ ìª½ì´ ë¶€ëª¨)
                    if to_is_pk and not info['is_pk']:
                        fk_candidates.add((from_table, to_table, col))
                    elif from_level < to_level:
                        # ë ˆë²¨ì´ ë‚®ì€ ìª½ì´ ë¶€ëª¨
                        fk_candidates.add((from_table, to_table, col))
                    else:
                        fk_candidates.add((to_table, from_table, col))

    fk_candidates = list(fk_candidates)
    display_count = len(related_tables_set)

    # 4. Graphviz ë Œë”ë§ (ì´ì „ê³¼ ë™ì¼)
    dot = Digraph(comment='Physical ERD', encoding='utf-8')
    dot.attr(rankdir='LR', nodesep='0.5', ranksep='1.5', splines='polyline')
    dot.attr('node', fontname='Malgun Gothic', fontsize='10', shape='none')

    for table_name in sorted(related_tables_set):
        is_anchor = table_name in selected_files
        header_bg = '#FFA500' if is_anchor else '#BBDEFB'
        
        label = f'<<TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" PORT="title">'
        label += f'<TR><TD BGCOLOR="{header_bg}"><B>{table_name}</B></TD></TR>'
        
        cols = table_info[table_name]
        involved_cols = {c for f, t, c in fk_candidates if f == table_name or t == table_name}
        
        for c_name in sorted(cols.keys()):
            info = cols[c_name]
            if info['is_pk'] or c_name in involved_cols or (show_all_columns and is_anchor):
                prefix = "ğŸ”‘ " if info['is_pk'] else ("ğŸ”— " if c_name in involved_cols else "  ")
                bg = "#E3F2FD" if info['is_pk'] else "#FFFFFF"
                label += f'<TR><TD ALIGN="LEFT" BGCOLOR="{bg}" PORT="{c_name}">{prefix}{c_name}</TD></TR>'
        
        label += '</TABLE>>'
        dot.node(table_name, label)

    for f_tab, t_tab, col in fk_candidates:
        dot.edge(f'{f_tab}:{col}', f'{t_tab}:{col}', dir='both', 
                 arrowhead='none', arrowtail='crow', color='#444444')

    # ERD ìƒì„± ì •ë³´ ìˆ˜ì§‘
    erd_info = {
        'table_info': table_info,
        'fk_candidates': fk_candidates,
        'related_tables_set': related_tables_set,
        'table_levels': table_levels,
        'involved_cols_by_table': {table: {c for f, t, c in fk_candidates if f == table or t == table} 
                                    for table in related_tables_set},
        'show_all_columns': show_all_columns,
        'selected_files': selected_files,
        'mode': 'Physical'  # ëª¨ë“œ ì •ë³´ ì¶”ê°€
    }
    
    return dot, display_count, erd_info

def generate_combined_erd_image(codemapping_df, df_ex, df_cr, selected_files, related_tables, table_levels, pk_map, it_df, show_all_columns=False):
    """
    Physical & Logical í†µí•© ERD ìƒì„± (ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„)
    - Physical ì—°ê²°ë§Œ: íŒŒë€ìƒ‰ (#0000FF)
    - Logical ì—°ê²°ë§Œ: ë¹¨ê°„ìƒ‰ (#FF0000)
    - ë‘ ê°œ ëª¨ë‘ ì—°ê²°: ë³´ë¼ìƒ‰ (#800080)
    """
    related_tables_set = set(related_tables)
    
    # 1. ë¸”ë™ë¦¬ìŠ¤íŠ¸(exclusive) ì²˜ë¦¬
    ex_cols = set()
    if df_ex is not None and not df_ex.empty and 'exclusive' in df_ex.columns:
        ex_cols = set(df_ex[df_ex['exclusive'] == 1]['ColumnName'].astype(str).str.strip().unique())

    # 2. ë°ì´í„° ì¸ë±ì‹±
    table_info = defaultdict(dict)
    col_to_tables = defaultdict(set)
    
    for _, row in codemapping_df.iterrows():
        f = str(row['FileName']).strip()
        c = str(row['ColumnName']).strip()
        is_pk = str(row.get('PK', '')).upper() in ['1', '1.0', 'Y', 'TRUE']
        o_type = str(row.get('OracleType', '')).strip().upper()
        
        table_info[f][c] = {'is_pk': is_pk, 'o_type': o_type}
        if c not in ex_cols:
            col_to_tables[c].add(f)

    # 3. Physical ê´€ê³„ ì¶”ì¶œ (ì¸ì ‘í•œ ë ˆë²¨ ê°„ì˜ ê´€ê³„ë§Œ)
    physical_edges = set()
    
    for from_table in related_tables_set:
        if from_table not in table_info: continue
        
        from_level = table_levels.get(from_table, 0)
        
        for col, info in table_info[from_table].items():
            if col not in col_to_tables: continue
            
            for to_table in col_to_tables[col]:
                if to_table not in related_tables_set: continue
                if from_table == to_table: continue
                
                to_level = table_levels.get(to_table, 0)
                level_diff = abs(from_level - to_level)
                if level_diff > 1: continue
                
                if (from_table, to_table, col) in physical_edges or (to_table, from_table, col) in physical_edges:
                    continue
                
                to_is_pk = table_info[to_table].get(col, {}).get('is_pk', False)
                if info['is_pk'] or to_is_pk:
                    if to_is_pk and not info['is_pk']:
                        physical_edges.add((from_table, to_table, col))
                    elif from_level < to_level:
                        physical_edges.add((from_table, to_table, col))
                    else:
                        physical_edges.add((to_table, from_table, col))

    # 4. Logical ê´€ê³„ ì¶”ì¶œ (22ë²ˆ íŒŒì¼ê³¼ ë™ì¼í•œ ë¡œì§)
    logical_edges = set()
    logical_edge_details = {}  # {(from_file, to_file): (from_col, to_col)}
    
    # Level_Relationship_Internal ë˜ëŠ” Level_Relationship ì»¬ëŸ¼ í™•ì¸
    if 'Level_Relationship_Internal' in it_df.columns or 'Level_Relationship' in it_df.columns:
        logical_relationships = _extract_relationships_from_erd_logic(selected_files, related_tables_set, it_df)
        for from_file, from_col, to_file, to_col in logical_relationships:
            if from_file in related_tables_set and to_file in related_tables_set:
                key = (from_file, to_file)
                logical_edges.add(key)
                logical_edge_details[key] = (from_col, to_col)

    # 5. ê´€ê³„ íƒ€ì… ë¶„ë¥˜ (Physicalë§Œ, Logicalë§Œ, ë‘˜ ë‹¤)
    edge_types = {}  # {(from_table, to_table): 'physical'|'logical'|'both'}
    
    for from_table, to_table, col in physical_edges:
        key = (from_table, to_table)
        reverse_key = (to_table, from_table)
        
        if key in edge_types or reverse_key in edge_types:
            edge_types[key if key in edge_types else reverse_key] = 'both'
        else:
            edge_types[key] = 'physical'
    
    for from_file, to_file in logical_edges:
        key = (from_file, to_file)
        reverse_key = (to_file, from_file)
        
        if key in edge_types or reverse_key in edge_types:
            edge_types[key if key in edge_types else reverse_key] = 'both'
        else:
            edge_types[key] = 'logical'

    # 6. Graphviz ë Œë”ë§
    dot = Digraph(comment='Physical & Logical ERD', encoding='utf-8')
    dot.attr(rankdir='LR', nodesep='0.5', ranksep='1.5', splines='polyline')
    dot.attr('node', fontname='Malgun Gothic', fontsize='10', shape='none')
    dot.attr('edge', fontname='Malgun Gothic', fontsize='8')

    # 7. ë…¸ë“œ ìƒì„±
    for table_name in sorted(related_tables_set):
        is_anchor = table_name in selected_files
        header_bg = '#FFA500' if is_anchor else '#BBDEFB'
        
        label = f'<<TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" PORT="title">'
        label += f'<TR><TD BGCOLOR="{header_bg}"><B>{table_name}</B></TD></TR>'
        
        cols = table_info[table_name]
        
        # Physicalê³¼ Logical ê´€ê³„ì— ëª¨ë‘ í¬í•¨ëœ ì»¬ëŸ¼ ìˆ˜ì§‘
        physical_involved_cols = {c for f, t, c in physical_edges if f == table_name or t == table_name}
        logical_involved_cols = set()
        for from_file, to_file in logical_edges:
            if from_file == table_name or to_file == table_name:
                if (from_file, to_file) in logical_edge_details:
                    from_col, to_col = logical_edge_details[(from_file, to_file)]
                    if from_file == table_name:
                        logical_involved_cols.add(from_col)
                    if to_file == table_name:
                        logical_involved_cols.add(to_col)
        
        involved_cols = physical_involved_cols | logical_involved_cols
        
        for c_name in sorted(cols.keys()):
            info = cols[c_name]
            if info['is_pk'] or c_name in involved_cols or (show_all_columns and is_anchor):
                prefix = "ğŸ”‘ " if info['is_pk'] else ("ğŸ”— " if c_name in involved_cols else "  ")
                bg = "#E3F2FD" if info['is_pk'] else "#FFFFFF"
                label += f'<TR><TD ALIGN="LEFT" BGCOLOR="{bg}" PORT="{c_name}">{prefix}{c_name}</TD></TR>'
        
        label += '</TABLE>>'
        dot.node(table_name, label)

    # 8. ì—£ì§€ ì¶”ê°€ (ìƒ‰ìƒ êµ¬ë¶„)
    for from_table, to_table, col in physical_edges:
        key = (from_table, to_table)
        reverse_key = (to_table, from_table)
        
        edge_type = edge_types.get(key, edge_types.get(reverse_key, 'physical'))
        
        if edge_type == 'physical':
            edge_color = '#0000FF'  # íŒŒë€ìƒ‰
            penwidth = '1.5'
        elif edge_type == 'logical':
            edge_color = '#FF0000'  # ë¹¨ê°„ìƒ‰
            penwidth = '1.5'
        else:  # 'both'
            edge_color = '#800080'  # ë³´ë¼ìƒ‰
            penwidth = '2.0'
        
        dot.edge(f'{from_table}:{col}', f'{to_table}:{col}', 
                 dir='both', arrowhead='none', arrowtail='crow', 
                 color=edge_color, penwidth=penwidth)
    
    # Logical ì—£ì§€ ì¶”ê°€ (Physicalê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ê²½ìš°ë§Œ)
    for from_file, to_file in logical_edges:
        key = (from_file, to_file)
        reverse_key = (to_file, from_file)
        
        # Physical ê´€ê³„ì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        has_physical = any((f == from_file and t == to_file) or (f == to_file and t == from_file) 
                          for f, t, _ in physical_edges)
        
        if not has_physical and key in logical_edge_details:
            # Logical ê´€ê³„ë§Œ ìˆëŠ” ê²½ìš°
            from_col, to_col = logical_edge_details[key]
            dot.edge(f'{from_file}:{from_col}', f'{to_file}:{to_col}',
                     dir='both', arrowhead='none', arrowtail='crow',
                     color='#FF0000', penwidth='1.5')  # ë¹¨ê°„ìƒ‰

    # ERD ìƒì„± ì •ë³´ ìˆ˜ì§‘
    involved_cols_by_table = {}
    for table in related_tables_set:
        physical_cols = {c for f, t, c in physical_edges if f == table or t == table}
        logical_cols = set()
        for from_file, to_file in logical_edges:
            if (from_file == table or to_file == table) and (from_file, to_file) in logical_edge_details:
                from_col, to_col = logical_edge_details[(from_file, to_file)]
                if from_file == table:
                    logical_cols.add(from_col)
                if to_file == table:
                    logical_cols.add(to_col)
        involved_cols_by_table[table] = physical_cols | logical_cols
    
    erd_info = {
        'table_info': table_info,
        'physical_edges': physical_edges,
        'logical_edges': logical_edges,
        'logical_edge_details': logical_edge_details,
        'edge_types': edge_types,
        'related_tables_set': related_tables_set,
        'table_levels': table_levels,
        'involved_cols_by_table': involved_cols_by_table,
        'show_all_columns': show_all_columns,
        'selected_files': selected_files,
        'mode': 'Physical & Logical'
    }
    
    return dot, len(related_tables_set), erd_info

# -------------------------------------------------
# 10. ERD ì •ë³´/ë°ì´í„°í”„ë ˆì„ ìƒì„± í•¨ìˆ˜ (ERD Info DataFrame)
# -------------------------------------------------
def create_erd_info_dataframe(erd_info: dict) -> pd.DataFrame:
    """
    ERD ìƒì„± ì •ë³´ë¥¼ ì»¬ëŸ¼ ë‹¨ìœ„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
    """
    rows = []
    
    mode = erd_info.get('mode', 'Unknown')
    table_info = erd_info.get('table_info', {})
    related_tables_set = erd_info.get('related_tables_set', set())
    show_all_columns = erd_info.get('show_all_columns', False)
    selected_files = erd_info.get('selected_files', [])
    involved_cols_by_table = erd_info.get('involved_cols_by_table', {})
    
    if mode == 'Physical':
        fk_candidates = erd_info.get('fk_candidates', [])
        table_levels = erd_info.get('table_levels', {})
        
        # ê´€ê³„ ì •ë³´ ë§¤í•‘
        relationships_by_col = defaultdict(list)
        for from_table, to_table, col in fk_candidates:
            relationships_by_col[(from_table, col)].append((to_table, col))
            relationships_by_col[(to_table, col)].append((from_table, col))
        
        # related_tables_setì´ setì´ë©´ listë¡œ ë³€í™˜
        if isinstance(related_tables_set, set):
            related_tables_list = sorted(list(related_tables_set))
        else:
            related_tables_list = sorted(list(related_tables_set)) if related_tables_set else []
        
        for table_name in related_tables_list:
            if table_name not in table_info:
                continue
            
            cols = table_info[table_name]
            involved_cols = involved_cols_by_table.get(table_name, set())
            is_anchor = table_name in selected_files
            level = table_levels.get(table_name, 0)
            
            # í‘œì‹œëœ ì»¬ëŸ¼ ìˆ˜ì§‘ (ERDì— ì‹¤ì œë¡œ í‘œì‹œëœ ì»¬ëŸ¼)
            displayed_cols = set()
            for c_name, info in cols.items():
                is_displayed = info['is_pk'] or c_name in involved_cols or (show_all_columns and is_anchor)
                if is_displayed:
                    displayed_cols.add(c_name)
            
            # í‘œì‹œëœ ì»¬ëŸ¼ì— ëŒ€í•´ ì •ë³´ ìƒì„±
            for c_name in displayed_cols:
                info = cols[c_name]
                
                # ê´€ê³„ ì •ë³´ ìˆ˜ì§‘
                related_info = relationships_by_col.get((table_name, c_name), [])
                if related_info:
                    # ê´€ê³„ê°€ ìˆëŠ” ê²½ìš°: ê° ê´€ê³„ë§ˆë‹¤ í–‰ ìƒì„±
                    for related_table, related_col in related_info:
                        rows.append({
                            'FileName': table_name,
                            'ColumnName': c_name,
                            'PK': 'Y' if info['is_pk'] else 'N',
                            'FK': 'Y',
                            'Relationship_Type': 'Physical',
                            'Related_Table': related_table,
                            'Related_Column': related_col,
                            'Level': level,
                            'Displayed': 'Y',
                            'Is_Anchor': 'Y' if is_anchor else 'N'
                        })
                else:
                    # ê´€ê³„ê°€ ì—†ëŠ” ì»¬ëŸ¼ë„ í‘œì‹œ (ERDì— í‘œì‹œë˜ì—ˆìœ¼ë¯€ë¡œ)
                    rows.append({
                        'FileName': table_name,
                        'ColumnName': c_name,
                        'PK': 'Y' if info['is_pk'] else 'N',
                        'FK': 'N',
                        'Relationship_Type': 'Physical',
                        'Related_Table': '',
                        'Related_Column': '',
                        'Level': level,
                        'Displayed': 'Y',
                        'Is_Anchor': 'Y' if is_anchor else 'N'
                    })
    
    elif mode == 'Logical':
        relationships_list = erd_info.get('relationships_list', [])
        all_tables = erd_info.get('all_tables', set())
        pk_map = erd_info.get('pk_map', {})
        display_columns = erd_info.get('display_columns', {})
        connected_columns = erd_info.get('connected_columns', {})
        
        # ê´€ê³„ ì •ë³´ ë§¤í•‘
        relationships_by_col = defaultdict(list)
        for from_file, from_col, to_file, to_col in relationships_list:
            relationships_by_col[(from_file, from_col)].append((to_file, to_col))
            relationships_by_col[(to_file, to_col)].append((from_file, from_col))
        
        # all_tablesê°€ setì´ë©´ listë¡œ ë³€í™˜
        if isinstance(all_tables, set):
            all_tables_list = sorted(list(all_tables))
        else:
            all_tables_list = sorted(list(all_tables)) if all_tables else []
        
        for table_name in all_tables_list:
            is_anchor = table_name in selected_files
            pk_cols = set(pk_map.get(table_name, []))
            displayed_cols = set(display_columns.get(table_name, []))
            connected_cols = connected_columns.get(table_name, set())
            
            for col_name in displayed_cols:
                is_pk = col_name in pk_cols
                is_fk = col_name in connected_cols
                
                # ê´€ê³„ ì •ë³´ ìˆ˜ì§‘
                related_info = relationships_by_col.get((table_name, col_name), [])
                if related_info:
                    for related_table, related_col in related_info:
                        rows.append({
                            'FileName': table_name,
                            'ColumnName': col_name,
                            'PK': 'Y' if is_pk else 'N',
                            'FK': 'Y' if is_fk else 'N',
                            'Relationship_Type': 'Logical',
                            'Related_Table': related_table,
                            'Related_Column': related_col,
                            'Level': '',
                            'Displayed': 'Y',
                            'Is_Anchor': 'Y' if is_anchor else 'N'
                        })
                else:
                    rows.append({
                        'FileName': table_name,
                        'ColumnName': col_name,
                        'PK': 'Y' if is_pk else 'N',
                        'FK': 'N',
                        'Relationship_Type': 'Logical',
                        'Related_Table': '',
                        'Related_Column': '',
                        'Level': '',
                        'Displayed': 'Y',
                        'Is_Anchor': 'Y' if is_anchor else 'N'
                    })
    
    elif mode == 'Physical & Logical':
        physical_edges = erd_info.get('physical_edges', set())
        logical_edges = erd_info.get('logical_edges', set())
        logical_edge_details = erd_info.get('logical_edge_details', {})
        edge_types = erd_info.get('edge_types', {})
        table_levels = erd_info.get('table_levels', {})
        
        # Physical ê´€ê³„ ë§¤í•‘
        physical_relationships_by_col = defaultdict(list)
        for from_table, to_table, col in physical_edges:
            physical_relationships_by_col[(from_table, col)].append((to_table, col, 'Physical'))
            physical_relationships_by_col[(to_table, col)].append((from_table, col, 'Physical'))
        
        # Logical ê´€ê³„ ë§¤í•‘
        logical_relationships_by_col = defaultdict(list)
        for from_file, to_file in logical_edges:
            if (from_file, to_file) in logical_edge_details:
                from_col, to_col = logical_edge_details[(from_file, to_file)]
                logical_relationships_by_col[(from_file, from_col)].append((to_file, to_col, 'Logical'))
                logical_relationships_by_col[(to_file, to_col)].append((from_file, from_col, 'Logical'))
        
        for table_name in related_tables_set:
            if table_name not in table_info:
                continue
            
            cols = table_info[table_name]
            involved_cols = involved_cols_by_table.get(table_name, set())
            is_anchor = table_name in selected_files
            level = table_levels.get(table_name, 0)
            
            for c_name, info in cols.items():
                is_displayed = info['is_pk'] or c_name in involved_cols or (show_all_columns and is_anchor)
                
                # Physical ê´€ê³„
                physical_related = physical_relationships_by_col.get((table_name, c_name), [])
                # Logical ê´€ê³„
                logical_related = logical_relationships_by_col.get((table_name, c_name), [])
                
                # ëª¨ë“  ê´€ê³„ë¥¼ ìˆ˜ì§‘ (í…Œì´ë¸”-ì»¬ëŸ¼ ì¡°í•© ê¸°ì¤€)
                physical_relations = {(rt, rc) for rt, rc, _ in physical_related}
                logical_relations = {(rt, rc) for rt, rc, _ in logical_related}
                all_relation_pairs = physical_relations | logical_relations
                
                # ê° ê´€ê³„ì— ëŒ€í•´ í–‰ ìƒì„±
                if all_relation_pairs:
                    for related_table, related_col in all_relation_pairs:
                        # Physical ê´€ê³„ì¸ì§€ í™•ì¸
                        has_physical = (related_table, related_col) in physical_relations
                        # Logical ê´€ê³„ì¸ì§€ í™•ì¸
                        has_logical = (related_table, related_col) in logical_relations
                        
                        # íƒ€ì… ì»¬ëŸ¼ ì„¤ì •
                        physical_type = 1 if has_physical else 0
                        logical_type = 1 if has_logical else 0
                        both_type = 1 if (has_physical and has_logical) else 0
                        check = 1 if (has_logical and not has_physical) else 0
                        
                        rows.append({
                            'FileName': table_name,
                            'ColumnName': c_name,
                            'PK': 'Y' if info['is_pk'] else 'N',
                            'FK': 'Y' if (has_physical or has_logical) else 'N',
                            'Physical_Type': physical_type,
                            'Logical_Type': logical_type,
                            'Both_Type': both_type,
                            'Check': check,
                            'Related_Table': related_table,
                            'Related_Column': related_col,
                            'Level': level,
                            'Displayed': 'Y' if is_displayed else 'N',
                            'Is_Anchor': 'Y' if is_anchor else 'N'
                        })
                
                # ê´€ê³„ê°€ ì—†ëŠ” ì»¬ëŸ¼ë„ í‘œì‹œ
                if not all_relation_pairs:
                    if is_displayed:
                        rows.append({
                            'FileName': table_name,
                            'ColumnName': c_name,
                            'PK': 'Y' if info['is_pk'] else 'N',
                            'FK': 'N',
                            'Physical_Type': 0,
                            'Logical_Type': 0,
                            'Both_Type': 0,
                            'Check': 0,
                            'Related_Table': '',
                            'Related_Column': '',
                            'Level': level,
                            'Displayed': 'Y',
                            'Is_Anchor': 'Y' if is_anchor else 'N'
                        })
                else:
                    if is_displayed:
                        rows.append({
                            'FileName': table_name,
                            'ColumnName': c_name,
                            'PK': 'Y' if info['is_pk'] else 'N',
                            'FK': 'N',
                            'Relationship_Type': 'None',
                            'Related_Table': '',
                            'Related_Column': '',
                            'Level': level,
                            'Displayed': 'Y',
                            'Is_Anchor': 'Y' if is_anchor else 'N'
                        })
    
    if not rows:
        return pd.DataFrame()
    
    df = pd.DataFrame(rows)
    
    # Logical ëª¨ë“œì—ì„œ ì¤‘ë³µ ì œê±°
    if mode == 'Logical':
        # ê°™ì€ FileName, ColumnName, Related_Table, Related_Column ì¡°í•©ì´ ì¤‘ë³µë˜ë©´ í•˜ë‚˜ë§Œ ë‚¨ê¸°ê¸°
        # ë‹¨, Related_Tableì´ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì¤‘ë³µ ì œê±° (ê´€ê³„ê°€ ì—†ëŠ” ì»¬ëŸ¼ì€ ìœ ì§€)
        df_with_relations = df[df['Related_Table'] != ''].copy()
        df_without_relations = df[df['Related_Table'] == ''].copy()
        
        if not df_with_relations.empty:
            # ì¤‘ë³µ ì œê±°: FileName, ColumnName, Related_Table, Related_Column ê¸°ì¤€
            df_with_relations = df_with_relations.drop_duplicates(
                subset=['FileName', 'ColumnName', 'Related_Table', 'Related_Column'],
                keep='first'
            )
        
        # ë‹¤ì‹œ í•©ì¹˜ê¸°
        if not df_without_relations.empty:
            df = pd.concat([df_with_relations, df_without_relations], ignore_index=True)
        else:
            df = df_with_relations
    
    # ì •ë ¬: FileName, ColumnName, Related_Table ìˆœì„œ
    df = df.sort_values(['FileName', 'ColumnName', 'Related_Table']).reset_index(drop=True)
    
    return df

# -------------------------------------------------
# 12. ERD ìƒì„± ë˜í¼ í•¨ìˆ˜ (ERD Generation Wrappers)
# -------------------------------------------------
def run_erd_generation_wrapper(df_cm, df_ex, df_cr=None):
    """
    df_cm: CodeMapping.csv (ë¬¼ë¦¬ì  ê´€ê³„ ì •ë³´)
    df_ex: ERD_exclusive.csv (ì œì™¸í•  ì»¬ëŸ¼ ì •ë³´)
    df_cr: CodeMapping_erd.csv (ë…¼ë¦¬ì  ê´€ê³„ ì •ë³´, optional)
    """

    # 1st íŒŒì¼ ì •ë³´ ì¶œë ¥ ë° íŒŒì¼ ì„ íƒ 
    selected_files = select_files(df_cr, df_cm, df_ex)
    if not selected_files:
        return
    
    st.subheader("ì—°ê²°ê´€ê³„ ì •ë³´ ì„¤ì •")
    col1, col2, col3     = st.columns([1, 1, 1])

    with col1:
        erd_mode = st.radio("ì—°ê²°ê´€ê³„ ëª¨ë“œ ì„ íƒ", ["Physical", "Logical", "Physical & Logical"])

    with col2:
        if erd_mode == "Physical":
            depth = st.slider("íƒìƒ‰ ê¹Šì´ (Level)", 1, 4, 2, key="depth_slider_physical")
        elif erd_mode == "Physical & Logical":
            depth = st.slider("íƒìƒ‰ ê¹Šì´ (Level)", 1, 4, 2, key="depth_slider_combined")

    with col3:
        show_all = st.checkbox("ì „ì²´ ì»¬ëŸ¼ í‘œì‹œ", value=False)


    if st.button(f"ğŸš€ {erd_mode} ERD ìƒì„± ë° ë¶„ì„ ì‹œì‘", type="primary"):
        # Cloud í™˜ê²½ì—ì„œëŠ” ì˜ˆì œ ì´ë¯¸ì§€ë§Œ í‘œì‹œí•˜ê³ , ERDëŠ” ìƒì„±í•˜ì§€ ì•Šì§€ë§Œ ê²°ê³¼ëŠ” ë³´ì—¬ì¤Œ
        cloud_mode = is_cloud_env()
        # cloud_mode = True # í…ŒìŠ¤íŠ¸ìš©
        if cloud_mode:
            show_example_erd_images()

        with st.spinner("N-Level ê´€ê³„ íƒìƒ‰ ë° ë ˆì´ì•„ì›ƒ ê³„ì‚° ì¤‘..."):
            if erd_mode == "Physical":
                # Physical ëª¨ë“œ: depthë¥¼ ì‚¬ìš©í•˜ì—¬ N-Level íƒìƒ‰
                # ì„ íƒëœ ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ ê°ê° depth ë ˆë²¨ê¹Œì§€ ì§ì ‘ ì—°ê²°ëœ í…Œì´ë¸”ë§Œ ì°¾ê¸°
                all_related_tables = set(selected_files)  # ì„ íƒëœ í…Œì´ë¸” í¬í•¨
                all_table_levels = {}  # ëª¨ë“  í…Œì´ë¸”ì˜ ë ˆë²¨ ì •ë³´ í†µí•©
                
                # ì„ íƒëœ í…Œì´ë¸”ì€ ëª¨ë‘ ë ˆë²¨ 0
                for table in selected_files:
                    table_str = str(table) if isinstance(table, str) else str(table)
                    all_table_levels[table_str] = 0
                
                for anchor_table in selected_files:
                    anchor_table_str = str(anchor_table) if isinstance(anchor_table, str) else str(anchor_table)
                    # ê° ì„ íƒëœ í…Œì´ë¸”ì— ëŒ€í•´ depth ë ˆë²¨ê¹Œì§€ ì§ì ‘ ì—°ê²°ëœ í…Œì´ë¸”ë§Œ ì°¾ê¸°
                    related_for_this, levels_for_this = get_physical_n_level_tables(df_cm, anchor_table_str, depth, df_ex)
                    all_related_tables.update(related_for_this)
                    # ë ˆë²¨ ì •ë³´ ë³‘í•© (ì´ë¯¸ ìˆëŠ” ê²½ìš° ë” ë‚®ì€ ë ˆë²¨ ìœ ì§€)
                    for table, level in levels_for_this.items():
                        if table not in all_table_levels or all_table_levels[table] > level:
                            all_table_levels[table] = level
                
                related_list = list(all_related_tables)
                
                if not related_list or len(related_list) == 0:
                    st.warning(f"âš ï¸ ì„ íƒëœ í…Œì´ë¸”ê³¼ ì—°ê²°ëœ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ERD ìƒì„± (depth ì œí•œëœ í…Œì´ë¸” ëª©ë¡ê³¼ ë ˆë²¨ ì •ë³´ ì „ë‹¬)
                    dot, count, erd_info = generate_physical_erd_image(df_cm, df_ex, selected_files, related_list, show_all, all_table_levels)
                    
                    if dot and not cloud_mode:
                        suffix = f"L{depth}_{len(selected_files)}tables"
                        display_erd_with_download(dot, suffix, count)
                        st.success(f"âœ… ë¶„ì„ ì™„ë£Œ: ì„ íƒëœ {len(selected_files)}ê°œ í…Œì´ë¸” ê¸°ì¤€ {depth}ë ˆë²¨ê¹Œì§€ ì§ì ‘ ì—°ê²°ëœ ì´ {len(related_list)}ê°œ í…Œì´ë¸” í‘œì‹œ")

                    # ERD ì •ë³´ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
                    st.subheader("ğŸ“Š ERD ìƒì„± ì •ë³´ (ì»¬ëŸ¼ ë‹¨ìœ„)")
                    erd_df = create_erd_info_dataframe(erd_info)
                    st.dataframe(erd_df, width='stretch', hide_index=True)

            elif erd_mode == "Logical":
                # PK ë§µê³¼ it_df ìƒì„±
                pk_map, fk_map, it_df = _extract_and_load_erd_data_impl(df_cr)
                
                related_tables = get_related_tables(selected_files, it_df)
                related_table_count = len(related_tables)
                
                if related_table_count > MAX_RELATED_TABLE_COUNT:
                    st.error(f"ì—°ê²°ëœ í…Œì´ë¸” ìˆ˜ê°€ {MAX_RELATED_TABLE_COUNT}ê°œë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
                elif not related_tables or len(related_tables) == 0:
                    st.warning(f"âš ï¸ ì„ íƒëœ í…Œì´ë¸”ê³¼ ì—°ê²°ëœ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    dot, edge_count, erd_info = generate_logical_erd_image(
                        selected_files, 
                        set(related_tables), 
                        pk_map, 
                        it_df, 
                        show_all
                    )
                    
                    if dot and not cloud_mode:
                        suffix = f"{erd_mode}_{selected_files[0]}"
                        display_erd_with_download(dot, suffix, edge_count)
                        st.success(f"âœ… ë¶„ì„ ì™„ë£Œ: ì´ {len(related_tables)}ê°œ í…Œì´ë¸” ì—°ê²°ë¨")

                    # ERD ì •ë³´ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
                    st.subheader("ğŸ“Š ERD ìƒì„± ì •ë³´ (ì»¬ëŸ¼ ë‹¨ìœ„)")
                    erd_df = create_erd_info_dataframe(erd_info)
                    st.dataframe(erd_df, width='stretch', hide_index=True)

            elif erd_mode == "Physical & Logical":
                # Physical & Logical í†µí•© ëª¨ë“œ
                # PK ë§µê³¼ it_df ìƒì„±
                pk_map, fk_map, it_df = _extract_and_load_erd_data_impl(df_cr)
                
                # Physical ê´€ê³„ íƒìƒ‰
                all_related_tables = set(selected_files)
                all_table_levels = {}
                
                for table in selected_files:
                    table_str = str(table) if isinstance(table, str) else str(table)
                    all_table_levels[table_str] = 0
                
                for anchor_table in selected_files:
                    anchor_table_str = str(anchor_table) if isinstance(anchor_table, str) else str(anchor_table)
                    related_for_this, levels_for_this = get_physical_n_level_tables(df_cm, anchor_table_str, depth, df_ex)
                    all_related_tables.update(related_for_this)
                    for table, level in levels_for_this.items():
                        if table not in all_table_levels or all_table_levels[table] > level:
                            all_table_levels[table] = level
                
                # Logical ê´€ê³„ íƒìƒ‰ (22ë²ˆ íŒŒì¼ê³¼ ë™ì¼í•œ ë¡œì§)
                logical_related_tables = get_related_tables(selected_files, it_df)
                logical_related_table_count = len(logical_related_tables)
                
                # Physicalê³¼ Logical ê´€ê³„ë¥¼ í†µí•©
                all_related_tables.update(logical_related_tables)
                related_list = list(all_related_tables)
                
                if not related_list or len(related_list) == 0:
                    st.warning(f"âš ï¸ ì„ íƒëœ í…Œì´ë¸”ê³¼ ì—°ê²°ëœ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # í†µí•© ERD ìƒì„±
                    dot, count, erd_info = generate_combined_erd_image(
                        df_cm, df_ex, df_cr, selected_files, related_list, 
                        all_table_levels, pk_map, it_df, show_all
                    )
                    
                    if dot and not cloud_mode:
                        suffix = f"Combined_L{depth}_{len(selected_files)}tables"
                        display_erd_with_download(dot, suffix, count)
                        st.success(f"âœ… í†µí•© ë¶„ì„ ì™„ë£Œ: Physical & Logical ê´€ê³„ë¥¼ ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ (ì´ {count}ê°œ í…Œì´ë¸”)")
                        st.info("ğŸ”µ íŒŒë€ìƒ‰: Physical ì—°ê²°ë§Œ | ğŸ”´ ë¹¨ê°„ìƒ‰: Logical ì—°ê²°ë§Œ | ğŸŸ£ ë³´ë¼ìƒ‰: ë‘ ì—°ê²° ëª¨ë‘")

                    # ERD ì •ë³´ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ (Cloud í™˜ê²½ì—ì„œë„ í‘œì‹œ)
                    st.subheader("ğŸ“Š ERD ìƒì„± ì •ë³´ (ì»¬ëŸ¼ ë‹¨ìœ„)")
                    erd_df = create_erd_info_dataframe(erd_info)
                    st.dataframe(erd_df, width='stretch', hide_index=True)

# -------------------------------------------------
# 13. ë©”ì¸ í•¨ìˆ˜ (Main)
# -------------------------------------------------
def main():
    st.title(APP_TITLE)
    st.caption(APP_DESCRIPTION)

    try:
        # 1. ë°ì´í„° ë¡œë“œ
        path = OUTPUT_DIR
        files_to_load = {   # load í•  íŒŒì¼ ëª©ë¡
            'codemapping_erd': path / "CodeMapping_erd.csv", 
            'codemapping': path / "CodeMapping.csv",
            'filestats': path / "FileStats.csv", 
            'exclusive': path / "ERD_exclusive.csv"
        }

        loaded_data = load_data_all(files_to_load)

        if loaded_data is None:
            st.error("ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            return
        else:
            df_cr = loaded_data['codemapping_erd']
            df_cm = loaded_data['codemapping']
            df_fs = loaded_data['filestats']
            df_ex = loaded_data['exclusive']

        run_erd_generation_wrapper(df_cm, df_ex, df_cr)
        
    except Exception as e:
        st.error(f"Data Relationship Diagram ìƒì„± ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

if __name__ == '__main__':
    main()



