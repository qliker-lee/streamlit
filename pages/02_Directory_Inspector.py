# 01_Directory_Inspector.py
# -*- coding: utf-8 -*-
"""
DS_Diretory_Config.yaml ì„ ì½ì–´
- directories.* ê²½ë¡œ
- source_directories.* ê²½ë¡œ
ì˜ íŒŒì¼/í´ë” ìˆ˜ ë° ìš©ëŸ‰ì„ ì§‘ê³„/í‘œì‹œí•˜ëŠ” Streamlit ì•±
"""

from __future__ import annotations
import os
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
import time

import yaml
import pandas as pd
import streamlit as st

# =========================
# ìœ í‹¸: YAML ë¡œë”©/ê²½ë¡œ íƒìƒ‰
# =========================
def _safe_load_yaml(p: Path) -> Dict[str, Any]:
    encs = ("utf-8", "utf-8-sig", "euc-kr", "cp949")
    last_err = None
    for enc in encs:
        try:
            with open(p, "r", encoding=enc) as f:
                obj = yaml.safe_load(f) or {}
            return obj
        except Exception as e:
            last_err = e
    raise RuntimeError(f"YAML ë¡œë“œ ì‹¤íŒ¨: {p} :: {last_err}")

def _auto_find_yaml() -> Optional[Path]:
    """
    DS_Diretory_Config.yaml ìë™ íƒìƒ‰
    - CWD
    - CWD/util
    - í”„ë¡œì íŠ¸ ìƒìœ„ ì¶”ì • ê²½ë¡œë“¤
    - DataSense/util
    """
    candidates = [
        Path.cwd() / "DS_Diretory_Config.yaml",
        Path.cwd() / "util" / "DS_Diretory_Config.yaml",
        Path.cwd().parent / "DS_Diretory_Config.yaml",
        Path.cwd().parent / "util" / "DS_Diretory_Config.yaml",
        Path.cwd() / "DataSense" / "util" / "DS_Diretory_Config.yaml",
        Path.cwd().parent / "DataSense" / "util" / "DS_Diretory_Config.yaml",
    ]
    for p in candidates:
        if p.exists():
            return p
    return None

def _expand_path(base: Path, p: str) -> Path:
    """í™˜ê²½ë³€ìˆ˜/í™ˆ(~)/ìƒëŒ€ê²½ë¡œë¥¼ í¬í•¨í•  ìˆ˜ ìˆëŠ” ë¬¸ìì—´ì„ ì ˆëŒ€ê²½ë¡œë¡œ ì •ê·œí™”"""
    s = os.path.expandvars(str(p or "").strip())
    s = os.path.expanduser(s)
    q = Path(s)
    if not q.is_absolute():
        q = (base / q)
    return q.resolve()

def _fmt_bytes(n: int) -> str:
    for unit in ["B","KB","MB","GB","TB"]:
        if n < 1024:
            return f"{n:.0f} {unit}"
        n /= 1024
    return f"{n:.0f} PB"

# =========================
# íŒŒì¼/í´ë” ì§‘ê³„
# =========================
def _iter_children(root: Path, recursive: bool, include_hidden: bool):
    """
    ì§€ì • ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼/í´ë”ë¥¼ ìˆœíšŒí•˜ëŠ” ì œë„ˆë ˆì´í„°.
    recursive=False ë©´ 1ë ˆë²¨ë§Œ, True ë©´ ì¬ê·€
    """
    if not root.exists() or not root.is_dir():
        return
    if not recursive:
        for entry in os.scandir(root):
            if not include_hidden and Path(entry.path).name.startswith("."):
                continue
            yield entry
    else:
        for dirpath, dirnames, filenames in os.walk(root):
            # ìˆ¨ê¹€ ì²˜ë¦¬
            if not include_hidden:
                dirnames[:]  = [d for d in dirnames if not d.startswith(".")]
                filenames[:] = [f for f in filenames if not f.startswith(".")]
            # íŒŒì¼
            for fn in filenames:
                full = Path(dirpath) / fn
                yield full

@st.cache_data(show_spinner=False)
def scan_dir_stats(
    dir_path_str: str, recursive: bool, include_hidden: bool
) -> Tuple[int, int, int]:
    """
    ë””ë ‰í† ë¦¬ ì§‘ê³„ ê²°ê³¼ ìºì‹œ:
      - file_count
      - dir_count (recursive=Trueì¸ ê²½ìš°ì—ë§Œ ì˜ë¯¸ ìˆìŒ)
      - total_size(bytes)
    """
    p = Path(dir_path_str)
    file_count = 0
    dir_count = 0
    total_size = 0

    if not p.exists() or not p.is_dir():
        return (0, 0, 0)

    if not recursive:
        # 1ë ˆë²¨ë§Œ
        for e in _iter_children(p, recursive=False, include_hidden=include_hidden):
            try:
                if isinstance(e, os.DirEntry):
                    if e.is_file():
                        file_count += 1
                        try:
                            total_size += e.stat().st_size
                        except Exception:
                            pass
                    elif e.is_dir():
                        dir_count += 1
                else:
                    # pathlib Path ë¡œ ë“¤ì–´ì˜¨ ê²½ìš°
                    if Path(e).is_file():
                        file_count += 1
                        try:
                            total_size += Path(e).stat().st_size
                        except Exception:
                            pass
                    elif Path(e).is_dir():
                        dir_count += 1
            except Exception:
                pass
    else:
        # ì¬ê·€: íŒŒì¼/í´ë” ëª¨ë‘ ì¹´ìš´íŠ¸
        for dirpath, dirnames, filenames in os.walk(p):
            if not include_hidden:
                dirnames[:]  = [d for d in dirnames if not d.startswith(".")]
                filenames[:] = [f for f in filenames if not f.startswith(".")]
            dir_count += len(dirnames)
            file_count += len(filenames)
            for fn in filenames:
                fp = Path(dirpath) / fn
                try:
                    total_size += fp.stat().st_size
                except Exception:
                    pass

    return (file_count, dir_count, total_size)

def build_section_table(
    section_name: str,
    mapping: Dict[str, Any],
    root_path: Path,
    recursive: bool,
    include_hidden: bool,
) -> pd.DataFrame:
    """
    section_name: 'directories' ë˜ëŠ” 'source_directories'
    mapping: {key: path_str}
    """
    rows = []
    for k, rel in (mapping or {}).items():
        try:
            abs_path = _expand_path(root_path, str(rel))
            exists = abs_path.exists()
            is_dir = abs_path.is_dir()
            if exists and is_dir:
                files, dirs, total = scan_dir_stats(str(abs_path), recursive, include_hidden)
            else:
                files, dirs, total = (0, 0, 0)
            rows.append({
                "section": section_name,
                "key": str(k),
                "path": str(rel),
                "resolved_path": str(abs_path),
                "exists": "Y" if exists else "N",
                "is_dir": "Y" if is_dir else "N",
                "file_count": files,
                "dir_count": dirs,
                "total_size": total,
                "total_size(human)": _fmt_bytes(total),
            })
        except Exception as e:
            rows.append({
                "section": section_name,
                "key": str(k),
                "path": str(rel),
                "resolved_path": "",
                "exists": "N",
                "is_dir": "N",
                "file_count": 0,
                "dir_count": 0,
                "total_size": 0,
                "total_size(human)": "-",
                "error": str(e),
            })
    return pd.DataFrame(rows)

# =========================
# Streamlit ì•±
# =========================
def main():
    st.set_page_config(page_title="Directory Inspector", layout="wide", page_icon="ğŸ—‚ï¸")
    st.title("Directory Inspector") # st.title("Directory Inspector (DS_Diretory_Config.yaml)")

    st.markdown(
        "- **DS_Diretory_Config.yaml** ì„ ì½ì–´ `directories`/`source_directories` ê²½ë¡œì˜ íŒŒì¼/í´ë” ìˆ˜ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤.\n"
        "- ê²½ë¡œëŠ” `ROOT_PATH`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ê²½ë¡œë¥¼ ì ˆëŒ€ê²½ë¡œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
    )

    # ----- ì…ë ¥ UI -----
    with st.expander("â‘  YAML ì„ íƒ", expanded=True):
        col1, col2 = st.columns([3, 2])
        with col1:
            yaml_path_txt = st.text_input(
                "YAML ê²½ë¡œ (ë¯¸ì…ë ¥ ì‹œ ìë™ íƒìƒ‰)",
                value=str(_auto_find_yaml() or ""),
                placeholder="ì˜ˆ) C:/projects/DataSense/util/DS_Diretory_Config.yaml"
            )
        with col2:
            uploaded = st.file_uploader("ë˜ëŠ” ì—…ë¡œë“œ", type=["yaml", "yml"])

        yaml_data: Dict[str, Any] = {}
        yaml_path_used: Optional[Path] = None

        if uploaded is not None:
            try:
                yaml_data = yaml.safe_load(uploaded.read().decode("utf-8")) or {}
                yaml_path_used = None
                st.success("ì—…ë¡œë“œ YAML ë¡œë“œ ì„±ê³µ")
            except Exception as e:
                st.error(f"ì—…ë¡œë“œ íŒŒì‹± ì‹¤íŒ¨: {e}")
        else:
            if yaml_path_txt.strip():
                p = Path(yaml_path_txt.strip())
                if p.exists():
                    try:
                        yaml_data = _safe_load_yaml(p)
                        yaml_path_used = p
                        st.success(f"íŒŒì¼ ë¡œë“œ ì„±ê³µ: {p}")
                    except Exception as e:
                        st.error(f"YAML ë¡œë“œ ì‹¤íŒ¨: {e}")
                else:
                    st.warning("ì§€ì •í•œ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìë™ íƒìƒ‰ í›„ë³´ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.")
            else:
                st.info("ê²½ë¡œ ë¯¸ì…ë ¥ â†’ ìë™ íƒìƒ‰ì„ ì‹œë„í–ˆìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì§ì ‘ ì…ë ¥/ì—…ë¡œë“œ í•˜ì„¸ìš”.")

    # ----- ì˜µì…˜ -----
    with st.expander("â‘¡ ì˜µì…˜", expanded=True):
        c1, c2, c3 = st.columns([1, 1, 2])
        with c1:
            recursive = st.checkbox("í•˜ìœ„ í´ë” í¬í•¨(ì¬ê·€)", value=True)
        with c2:
            include_hidden = st.checkbox("ìˆ¨ê¹€ í¬í•¨(.*)", value=False)
        with c3:
            root_override = st.text_input(
                "ROOT_PATH ì¬ì •ì˜(ì„ íƒ, ë¹„ìš°ë©´ YAMLì˜ ROOT_PATH ì‚¬ìš©)",
                value=""
            )

    # ----- ì²˜ë¦¬ -----
    if not yaml_data:
        st.stop()

    root_path = Path(root_override.strip() or yaml_data.get("ROOT_PATH") or (yaml_path_used.parent if yaml_path_used else Path.cwd()))
    st.info(f"ROOT_PATH: `{root_path}`")

    directories = yaml_data.get("directories", {})
    source_directories = yaml_data.get("source_directories", {})

    t0 = time.time()
    df_dirs = build_section_table("directories", directories, root_path, recursive, include_hidden)
    df_src = build_section_table("source_directories", source_directories, root_path, recursive, include_hidden)
    df_all = pd.concat([df_dirs, df_src], ignore_index=True)
    dt_sec = time.time() - t0

    # ----- ì¶œë ¥ -----
    st.markdown("### ê²°ê³¼ ìš”ì•½")
    colA, colB, colC, colD = st.columns([1, 1, 1, 1])
    with colA:
        st.metric("ì´ í•­ëª©ìˆ˜", f"{len(df_all):,}")
    with colB:
        st.metric("ì´ íŒŒì¼ìˆ˜", f"{int(df_all['file_count'].sum()):,}")
    with colC:
        st.metric("ì´ í´ë”ìˆ˜", f"{int(df_all['dir_count'].sum()):,}")
    with colD:
        st.metric("ì´ ìš©ëŸ‰", _fmt_bytes(int(df_all["total_size"].sum())))
    st.caption(f"ìŠ¤ìº” ì‹œê°„: {dt_sec:.2f}s   (ì¬ê·€={recursive}, ìˆ¨ê¹€í¬í•¨={include_hidden})")

    st.markdown("### ìƒì„¸ í‘œ")
    st.dataframe(
        df_all[[
            "section","key","path","resolved_path","exists","is_dir",
            "file_count","dir_count","total_size(human)"
        ]].sort_values(["section","key"]),
        use_container_width=True,
        hide_index=True,
    )

    # ì„¹ì…˜ë³„ í•„í„° & ë¯¸ì¡´ì¬ ê²½ë¡œ í•˜ì´ë¼ì´íŠ¸
    with st.expander("í•„í„° & ì ê²€", expanded=False):
        section_pick = st.multiselect("ì„¹ì…˜", options=["directories","source_directories"], default=["directories","source_directories"])
        only_missing = st.checkbox("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ë¡œë§Œ ë³´ê¸°", value=False)
        df_view = df_all[df_all["section"].isin(section_pick)].copy()
        if only_missing:
            df_view = df_view[df_view["exists"] == "N"]
        if df_view.empty:
            st.info("í‘œì‹œí•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.dataframe(
                df_view.sort_values(["section","key"]),
                use_container_width=True,
                hide_index=True
            )

if __name__ == "__main__":
    main()
