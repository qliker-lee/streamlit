# -*- coding: utf-8 -*-
"""
2025.12.20  Qliker 
ğŸ“Š Data Analyzer (í†µí•©)
"""
# -------------------------------------------------------------------
# 1. ê²½ë¡œ ì„¤ì • (Streamlit warnings import ì „ì— í•„ìš”)
# -------------------------------------------------------------------
import sys
from pathlib import Path

CURRENT_DIR = Path(__file__).resolve()
PROJECT_ROOT = CURRENT_DIR.parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

# -------------------------------------------------------------------
# 2. ì»´íŒŒì¼ ë°œìƒí•˜ëŠ” Streamlit ê²½ê³  ë©”ì‹œì§€ ì–µì œ ì„¤ì • (Streamlit import ì „ì— í˜¸ì¶œ)
# -------------------------------------------------------------------
from util.streamlit_warnings import setup_streamlit_warnings
setup_streamlit_warnings()

# -------------------------------------------------------------------
# 3. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
# -------------------------------------------------------------------
import streamlit as st
import subprocess
import os
import sys
# import warnings
from pathlib import Path
import pandas as pd
from dataclasses import dataclass
from typing import Dict, Any, Optional
import yaml

# -------------------------------------------------------------------
# ê¸°ë³¸ ì•± ì •ë³´
# -------------------------------------------------------------------
APP_NAME = "Data Analyzer (Data Profile)"
APP_DESC = "##### ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ë° ë°ì´í„° ê´€ê³„ë„ ë¶„ì„ì„ ìœ„í•œ ì‘ì—…ì…ë‹ˆë‹¤."
APP_DESC2 = """
- ë°ì´í„° í”„ë¡œíŒŒì¼ë§ì„ ìˆ˜í–‰í•˜ì—¬ ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ë‹¤ì–‘í•œ í†µê³„ ì •ë³´ë¥¼ ìƒì„±í•˜ê³  (Data Quality Analyzer)
- ë°ì´í„° íƒ€ì… ë° ì‚¬ì „ ì •ì˜ëœ Ruleì„ ì ìš©í•˜ë©° (Data Type & Rule Analyzer)
- ë°ì´í„° ê°„ì˜ ë…¼ë¦¬ì  ê´€ê³„ë„ ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (Data Relationship Analyzer)
"""

from util.Files_FunctionV20 import load_yaml_datasense, set_page_config

set_page_config(APP_NAME)

# -------------------------------------------------------------------
# YAML CONFIG ë¡œë”
# -------------------------------------------------------------------
def _fallback_load_yaml_datasense() -> Dict[str, Any]:
    """YAML ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
    guessed_root = str(PROJECT_ROOT)
    cfg = {
        "ROOT_PATH": guessed_root,
        "files": {
            "fileformat_output": "DS_Output/FileFormat.csv",
            "ruledatatype_output": "DS_Output/RuleDataType.csv",
            "codemapping_output": "DS_Output/CodeMapping.csv",
        },
        "DataSense_Password": "qlalfqjsgh",  # ê¸°ë³¸ ë¹„ë°€ë²ˆí˜¸
    }
    path = Path(guessed_root) / "util" / "DS_00_Main_Config.yaml"
    if path.exists():
        try:
            with open(path, "r", encoding="utf-8") as f:
                y = yaml.safe_load(f) or {}
                y.setdefault("ROOT_PATH", guessed_root)
                y.setdefault("files", cfg["files"])
                return y
        except Exception:
            pass
    return cfg

try:
    from util.Files_FunctionV20 import load_yaml_datasense  # type: ignore
except Exception:
    load_yaml_datasense = _fallback_load_yaml_datasense

# -------------------------------------------------------------------
# ìœ í‹¸ í•¨ìˆ˜
# -------------------------------------------------------------------
def normalize_dataframe_for_display(df: pd.DataFrame) -> pd.DataFrame:
    """
    DataFrameì„ Streamlit í‘œì‹œìš©ìœ¼ë¡œ ì •ê·œí™”
    - ìˆ«ìí˜• ì»¬ëŸ¼: NaNì„ 0ìœ¼ë¡œ ë³€í™˜ (None í‘œì‹œ ë°©ì§€)
    - object íƒ€ì… ì»¬ëŸ¼: ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•˜ë©´ ë³€í™˜, ë¶ˆê°€ëŠ¥í•˜ë©´ Noneì„ ë¹ˆ ë¬¸ìì—´ë¡œ
    - ë¬¸ìì—´ ì»¬ëŸ¼: Noneì„ ë¹ˆ ë¬¸ìì—´ë¡œ
    Args:
        df: ì²˜ë¦¬í•  DataFrame
    Returns:
        ì •ê·œí™”ëœ DataFrame
    """
    if df is None or df.empty:
        return df
    
    df = df.copy()
    
    for col in df.columns:
        if df[col].dtype in ['int64', 'float64', 'int32', 'float32']:
            # ìˆ«ìí˜• ì»¬ëŸ¼: NaNì„ 0ìœ¼ë¡œ ë³€í™˜ (None í‘œì‹œ ë°©ì§€)
            df[col] = df[col].fillna(0)
        elif df[col].dtype == 'object': # object íƒ€ì…ì¸ ê²½ìš° ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸ 
            try:       
                numeric_series = pd.to_numeric(df[col], errors='coerce') # ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
                if not numeric_series.isna().all():
                    # ìˆ«ì ê°’ì´ ìˆìœ¼ë©´ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•˜ê³  NaNì€ 0ìœ¼ë¡œ
                    df[col] = numeric_series.fillna(0)
                else:
                    # ìˆ«ì ê°’ì´ ì—†ìœ¼ë©´ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
                    df[col] = df[col].fillna("")
            except Exception:
                # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
                df[col] = df[col].fillna("")
        else:
            # ë¬¸ìì—´ ì»¬ëŸ¼ì€ Noneì„ ë¹ˆ ë¬¸ìì—´ë¡œ
            df[col] = df[col].fillna("")
    
    return df

def display_statistics_info():
    """í†µê³„ ë‚´ì—­ì— í¬í•¨ëœ ì •ë³´ë“¤"""
    st.markdown("###### í†µê³„ ë‚´ì—­ì— í¬í•¨ëœ ì •ë³´ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.")
    col1, col2, col3, col4, col5, col6 = st.columns([1, 1, 1, 1, 1, 1])
    
    with col1:
        st.markdown("##### ì†ì„± ì •ë³´")
        st.write("ë°ì´í„° íƒ€ì…")
        st.write("ì˜¤ë¼í´ íƒ€ì…")
        st.write("ë£° ê¸°ë°˜ íƒ€ì…")
    
    with col2:
        st.markdown("##### Value ì •ë³´")
        st.write("Primary Key ì—¬ë¶€")
        st.write("ë°ì´í„° ê°’ì˜ ì—´ ê°œìˆ˜")
        st.write("Uniqueness ë¹„ìœ¨")
        st.write("Null ë¹„ìœ¨")
        st.write("ìµœì†Œ/ìµœëŒ€/í‰ê· /ì¤‘ì•™ ê°’")
    
    with col3:
        st.markdown("##### Length ì •ë³´")
        st.write("Length ì¢…ë¥˜")
        st.write("Length ìµœì†Œ")
        st.write("Length ìµœëŒ€")
        st.write("Length ë‹¤ë¹ˆë„")
        st.write("Length í‰ê· /ì¤‘ì•™ê°’")
    
    with col4:
        st.markdown("##### Value êµ¬ì„±")
        st.write("ì˜ë¬¸, í•œê¸€, ìˆ«ì ë“± íŒ¨í„´ êµ¬ì„±")
        st.write("íŒ¨í„´ì˜ ì¢…ë¥˜ ìˆ˜")
        st.write("ë‹¤ë¹ˆë„ íŒ¨í„´ êµ¬ì„±")
        st.write("ë‹¤ë¹ˆë„ íŒ¨í„´ ë° ë¹„ìœ¨")
        # st.write("2nd/3rd íŒ¨í„´ ë° ë¹„ìœ¨")
    
    with col5:
        st.markdown("##### Value Top 10")
        st.write("Top 10 ê°’")
        st.write("Top 10 ë¹„ìœ¨")
    
    with col6:
        st.markdown("##### ë¬¸ì í†µê³„")
        st.write("ì˜ë¬¸ ëŒ€ì†Œë¬¸ì ì—´ ìˆ˜")
        st.write("í•œê¸€ í¬í•¨ ì—´ ìˆ˜")
        st.write("ìˆ«ì í¬í•¨ ì—´ ìˆ˜")
        st.write("íŠ¹ìˆ˜ë¬¸ì ì—´ ìˆ˜")
        st.write("í˜¼í•© ë¬¸ì ì—´ ìˆ˜")

def display_data_quality_results(df: pd.DataFrame):
    """Data Quality Analyzer ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
   
    if df is None:
        st.warning(f"âš ï¸ Data Quality Analyzer ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    st.markdown("##### Data Quality Analyzer ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.")
    # DataFrame ì •ê·œí™” (None ê°’ ì²˜ë¦¬ ë° Arrow í˜¸í™˜ì„±)
    df = normalize_dataframe_for_display(df)
    
    df = df.drop(columns=['FilePath'])
    st.dataframe(df, width='stretch', height=550, hide_index=True)

def display_data_type_rule_results(df: pd.DataFrame):
    """Data Type & Rule Analyzer ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    required_columns = [
            "FileName", "MasterType", "ColumnName", "DataType", "OracleType",
            "Rule", "RuleType", "MatchedRule", "MatchedScoreList", 
            "MatchScoreAvg", "MatchScoreMax"
        ]
    if df is None:
        st.warning(f"âš ï¸ Data Type & Rule Analyzer ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    st.markdown("##### Data Type & Rule Analyzer ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.")
    # DataFrame ì •ê·œí™” (None ê°’ ì²˜ë¦¬ ë° Arrow í˜¸í™˜ì„±)
    df = normalize_dataframe_for_display(df)
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í•„í„°ë§
    available_columns = [col for col in required_columns if col in df.columns]
    if available_columns:
        df = df[available_columns]
    
    st.dataframe(df, width='stretch', height=600, hide_index=True)

def display_code_relationship_results(df: pd.DataFrame):
    """Code Relationship Analyzer ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    if df is None:
        st.warning(f"âš ï¸ Code Relationship Analyzer ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    st.markdown("##### Code Relationship Analyzer ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.")
    # DataFrame ì •ê·œí™” (None ê°’ ì²˜ë¦¬ ë° Arrow í˜¸í™˜ì„±)
    df = normalize_dataframe_for_display(df)
    st.dataframe(df, width='stretch', height=600, hide_index=True)

# -------------------------------------------------------------------
# FILE LOADER
# -------------------------------------------------------------------
@dataclass
class FileConfig:
    """íŒŒì¼ ì„¤ì • ì •ë³´"""
    fileformat_output: str
    ruledatatype_output: str
    codemapping_output: str
    analyzer_script_quality: str
    analyzer_script_rule: str
    analyzer_script_relationship: str
    # analyzer_script_erd_mapping: str

class FileLoader:
    """íŒŒì¼ ë¡œë”©ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, yaml_config: Dict[str, Any]):
        self.yaml_config = yaml_config
        # í•­ìƒ PROJECT_ROOTë¥¼ ì‚¬ìš© (YAMLì˜ ROOT_PATHëŠ” ë¬´ì‹œ)
        # Files_FunctionV20.pyì˜ load_yaml_datasense()ê°€ ì˜ëª»ëœ ROOT_PATHë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŒ
        self.root_path = str(PROJECT_ROOT.resolve())
        self.files_config = self._setup_files_config()
    
    def _setup_files_config(self) -> FileConfig:
        """íŒŒì¼ ì„¤ì • êµ¬ì„±"""
        files = self.yaml_config.get('files', {})
        
        def _full_path(path_str):
            p = Path(path_str)
            if not p.is_absolute():
                p = Path(self.root_path) / p
            return str(p.resolve())
        
        return FileConfig(
            fileformat_output=_full_path(files.get('fileformat_output', 'DS_Output/FileFormat.csv')),
            ruledatatype_output=_full_path(files.get('ruledatatype_output', 'DS_Output/RuleDataType.csv')),
            codemapping_output=_full_path(files.get('codemapping_output', 'DS_Output/CodeMapping.csv')),
            analyzer_script_quality=_full_path(files.get('analyzer_script_quality', 'util/DS_11_MasterCodeFormat.py')),
            analyzer_script_rule=_full_path(files.get('analyzer_script_rule', 'util/DS_12_MasterRuleDataType.py')),
            analyzer_script_relationship=_full_path(files.get('analyzer_script_relationship', 'util/DS_13_Code Relationship Analyzer.py')),
            # analyzer_script_erd_mapping=_full_path(files.get('analyzer_script_erd_mapping', 'util/DS_14_ERD Mapping.py'))
        )
    
    def load_file(self, file_path: str, file_name: str) -> Optional[pd.DataFrame]:
        """CSV íŒŒì¼ ë¡œë“œ"""
        path = Path(file_path)
        if not path.exists():
            return None
        
        try:
            for enc in ("utf-8-sig", "utf-8", "cp949"):
                try:
                    df = pd.read_csv(path, encoding=enc)
                    return df
                except Exception:
                    continue
            return None
        except Exception as e:
            st.error(f"{file_name} ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None

# -------------------------------------------------------------------
# DATA QUALITY ANALYZER
# -------------------------------------------------------------------
class DataQualityAnalyzer:
    """Data Quality Analyzer ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self, yaml_config: Dict[str, Any], loader: FileLoader):
        self.yaml_config = yaml_config
        self.loader = loader
        self.script_path = Path(loader.files_config.analyzer_script_quality)
        self.output_path = Path(loader.files_config.fileformat_output)
    
    def run_analyzer(self) -> bool:
        """Data Quality Analyzer ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰"""
        if not self.script_path.exists():
            st.error(f"âŒ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.script_path}")
            return False
        
        cmd = [sys.executable, str(self.script_path)]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ âœ…")
            st.text_area("ğŸ“œ ì‹¤í–‰ ë¡œê·¸", result.stdout, height=200, key="quality_analyzer_log")
            return True
        except subprocess.CalledProcessError as e:
            st.error("âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.text_area("âš ï¸ ì˜¤ë¥˜ ë¡œê·¸", e.stderr, height=200, key="quality_analyzer_error")
            return False
# -------------------------------------------------------------------
# DATA TYPE & RULE ANALYZER
# -------------------------------------------------------------------
class DataTypeRuleAnalyzer:
    """Data Type & Rule Analyzer ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self, yaml_config: Dict[str, Any], loader: FileLoader):
        self.yaml_config = yaml_config
        self.loader = loader
        self.script_path = Path(loader.files_config.analyzer_script_rule)
    
    def run_analyzer(self) -> bool:
        """Data Type & Rule Analyzer ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰"""
        if not self.script_path.exists():
            st.error(f"âŒ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.script_path}")
            return False
        
        cmd = [sys.executable, str(self.script_path)]

        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ âœ…")
            st.text_area("ğŸ“œ ì‹¤í–‰ ë¡œê·¸", result.stdout, height=200, key="rule_analyzer_log")
            return True
        except subprocess.CalledProcessError as e:
            st.error("âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.text_area("âš ï¸ ì˜¤ë¥˜ ë¡œê·¸", e.stderr, height=200, key="rule_analyzer_error")
            return False
# -------------------------------------------------------------------
# CODE RELATIONSHIP ANALYZER
# -------------------------------------------------------------------
class CodeRelationshipAnalyzer:
    """Code Relationship Analyzer ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self, yaml_config: Dict[str, Any], loader: FileLoader):
        self.yaml_config = yaml_config
        self.loader = loader
        self.script_path = Path(loader.files_config.analyzer_script_relationship)
        # self.script_erd_path = Path(loader.files_config.analyzer_script_erd_mapping)
    
    def run_analyzer(self) -> bool:
        """Code Relationship Analyzer ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰"""
        if not self.script_path.exists():
            st.error(f"âŒ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.script_path}")
            return False
        
        cmd = [sys.executable, str(self.script_path)]
        # cmd_erd = [sys.executable, str(self.script_erd_path)]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ âœ…")
            st.text_area("ğŸ“œ ì‹¤í–‰ ë¡œê·¸", result.stdout, height=200, key="relationship_analyzer_log")
            return True
        except subprocess.CalledProcessError as e:
            st.error("âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.text_area("âš ï¸ ì˜¤ë¥˜ ë¡œê·¸", e.stderr, height=200, key="relationship_analyzer_error")
            return False  
# -------------------------------------------------------------------
# MAIN APP
# -------------------------------------------------------------------
class DataAnalyzerApp:
    """Data Analyzer í†µí•© ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self):
        self.yaml_config = None
        self.loader = None
        self.quality_analyzer = None
        self.rule_analyzer = None
        self.relationship_analyzer = None
        self.password = None
    
    def initialize(self) -> bool:
        """ì´ˆê¸°í™”"""
        try:
            self.yaml_config = load_yaml_datasense()
            self.loader = FileLoader(self.yaml_config)
            self.quality_analyzer = DataQualityAnalyzer(self.yaml_config, self.loader)
            self.rule_analyzer = DataTypeRuleAnalyzer(self.yaml_config, self.loader)
            self.relationship_analyzer = CodeRelationshipAnalyzer(self.yaml_config, self.loader)
            self.password = self.yaml_config.get("DataSense_Password", "") # tkfkdgo
            return True
        except Exception as e:
            st.error(f"ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            return False
    
    def data_analyzer(self):
        """ë©”ì¸ UI í‘œì‹œ"""
        st.title(f"ğŸ“Š {APP_NAME}")
        st.markdown(APP_DESC)
        st.markdown(APP_DESC2)
        
        display_statistics_info()

        st.divider()
        col1, col2 = st.columns([1, 2])
        with col1:
            password_input = None
            with st.expander("ğŸ” ì‹¤í–‰ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥", expanded=True):
                password_input = st.text_input(
                    "ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                    type="password",
                    key="data_analyzer_password_input",
                    help="Data Analyzer ì‹¤í–‰ì„ ìœ„í•œ ë¹„ë°€ë²ˆí˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                )

        with col2:
            st.markdown("###### ì „ì²´ íŒŒì¼ì˜ ìˆ˜ ë° í¬ê¸°ì— ë”°ë¼ ì‹œê°„ì´ ë§ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì•½ 10ë¶„ ì´ìƒ ì†Œìš”)")
            if st.button("ğŸ” Data Analyzer ì‹¤í–‰", key="btn_integrated_analyzer"):
                if not password_input:
                    st.error("âŒ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                elif password_input != self.password:
                    st.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                else:
                    # í†µí•© ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
                    with st.spinner("ì „ì²´ ë°ì´í„° ë¶„ì„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                        # 1. í”„ë¡œê·¸ë ˆìŠ¤ ë°”ì™€ ìƒíƒœ í…ìŠ¤íŠ¸ ì˜ì—­ ìƒì„±
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        # --- [1ë‹¨ê³„: Data Quality] ---
                        status_text.write("â³ [1/3] Data Quality ë¶„ì„ì„ ìˆ˜í–‰ ì¤‘ì…ë‹ˆë‹¤... (33%)")
                        progress_bar.progress(10) # ì‹œì‘ ì‹œ ì•½ê°„ ì±„ì›€
                        
                        if self.quality_analyzer.run_analyzer():
                            progress_bar.progress(33)
                            
                            # --- [2ë‹¨ê³„: Data Type & Rule] ---
                            status_text.write("â³ [2/3] Data Type & Rule ë¶„ì„ì„ ìˆ˜í–‰ ì¤‘ì…ë‹ˆë‹¤... (66%)")
                            if self.rule_analyzer.run_analyzer():
                                progress_bar.progress(66)
                                
                                # --- [3ë‹¨ê³„: Code Relationship] ---
                                status_text.write("â³ [3/3] Code Relationship ë¶„ì„ì„ ìˆ˜í–‰ ì¤‘ì…ë‹ˆë‹¤... (100%)")
                                if self.relationship_analyzer.run_analyzer():
                                    progress_bar.progress(100)
                                    status_text.empty() # ì§„í–‰ í…ìŠ¤íŠ¸ ì‚­ì œ
                                    
                                    st.success("ğŸ‰ ëª¨ë“  ë¶„ì„ ë‹¨ê³„(Quality -> Rule -> Relationship)ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                                    st.balloons()
                                else:
                                    st.error("âŒ 3ë‹¨ê³„(Relationship) ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                            else:
                                st.error("âŒ 2ë‹¨ê³„(Rule) ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.error("âŒ 1ë‹¨ê³„(Quality) ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        #----------------------------------------------------
        # Data Analyzer ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        #----------------------------------------------------
        st.divider()
        tab1, tab2, tab3 = st.tabs(["Data Quality Analyzer", "Data Type & Rule Analyzer", "Code Relationship Analyzer"])
        with tab1:
            df = self.loader.load_file(self.loader.files_config.fileformat_output, "FileFormat")
            if df is not None:  
                display_data_quality_results(df)
            else:
                st.info("Data Quality Analyzer ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        with tab2:
            df = self.loader.load_file(self.loader.files_config.ruledatatype_output, "RuleDataType")
            if df is not None:  
                st.info("ì•„ë˜ ë°ì´í„°ëŠ” ì´ì „ì— ì²˜ë¦¬ëœ ê²°ê³¼ì…ë‹ˆë‹¤. ")
                display_data_type_rule_results(df)
            else:
                st.info("Data Type & Rule Analyzer ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        with tab3:
            df = self.loader.load_file(self.loader.files_config.codemapping_output, "CodeMapping")
            if df is not None:  
                st.info("ì•„ë˜ ë°ì´í„°ëŠ” ì´ì „ì— ì²˜ë¦¬ëœ ê²°ê³¼ì…ë‹ˆë‹¤. ")
                display_code_relationship_results(df)
            else:
                st.info("Code Relationship Analyzer ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.info("##### Data Quality Information ì•±ì—ì„œ ìƒì„¸ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
# -------------------------------------------------------------------
# MAIN
# -------------------------------------------------------------------
def main():
    try:
        app = DataAnalyzerApp()
        if app.initialize():
            app.data_analyzer()
        else:
            st.error("DataAnalyzerApp ì´ˆê¸°í™” ì‹¤íŒ¨")
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì˜¤ë¥˜: {e}")
        import traceback
        st.exception(e)

if __name__ == "__main__":
    main()

